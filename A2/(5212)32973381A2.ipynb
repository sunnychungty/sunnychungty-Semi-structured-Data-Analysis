{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "21c48916",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "# import torchtext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d6b51e97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2b52042c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\Sunny\\\\Desktop\\\\Master\\\\Sem3\\\\5212\\\\A2'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "34b48887",
   "metadata": {},
   "outputs": [],
   "source": [
    "FolderPath = \"/data\"\n",
    "import pandas as pd\n",
    "FolderPath = \"C:/Users/Sunny/Desktop/Master/Sem3/5212/A2/Data\"\n",
    "train_df = pd.read_csv(FolderPath + \"/train.csv\")\n",
    "test_df = pd.read_csv(FolderPath + \"/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4e1804bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 286136 entries, 0 to 286135\n",
      "Data columns (total 4 columns):\n",
      " #   Column     Non-Null Count   Dtype \n",
      "---  ------     --------------   ----- \n",
      " 0   user_id    286136 non-null  int64 \n",
      " 1   item_id    286136 non-null  int64 \n",
      " 2   rating     286136 non-null  int64 \n",
      " 3   book_name  286136 non-null  object\n",
      "dtypes: int64(3), object(1)\n",
      "memory usage: 8.7+ MB\n"
     ]
    }
   ],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7a92ed0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 56199 entries, 0 to 56198\n",
      "Data columns (total 4 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   ID         56199 non-null  int64 \n",
      " 1   user_id    56199 non-null  int64 \n",
      " 2   item_id    56199 non-null  int64 \n",
      " 3   book_name  56199 non-null  object\n",
      "dtypes: int64(3), object(1)\n",
      "memory usage: 1.7+ MB\n"
     ]
    }
   ],
   "source": [
    "test_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "678c3e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = pd.read_csv(FolderPath + \"/books_metadata.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "baf5dc9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata[\"item_id\"] = pd.to_numeric(metadata[\"item_id\"], errors=\"coerce\").astype(\"Int64\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "de6a843f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1636235 entries, 0 to 1636234\n",
      "Data columns (total 9 columns):\n",
      " #   Column          Non-Null Count    Dtype  \n",
      "---  ------          --------------    -----  \n",
      " 0   Name            1636235 non-null  object \n",
      " 1   pagesNumber     1636235 non-null  float64\n",
      " 2   Publisher       1628844 non-null  object \n",
      " 3   CountsOfReview  1636235 non-null  float64\n",
      " 4   PublishYear     1636235 non-null  float64\n",
      " 5   Language        1045236 non-null  object \n",
      " 6   Authors         1636235 non-null  object \n",
      " 7   Rating          1636235 non-null  float64\n",
      " 8   item_id         44586 non-null    Int64  \n",
      "dtypes: Int64(1), float64(4), object(4)\n",
      "memory usage: 113.9+ MB\n"
     ]
    }
   ],
   "source": [
    "metadata.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "56cc98db",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata[~metadata[\"pagesNumber\"].isna()][\"pagesNumber\"].mean()\n",
    "metadata.loc[metadata[\"pagesNumber\"].isna(), \"pagesNumber\"] = metadata[~metadata[\"pagesNumber\"].isna()][\"pagesNumber\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3f8ac7d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata.loc[metadata[\"Publisher\"].isna(), \"Publisher\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bfca4e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bbaad272",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 286136 entries, 0 to 286135\n",
      "Data columns (total 12 columns):\n",
      " #   Column          Non-Null Count   Dtype  \n",
      "---  ------          --------------   -----  \n",
      " 0   user_id         286136 non-null  int64  \n",
      " 1   item_id         286136 non-null  int64  \n",
      " 2   rating          286136 non-null  int64  \n",
      " 3   book_name       286136 non-null  object \n",
      " 4   Name            185375 non-null  object \n",
      " 5   pagesNumber     167068 non-null  float64\n",
      " 6   Publisher       184481 non-null  object \n",
      " 7   CountsOfReview  185375 non-null  float64\n",
      " 8   PublishYear     185375 non-null  float64\n",
      " 9   Language        185375 non-null  object \n",
      " 10  Authors         185375 non-null  object \n",
      " 11  Rating          185375 non-null  float64\n",
      "dtypes: float64(4), int64(3), object(5)\n",
      "memory usage: 28.4+ MB\n"
     ]
    }
   ],
   "source": [
    "metadata[\"item_id\"] = metadata[\"item_id\"].fillna(-1)\n",
    "train_df = train_df.merge(metadata, on = \"item_id\", how = \"left\")\n",
    "test_df = test_df.merge(metadata, on = \"item_id\", how = \"left\")\n",
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d31439b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Imputing languages:  62%|██████▏   | 1016447/1636235 [3:51:46<54:32, 189.42it/s]    "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from langdetect import detect\n",
    "from langdetect import DetectorFactory\n",
    "from multiprocessing import Pool, cpu_count\n",
    "from tqdm import tqdm\n",
    "def detect_language(text):\n",
    "    try:\n",
    "        return detect(text)\n",
    "    except:\n",
    "        return None\n",
    "    \n",
    "df = metadata\n",
    "for index, row in tqdm(df[df[\"Language\"].isna()].iterrows(), total = len(df), desc = \"Imputing languages\"):\n",
    "    text = f\"{row['Publisher']} {row['Name']} {row['Authors']}\"\n",
    "    language = detect_language(text)\n",
    "    \n",
    "    if language:\n",
    "        df.at[index, 'Language'] = language\n",
    "\n",
    "# Print the updated DataFrame\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc2fa328",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(FolderPath + \"/metadata_imputed.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a57cc988",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fe728b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata[metadata[\"Language\"].isna()].info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f155255e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-surprise\n",
      "  Using cached scikit-surprise-1.1.3.tar.gz (771 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: joblib>=1.0.0 in c:\\users\\sunny\\anaconda3\\envs\\5212a1\\lib\\site-packages (from scikit-surprise) (1.2.0)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\sunny\\anaconda3\\envs\\5212a1\\lib\\site-packages (from scikit-surprise) (1.22.3)\n",
      "Requirement already satisfied: scipy>=1.3.2 in c:\\users\\sunny\\anaconda3\\envs\\5212a1\\lib\\site-packages (from scikit-surprise) (1.10.1)\n",
      "Building wheels for collected packages: scikit-surprise\n",
      "  Building wheel for scikit-surprise (setup.py): started\n",
      "  Building wheel for scikit-surprise (setup.py): finished with status 'error'\n",
      "  Running setup.py clean for scikit-surprise\n",
      "Failed to build scikit-surprise\n",
      "Installing collected packages: scikit-surprise\n",
      "  Running setup.py install for scikit-surprise: started\n",
      "  Running setup.py install for scikit-surprise: finished with status 'error'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  python setup.py bdist_wheel did not run successfully.\n",
      "  exit code: 1\n",
      "  \n",
      "  [76 lines of output]\n",
      "  running bdist_wheel\n",
      "  running build\n",
      "  running build_py\n",
      "  creating build\n",
      "  creating build\\lib.win-amd64-cpython-38\n",
      "  creating build\\lib.win-amd64-cpython-38\\surprise\n",
      "  copying surprise\\accuracy.py -> build\\lib.win-amd64-cpython-38\\surprise\n",
      "  copying surprise\\builtin_datasets.py -> build\\lib.win-amd64-cpython-38\\surprise\n",
      "  copying surprise\\dataset.py -> build\\lib.win-amd64-cpython-38\\surprise\n",
      "  copying surprise\\dump.py -> build\\lib.win-amd64-cpython-38\\surprise\n",
      "  copying surprise\\reader.py -> build\\lib.win-amd64-cpython-38\\surprise\n",
      "  copying surprise\\trainset.py -> build\\lib.win-amd64-cpython-38\\surprise\n",
      "  copying surprise\\utils.py -> build\\lib.win-amd64-cpython-38\\surprise\n",
      "  copying surprise\\__init__.py -> build\\lib.win-amd64-cpython-38\\surprise\n",
      "  copying surprise\\__main__.py -> build\\lib.win-amd64-cpython-38\\surprise\n",
      "  creating build\\lib.win-amd64-cpython-38\\surprise\\model_selection\n",
      "  copying surprise\\model_selection\\search.py -> build\\lib.win-amd64-cpython-38\\surprise\\model_selection\n",
      "  copying surprise\\model_selection\\split.py -> build\\lib.win-amd64-cpython-38\\surprise\\model_selection\n",
      "  copying surprise\\model_selection\\validation.py -> build\\lib.win-amd64-cpython-38\\surprise\\model_selection\n",
      "  copying surprise\\model_selection\\__init__.py -> build\\lib.win-amd64-cpython-38\\surprise\\model_selection\n",
      "  creating build\\lib.win-amd64-cpython-38\\surprise\\prediction_algorithms\n",
      "  copying surprise\\prediction_algorithms\\algo_base.py -> build\\lib.win-amd64-cpython-38\\surprise\\prediction_algorithms\n",
      "  copying surprise\\prediction_algorithms\\baseline_only.py -> build\\lib.win-amd64-cpython-38\\surprise\\prediction_algorithms\n",
      "  copying surprise\\prediction_algorithms\\knns.py -> build\\lib.win-amd64-cpython-38\\surprise\\prediction_algorithms\n",
      "  copying surprise\\prediction_algorithms\\predictions.py -> build\\lib.win-amd64-cpython-38\\surprise\\prediction_algorithms\n",
      "  copying surprise\\prediction_algorithms\\random_pred.py -> build\\lib.win-amd64-cpython-38\\surprise\\prediction_algorithms\n",
      "  copying surprise\\prediction_algorithms\\__init__.py -> build\\lib.win-amd64-cpython-38\\surprise\\prediction_algorithms\n",
      "  running egg_info\n",
      "  writing scikit_surprise.egg-info\\PKG-INFO\n",
      "  writing dependency_links to scikit_surprise.egg-info\\dependency_links.txt\n",
      "  writing entry points to scikit_surprise.egg-info\\entry_points.txt\n",
      "  writing requirements to scikit_surprise.egg-info\\requires.txt\n",
      "  writing top-level names to scikit_surprise.egg-info\\top_level.txt\n",
      "  reading manifest file 'scikit_surprise.egg-info\\SOURCES.txt'\n",
      "  reading manifest template 'MANIFEST.in'\n",
      "  adding license file 'LICENSE.md'\n",
      "  writing manifest file 'scikit_surprise.egg-info\\SOURCES.txt'\n",
      "  C:\\Users\\Sunny\\anaconda3\\envs\\5212A1\\lib\\site-packages\\setuptools\\command\\build_py.py:202: SetuptoolsDeprecationWarning:     Installing 'surprise.prediction_algorithms' as data is deprecated, please list it in `packages`.\n",
      "      !!\n",
      "  \n",
      "  \n",
      "      ############################\n",
      "      # Package would be ignored #\n",
      "      ############################\n",
      "      Python recognizes 'surprise.prediction_algorithms' as an importable package,\n",
      "      but it is not listed in the `packages` configuration of setuptools.\n",
      "  \n",
      "      'surprise.prediction_algorithms' has been automatically added to the distribution only\n",
      "      because it may contain data files, but this behavior is likely to change\n",
      "      in future versions of setuptools (and therefore is considered deprecated).\n",
      "  \n",
      "      Please make sure that 'surprise.prediction_algorithms' is included as a package by using\n",
      "      the `packages` configuration field or the proper discovery methods\n",
      "      (for example by using `find_namespace_packages(...)`/`find_namespace:`\n",
      "      instead of `find_packages(...)`/`find:`).\n",
      "  \n",
      "      You can read more about \"package discovery\" and \"data files\" on setuptools\n",
      "      documentation page.\n",
      "  \n",
      "  \n",
      "  !!\n",
      "  \n",
      "    check.warn(importable)\n",
      "  copying surprise\\similarities.c -> build\\lib.win-amd64-cpython-38\\surprise\n",
      "  copying surprise\\similarities.pyx -> build\\lib.win-amd64-cpython-38\\surprise\n",
      "  copying surprise\\prediction_algorithms\\co_clustering.c -> build\\lib.win-amd64-cpython-38\\surprise\\prediction_algorithms\n",
      "  copying surprise\\prediction_algorithms\\matrix_factorization.c -> build\\lib.win-amd64-cpython-38\\surprise\\prediction_algorithms\n",
      "  copying surprise\\prediction_algorithms\\optimize_baselines.c -> build\\lib.win-amd64-cpython-38\\surprise\\prediction_algorithms\n",
      "  copying surprise\\prediction_algorithms\\slope_one.c -> build\\lib.win-amd64-cpython-38\\surprise\\prediction_algorithms\n",
      "  copying surprise\\prediction_algorithms\\co_clustering.pyx -> build\\lib.win-amd64-cpython-38\\surprise\\prediction_algorithms\n",
      "  copying surprise\\prediction_algorithms\\matrix_factorization.pyx -> build\\lib.win-amd64-cpython-38\\surprise\\prediction_algorithms\n",
      "  copying surprise\\prediction_algorithms\\optimize_baselines.pyx -> build\\lib.win-amd64-cpython-38\\surprise\\prediction_algorithms\n",
      "  copying surprise\\prediction_algorithms\\slope_one.pyx -> build\\lib.win-amd64-cpython-38\\surprise\\prediction_algorithms\n",
      "  running build_ext\n",
      "  building 'surprise.similarities' extension\n",
      "  error: Microsoft Visual C++ 14.0 or greater is required. Get it with \"Microsoft C++ Build Tools\": https://visualstudio.microsoft.com/visual-cpp-build-tools/\n",
      "  [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "  ERROR: Failed building wheel for scikit-surprise\n",
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  Running setup.py install for scikit-surprise did not run successfully.\n",
      "  exit code: 1\n",
      "  \n",
      "  [78 lines of output]\n",
      "  running install\n",
      "  C:\\Users\\Sunny\\anaconda3\\envs\\5212A1\\lib\\site-packages\\setuptools\\command\\install.py:34: SetuptoolsDeprecationWarning: setup.py install is deprecated. Use build and pip and other standards-based tools.\n",
      "    warnings.warn(\n",
      "  running build\n",
      "  running build_py\n",
      "  creating build\n",
      "  creating build\\lib.win-amd64-cpython-38\n",
      "  creating build\\lib.win-amd64-cpython-38\\surprise\n",
      "  copying surprise\\accuracy.py -> build\\lib.win-amd64-cpython-38\\surprise\n",
      "  copying surprise\\builtin_datasets.py -> build\\lib.win-amd64-cpython-38\\surprise\n",
      "  copying surprise\\dataset.py -> build\\lib.win-amd64-cpython-38\\surprise\n",
      "  copying surprise\\dump.py -> build\\lib.win-amd64-cpython-38\\surprise\n",
      "  copying surprise\\reader.py -> build\\lib.win-amd64-cpython-38\\surprise\n",
      "  copying surprise\\trainset.py -> build\\lib.win-amd64-cpython-38\\surprise\n",
      "  copying surprise\\utils.py -> build\\lib.win-amd64-cpython-38\\surprise\n",
      "  copying surprise\\__init__.py -> build\\lib.win-amd64-cpython-38\\surprise\n",
      "  copying surprise\\__main__.py -> build\\lib.win-amd64-cpython-38\\surprise\n",
      "  creating build\\lib.win-amd64-cpython-38\\surprise\\model_selection\n",
      "  copying surprise\\model_selection\\search.py -> build\\lib.win-amd64-cpython-38\\surprise\\model_selection\n",
      "  copying surprise\\model_selection\\split.py -> build\\lib.win-amd64-cpython-38\\surprise\\model_selection\n",
      "  copying surprise\\model_selection\\validation.py -> build\\lib.win-amd64-cpython-38\\surprise\\model_selection\n",
      "  copying surprise\\model_selection\\__init__.py -> build\\lib.win-amd64-cpython-38\\surprise\\model_selection\n",
      "  creating build\\lib.win-amd64-cpython-38\\surprise\\prediction_algorithms\n",
      "  copying surprise\\prediction_algorithms\\algo_base.py -> build\\lib.win-amd64-cpython-38\\surprise\\prediction_algorithms\n",
      "  copying surprise\\prediction_algorithms\\baseline_only.py -> build\\lib.win-amd64-cpython-38\\surprise\\prediction_algorithms\n",
      "  copying surprise\\prediction_algorithms\\knns.py -> build\\lib.win-amd64-cpython-38\\surprise\\prediction_algorithms\n",
      "  copying surprise\\prediction_algorithms\\predictions.py -> build\\lib.win-amd64-cpython-38\\surprise\\prediction_algorithms\n",
      "  copying surprise\\prediction_algorithms\\random_pred.py -> build\\lib.win-amd64-cpython-38\\surprise\\prediction_algorithms\n",
      "  copying surprise\\prediction_algorithms\\__init__.py -> build\\lib.win-amd64-cpython-38\\surprise\\prediction_algorithms\n",
      "  running egg_info\n",
      "  writing scikit_surprise.egg-info\\PKG-INFO\n",
      "  writing dependency_links to scikit_surprise.egg-info\\dependency_links.txt\n",
      "  writing entry points to scikit_surprise.egg-info\\entry_points.txt\n",
      "  writing requirements to scikit_surprise.egg-info\\requires.txt\n",
      "  writing top-level names to scikit_surprise.egg-info\\top_level.txt\n",
      "  reading manifest file 'scikit_surprise.egg-info\\SOURCES.txt'\n",
      "  reading manifest template 'MANIFEST.in'\n",
      "  adding license file 'LICENSE.md'\n",
      "  writing manifest file 'scikit_surprise.egg-info\\SOURCES.txt'\n",
      "  C:\\Users\\Sunny\\anaconda3\\envs\\5212A1\\lib\\site-packages\\setuptools\\command\\build_py.py:202: SetuptoolsDeprecationWarning:     Installing 'surprise.prediction_algorithms' as data is deprecated, please list it in `packages`.\n",
      "      !!\n",
      "  \n",
      "  \n",
      "      ############################\n",
      "      # Package would be ignored #\n",
      "      ############################\n",
      "      Python recognizes 'surprise.prediction_algorithms' as an importable package,\n",
      "      but it is not listed in the `packages` configuration of setuptools.\n",
      "  \n",
      "      'surprise.prediction_algorithms' has been automatically added to the distribution only\n",
      "      because it may contain data files, but this behavior is likely to change\n",
      "      in future versions of setuptools (and therefore is considered deprecated).\n",
      "  \n",
      "      Please make sure that 'surprise.prediction_algorithms' is included as a package by using\n",
      "      the `packages` configuration field or the proper discovery methods\n",
      "      (for example by using `find_namespace_packages(...)`/`find_namespace:`\n",
      "      instead of `find_packages(...)`/`find:`).\n",
      "  \n",
      "      You can read more about \"package discovery\" and \"data files\" on setuptools\n",
      "      documentation page.\n",
      "  \n",
      "  \n",
      "  !!\n",
      "  \n",
      "    check.warn(importable)\n",
      "  copying surprise\\similarities.c -> build\\lib.win-amd64-cpython-38\\surprise\n",
      "  copying surprise\\similarities.pyx -> build\\lib.win-amd64-cpython-38\\surprise\n",
      "  copying surprise\\prediction_algorithms\\co_clustering.c -> build\\lib.win-amd64-cpython-38\\surprise\\prediction_algorithms\n",
      "  copying surprise\\prediction_algorithms\\matrix_factorization.c -> build\\lib.win-amd64-cpython-38\\surprise\\prediction_algorithms\n",
      "  copying surprise\\prediction_algorithms\\optimize_baselines.c -> build\\lib.win-amd64-cpython-38\\surprise\\prediction_algorithms\n",
      "  copying surprise\\prediction_algorithms\\slope_one.c -> build\\lib.win-amd64-cpython-38\\surprise\\prediction_algorithms\n",
      "  copying surprise\\prediction_algorithms\\co_clustering.pyx -> build\\lib.win-amd64-cpython-38\\surprise\\prediction_algorithms\n",
      "  copying surprise\\prediction_algorithms\\matrix_factorization.pyx -> build\\lib.win-amd64-cpython-38\\surprise\\prediction_algorithms\n",
      "  copying surprise\\prediction_algorithms\\optimize_baselines.pyx -> build\\lib.win-amd64-cpython-38\\surprise\\prediction_algorithms\n",
      "  copying surprise\\prediction_algorithms\\slope_one.pyx -> build\\lib.win-amd64-cpython-38\\surprise\\prediction_algorithms\n",
      "  running build_ext\n",
      "  building 'surprise.similarities' extension\n",
      "  error: Microsoft Visual C++ 14.0 or greater is required. Get it with \"Microsoft C++ Build Tools\": https://visualstudio.microsoft.com/visual-cpp-build-tools/\n",
      "  [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "error: legacy-install-failure\n",
      "\n",
      "Encountered error while trying to install package.\n",
      "\n",
      "scikit-surprise\n",
      "\n",
      "note: This is an issue with the package mentioned above, not pip.\n",
      "hint: See above for output from the failure.\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-surprise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "852d8918",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'surprise'",
     "output_type": "error",
     "traceback": [
      "Traceback \u001b[1;36m(most recent call last)\u001b[0m:\n",
      "\u001b[1;36m  Cell \u001b[1;32mIn[17], line 2\u001b[1;36m\n\u001b[1;33m    from surprise import Reader, Dataset, SVD\u001b[1;36m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m\u001b[1;31m:\u001b[0m No module named 'surprise'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from surprise import Reader, Dataset, SVD\n",
    "from surprise.model_selection import train_test_split\n",
    "from surprise import accuracy\n",
    "\n",
    "# Assuming train_df is the DataFrame you provided\n",
    "train_df = pd.DataFrame( ... )\n",
    "\n",
    "# Create a reader\n",
    "reader = Reader(rating_scale=(1, 5))\n",
    "\n",
    "# Load the data\n",
    "data = Dataset.load_from_df(train_df[['user_id', 'item_id', 'rating']], reader)\n",
    "\n",
    "# Split the dataset into training and validation sets (80% training, 20% validation)\n",
    "trainset, testset = train_test_split(data, test_size=0.2)\n",
    "\n",
    "# Initialize the SVD algorithm\n",
    "algo = SVD()\n",
    "\n",
    "# Train the algorithm on the training set\n",
    "algo.fit(trainset)\n",
    "\n",
    "# Make predictions on the validation set\n",
    "predictions = algo.test(testset)\n",
    "\n",
    "# Calculate the Root Mean Square Error (RMSE) and Mean Absolute Error (MAE) for the predictions\n",
    "rmse = accuracy.rmse(predictions)\n",
    "mae = accuracy.mae(predictions)\n",
    "\n",
    "# Print the RMSE and MAE\n",
    "print(\"Root Mean Square Error (RMSE):\", rmse)\n",
    "print(\"Mean Absolute Error (MAE):\", mae)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e6142508",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1636235 entries, 0 to 1636234\n",
      "Data columns (total 9 columns):\n",
      " #   Column          Non-Null Count    Dtype  \n",
      "---  ------          --------------    -----  \n",
      " 0   Name            1636235 non-null  object \n",
      " 1   pagesNumber     718417 non-null   float64\n",
      " 2   Publisher       1619540 non-null  object \n",
      " 3   CountsOfReview  1636235 non-null  int64  \n",
      " 4   PublishYear     1636235 non-null  int64  \n",
      " 5   Language        1636233 non-null  object \n",
      " 6   Authors         1636235 non-null  object \n",
      " 7   Rating          1636235 non-null  float64\n",
      " 8   item_id         1636235 non-null  Int64  \n",
      "dtypes: Int64(1), float64(2), int64(2), object(4)\n",
      "memory usage: 113.9+ MB\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f3e9d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Assuming metadata_df is the DataFrame you provided\n",
    "metadata_df = pd.DataFrame( ... )\n",
    "\n",
    "# Preprocessing: fill missing values, normalize numeric columns\n",
    "metadata_df['pagesNumber'] = metadata_df['pagesNumber'].fillna(0)\n",
    "metadata_df['CountsOfReview'] = metadata_df['CountsOfReview'].fillna(0)\n",
    "metadata_df['PublishYear'] = metadata_df['PublishYear'].fillna(0)\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "metadata_df[['pagesNumber', 'CountsOfReview', 'PublishYear']] = scaler.fit_transform(metadata_df[['pagesNumber', 'CountsOfReview', 'PublishYear']])\n",
    "\n",
    "# Create a matrix of combined features\n",
    "metadata_df['combined_features'] = metadata_df['Name'] + ' ' + metadata_df['Publisher'] + ' ' + metadata_df['Language'] + ' ' + metadata_df['Authors']\n",
    "\n",
    "# Create a CountVectorizer object\n",
    "count_vectorizer = CountVectorizer()\n",
    "\n",
    "# Create a matrix of word count from combined_features\n",
    "count_matrix = count_vectorizer.fit_transform(metadata_df['combined_features'])\n",
    "\n",
    "# Compute the cosine similarity matrix\n",
    "cosine_sim_matrix = cosine_similarity(count_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da9b530d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise import AlgoBase\n",
    "\n",
    "class HybridRecommender(AlgoBase):\n",
    "    def __init__(self, sim_matrix):\n",
    "        AlgoBase.__init__(self)\n",
    "        self.sim_matrix = sim_matrix\n",
    "\n",
    "    def fit(self, trainset):\n",
    "        AlgoBase.fit(self, trainset)\n",
    "\n",
    "        # Train the SVD algorithm on the training set\n",
    "        self.algo = SVD()\n",
    "        self.algo.fit(trainset)\n",
    "        return self\n",
    "\n",
    "    def estimate(self, u, i):\n",
    "        if self.trainset.knows_user(u) and self.trainset.knows_item(i):\n",
    "            # Get the inner id of the item\n",
    "            item_inner_id = self.trainset.to_inner_iid(i)\n",
    "            \n",
    "            # Calculate the weighted average of similar items\n",
    "            sim_scores = list(enumerate(self.sim_matrix[item_inner_id]))\n",
    "            sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
    "            \n",
    "            # Get the top 10 most similar items\n",
    "            sim_scores = sim_scores[1:11]\n",
    "\n",
    "            # Get the item indices and their similarity scores\n",
    "            item_indices, sim_scores = zip(*sim_scores)\n",
    "\n",
    "            # Get the user's rating for the similar items\n",
    "            user_ratings = [self.trainset.ur[u][inner_id] for inner_id in item_indices]\n",
    "\n",
    "            # Compute the weighted average of ratings\n",
    "            weighted_rating = sum(user_ratings[i] * sim_scores[i] for i in range(len(user_ratings))) / sum(sim_scores)\n",
    "\n",
    "            return weighted_rating\n",
    "\n",
    "        # Default prediction\n",
    "        return self.trainset.global_mean\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36c15664",
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise.model_selection import train_test_split\n",
    "from surprise import accuracy\n",
    "\n",
    "# Load the data\n",
    "data = Dataset.load_from_df(train_df[['user_id', 'item_id', 'rating']], reader)\n",
    "\n",
    "# Split the dataset into training and validation sets (80% training, 20% validation)\n",
    "trainset, testset = train_test_split(data, test_size=0.2)\n",
    "\n",
    "# Initialize the hybrid recommender with the cosine similarity matrix\n",
    "hybrid_recommender = HybridRecommender(cosine_sim_matrix)\n",
    "\n",
    "# Train the algorithm on the training set\n",
    "hybrid_recommender.fit(trainset)\n",
    "\n",
    "# Make predictions on the validation set\n",
    "predictions = hybrid_recommender.test(testset)\n",
    "\n",
    "# Calculate the Root Mean Square Error (RMSE) and Mean Absolute Error (MAE) for the predictions\n",
    "rmse = accuracy.rmse(predictions)\n",
    "mae = accuracy.mae(predictions)\n",
    "\n",
    "# Print the RMSE and MAE\n",
    "print(\"Root Mean Square Error (RMSE):\", rmse)\n",
    "print(\"Mean Absolute Error (MAE):\", mae)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (Spyder)",
   "language": "python3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
