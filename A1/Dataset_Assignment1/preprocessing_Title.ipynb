{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a82d370b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip3 install torch==1.9.1+cu111 torchvision==0.10.1+cu111 torchaudio==0.9.1 -f https://download.pytorch.org/whl/torch_stable.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "da0dcdad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip3 install torchtext==0.10.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "961338fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5ace382f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sunny\\anaconda3\\envs\\5212A1\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Import Libraries\n",
    "import torch\n",
    "import torchtext\n",
    "\n",
    "from torchtext.legacy import data\n",
    "import torch.nn as nn\n",
    "from torchtext.legacy.data import Field, LabelField, TabularDataset, Dataset\n",
    "import copy\n",
    "\n",
    "import torch.optim as optim\n",
    "import collections\n",
    "import random\n",
    "import time\n",
    "import pandas as pd\n",
    "import re\n",
    "import spacy\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score, confusion_matrix, matthews_corrcoef\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "245e48c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current GPU: 0 - NVIDIA GeForce RTX 3070 Laptop GPU, device type: cuda\n"
     ]
    }
   ],
   "source": [
    "# check for device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "print(f\"Current GPU: {torch.cuda.current_device()} - {torch.cuda.get_device_name(torch.cuda.current_device())}, device type: {device}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "69c935c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\Sunny\\\\Desktop\\\\Master\\\\Sem3\\\\5212\\\\A1\\\\Dataset_Assignment1'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3b811ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up random seed\n",
    "\n",
    "SEED = 1\n",
    "\n",
    "torch.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "27bce534",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start with working on \"title\" as TEXT, using top 1000 records of train_data as training data\n",
    "\n",
    "# Set up field & loading datasets\n",
    "\n",
    "# Import STOP_WORDS from spaCy\n",
    "spacy_en = spacy.load(\"en_core_web_sm\")\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "\n",
    "# Create first pre-processing method P1\n",
    "# P1 aimms to remove all stop_words in TEXT Field\n",
    "def custom_tokenizer(text):\n",
    "  \n",
    "    return [tok.text for tok in spacy_en.tokenizer(text) if tok.text.lower() not in STOP_WORDS]\n",
    "\n",
    "ps = PorterStemmer()\n",
    "\n",
    "def custom_tokenizer_P2(text):\n",
    "    \n",
    "    return [ps.stem(tok.text) for tok in spacy_en.tokenizer(text)]\n",
    "# Create Field\n",
    "TEXT = data.Field(sequential=True, tokenize=custom_tokenizer, lower=False)\n",
    "LABEL = data.LabelField(dtype=torch.float, use_vocab = False, preprocessing = int)\n",
    " \n",
    "    \n",
    "train_datafield = [(\"title\", TEXT), \n",
    "                   (\"abstract\", None),\n",
    "                   (\"InformationTheory\", LABEL), \n",
    "                   (\"ComputationalLinguistics\", LABEL),\n",
    "                   (\"ComputerVision\", LABEL)\n",
    "                   ]\n",
    "\n",
    "\n",
    "\n",
    "# Dataset - P1\n",
    "train_data_whole, test_data = TabularDataset.splits(\n",
    "    path = \"./\",\n",
    "    train = \"train.csv\", test = \"test.csv\", format = \"csv\",\n",
    "    skip_header = True, fields = train_datafield)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "775c1c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, valid_data = train_data_whole.split(split_ratio = 0.9, random_state = random.getstate())\n",
    "train_1000, remaining = train_data_whole.split(split_ratio = 1000 / len(train_data_whole), random_state = random.getstate())\n",
    "train_1000, valid_1000 = train_1000.split(split_ratio = 0.9, random_state = random.getstate())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "40f51075",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building vocab\n",
    "MAX_VOCAB_SIZE = 5000\n",
    "\n",
    "TEXT.build_vocab(train_1000, max_size = MAX_VOCAB_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d3f7c917",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# Create iterator #1 for small train_data\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "def preprocess_target_label(target_field, validation):\n",
    "    for example in train_data:\n",
    "        setattr(example, f\"label_{target_field}\", getattr(example, target_field))\n",
    "        \n",
    "    for example in test_data:\n",
    "        setattr(example, f\"label_{target_field}\", getattr(example, target_field))\n",
    "\n",
    "    if validation:\n",
    "        for example in valid_data:\n",
    "            setattr(example, f\"label_{target_field}\", getattr(example, target_field))\n",
    "\n",
    "def generate_label_iterator(dataset, target, field_name, validation = True):\n",
    "    preprocess_target_label(target, validation)\n",
    "    \n",
    "    label_attr = f\"label_{target}\"\n",
    "    if validation:\n",
    "        iterators = data.BucketIterator.splits(\n",
    "            (dataset, valid_data, test_data),\n",
    "            batch_size = BATCH_SIZE,\n",
    "            device = device,\n",
    "            sort_key = lambda x: len(getattr(x, field_name)),\n",
    "            sort_within_batch = False)\n",
    "        return iterators[0], iterators[1], iterators[2]\n",
    "    else:\n",
    "        iterators = data.BucketIterator.splits(\n",
    "            (dataset, test_data),\n",
    "            batch_size = BATCH_SIZE,\n",
    "            device = device,\n",
    "            sort_key = lambda x: len(getattr(x, field_name)),\n",
    "            sort_within_batch = False)\n",
    "        return iterators[0], iterators[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "84e6d109",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run generate_label_iterator functions\n",
    "\n",
    "target_field = \"title\"\n",
    "train_iterator_IT, validation_IT, test_iterator_IT = generate_label_iterator(train_1000, \"InformationTheory\", target_field, validation = True)\n",
    "train_iterator_CL, validation_CL, test_iterator_CL = generate_label_iterator(train_1000, \"ComputationalLinguistics\", target_field, validation = True)\n",
    "train_iterator_CV, validation_CV, test_iterator_CV = generate_label_iterator(train_1000, \"ComputerVision\", target_field, validation = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2f6270d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define RNN\n",
    "\n",
    "\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_dim, embedding_dim, hidden_dim, output_dim, pos_weight = None):\n",
    "        \n",
    "        super(RNN, self).__init__()\n",
    "        \n",
    "        self.embedding = nn.Embedding(input_dim, embedding_dim)\n",
    "        \n",
    "        self.rnn = nn.RNN(embedding_dim, hidden_dim)\n",
    "        \n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "        \n",
    "        self.pos_weight = pos_weight\n",
    "\n",
    "        if self.pos_weight is not None:\n",
    "            self.criterion = nn.BCEWithLogitsLoss(pos_weight=self.pos_weight)\n",
    "        else:\n",
    "            self.criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "    def forward(self, text):\n",
    "\n",
    "        embedded = self.embedding(text)\n",
    "        \n",
    "        output, hidden = self.rnn(embedded)\n",
    "\n",
    "        assert torch.equal(output[-1,:,:], hidden.squeeze(0))\n",
    "        \n",
    "        return self.fc(hidden.squeeze(0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cef5d501",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize counts\n",
    "negative_IT_count, positive_IT_count = 0, 0\n",
    "negative_CL_count, positive_CL_count = 0, 0\n",
    "negative_CV_count, positive_CV_count = 0, 0\n",
    "\n",
    "# Iterate through the dataset\n",
    "for example in train_1000.examples:\n",
    "    if getattr(example, \"InformationTheory\") == 0:\n",
    "        negative_IT_count += 1\n",
    "    else:\n",
    "        positive_IT_count += 1\n",
    "\n",
    "    if getattr(example, \"ComputationalLinguistics\") == 0:\n",
    "        negative_CL_count += 1\n",
    "    else:\n",
    "        positive_CL_count += 1\n",
    "\n",
    "    if getattr(example, \"ComputerVision\") == 0:\n",
    "        negative_CV_count += 1\n",
    "    else:\n",
    "        positive_CV_count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b9c86eeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "439 461\n",
      "682 218\n",
      "679 221\n"
     ]
    }
   ],
   "source": [
    "print(negative_CV_count, positive_CV_count)\n",
    "print(negative_IT_count, positive_IT_count)\n",
    "print(negative_CL_count, positive_CL_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dc31133e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_weight_IT = torch.tensor([negative_IT_count / positive_IT_count])\n",
    "pos_weight_CL = torch.tensor([negative_CL_count / positive_CL_count])\n",
    "pos_weight_CV = torch.tensor([negative_CV_count / positive_CV_count])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "58863710",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model initialization & optimizer\n",
    "def generate_model_and_optimizer(pos_weight, embedding_dim=100, hidden_dim=256, output_dim=1, lr=1e-2):\n",
    "    INPUT_DIM = len(TEXT.vocab)\n",
    "\n",
    "    model = RNN(INPUT_DIM, embedding_dim, hidden_dim, output_dim, pos_weight)\n",
    "\n",
    "    optimizer = optim.SGD(model.parameters(), lr=lr)\n",
    "\n",
    "    model = model.to(device)\n",
    "    \n",
    "    return model, optimizer\n",
    "\n",
    "model_IT, optimizer_IT = generate_model_and_optimizer(pos_weight = pos_weight_IT)\n",
    "model_CL, optimizer_CL = generate_model_and_optimizer(pos_weight = pos_weight_CL)\n",
    "model_CV, optimizer_CV = generate_model_and_optimizer(pos_weight = pos_weight_CV)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4d5f2031",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation functions\n",
    "\n",
    "def binary_accuracy(preds, y):\n",
    "\n",
    "    #round predictions to the closest integer\n",
    "    rounded_preds = torch.round(torch.sigmoid(preds))\n",
    "    correct = (rounded_preds == y).float() #convert into float for division \n",
    "    acc = correct.sum() / len(correct)\n",
    "    return acc\n",
    "\n",
    "def train(model, iterator, optimizer, criterion, label_field, target_field):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    for batch in iterator:\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "                \n",
    "        predictions = model(getattr(batch, target_field)).squeeze(1)\n",
    "        \n",
    "        # Use the specific label field\n",
    "        loss = criterion(predictions, getattr(batch, label_field))\n",
    "        \n",
    "        acc = binary_accuracy(predictions, getattr(batch, label_field))\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)\n",
    "\n",
    "\n",
    "def evaluate(model, iterator, criterion, label_field, target_field):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "    \n",
    "        for batch in iterator:\n",
    "\n",
    "            predictions = model(getattr(batch, target_field)).squeeze(1)\n",
    "            \n",
    "            # Use the specific label field\n",
    "            loss = criterion(predictions, getattr(batch, label_field))\n",
    "            \n",
    "            acc = binary_accuracy(predictions, getattr(batch, label_field))\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)\n",
    "    \n",
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "acde9691",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(ModelsList, OptimizersList, IteratorsList, N_EPOCHS, label_names, target_field, modelFileNames, bestLossesList, preprocess, train_size, patience=5):\n",
    "    result = []\n",
    "    best_model_states = []\n",
    "    best_epochs = [0, 0, 0]\n",
    "    for idx, (label_name, model, optimizer, iterators_) in enumerate(zip(label_names, ModelsList, OptimizersList, IteratorsList)):\n",
    "        print(f\"Training model for {preprocess}_{label_name}, using {train_size} data of {target_field}...\")\n",
    "\n",
    "        bad_epochs = 0\n",
    "        best_model_state = None\n",
    "        best_epoch = 0\n",
    "\n",
    "        for epoch in range(N_EPOCHS):\n",
    "            start_time = time.time()\n",
    "\n",
    "            train_iterator = iterators_[0]\n",
    "            test_iterator = iterators_[2] if len(iterators_) > 2 else iterators_[1]\n",
    "            valid_iterator = iterators_[1] if len(iterators_) > 2 else None\n",
    "\n",
    "            train_loss, train_acc = train(model, train_iterator, optimizer, model.criterion, label_name, target_field)\n",
    "\n",
    "            if valid_iterator:\n",
    "                valid_loss, valid_acc = evaluate(model, valid_iterator, model.criterion, label_name, target_field)\n",
    "\n",
    "            test_loss, test_acc = evaluate(model, test_iterator, model.criterion, label_name, target_field)\n",
    "\n",
    "            end_time = time.time()\n",
    "            epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "\n",
    "            if test_loss < bestLossesList[idx]:\n",
    "                bestLossesList[idx] = test_loss\n",
    "                best_model_state = copy.deepcopy(model.state_dict())\n",
    "#                 best_model_state = model.state_dict()\n",
    "                bad_epochs = 0\n",
    "                best_epochs[idx] = epoch + 1\n",
    "\n",
    "            else:\n",
    "                bad_epochs += 1\n",
    "\n",
    "            print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
    "            print(f'{label_name} Train Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
    "\n",
    "            if valid_iterator:\n",
    "                print(f'{label_name} Valid Loss: {valid_loss:.3f} | Valid Acc: {valid_acc*100:.2f}%')\n",
    "\n",
    "            print(f'{label_name} Test Loss: {test_loss:.3f} | Test Acc: {test_acc*100:.2f}%')\n",
    "\n",
    "            if bad_epochs > patience:\n",
    "                print(f\"Early stopping at epoch {epoch+1} for {label_name} model.\")\n",
    "#                 model.load_state_dict(best_model_state)\n",
    "                print(f\"Best performing epoch for {label_name} model: {best_epochs[idx]}\")\n",
    "\n",
    "                break\n",
    "\n",
    "            # For predictions and ground truth collection\n",
    "            model.eval()\n",
    "            y_predict, y_test = [], []\n",
    "            with torch.no_grad():\n",
    "                for batch in test_iterator:\n",
    "                    predictions = model(getattr(batch, target_field)).squeeze(1)\n",
    "                    rounded_preds = torch.round(torch.sigmoid(predictions))\n",
    "                    y_predict += rounded_preds.tolist()\n",
    "                    y_test += getattr(batch, label_name).tolist()\n",
    "        \n",
    "        best_model_states.append(best_model_state)\n",
    "\n",
    "        result.append((y_predict, y_test))\n",
    "        \n",
    "    return result, best_model_states\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e254cc6a",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# def train_loop(ModelsList, OptimizersList, IteratorsList, N_EPOCHS, label_names, target_field, modelFileNames, bestLossesList, preprocess, train_size, patience=5):\n",
    "#     result = []\n",
    "#     for idx, (label_name, model, optimizer, iterators_) in enumerate(zip(label_names, ModelsList, OptimizersList, IteratorsList)):\n",
    "#         print(f\"Training model for {preprocess}_{label_name}, using {train_size} data of {target_field}...\")\n",
    "\n",
    "#         bad_epochs = 0\n",
    "#         best_model_state = None\n",
    "#         best_epoch = 1\n",
    "\n",
    "#         for epoch in range(N_EPOCHS):\n",
    "#             start_time = time.time()\n",
    "\n",
    "#             train_iterator = iterators_[0]\n",
    "#             test_iterator = iterators_[2] if len(iterators_) > 2 else iterators_[1]\n",
    "#             valid_iterator = iterators_[1] if len(iterators_) > 2 else None\n",
    "\n",
    "#             train_loss, train_acc = train(model, train_iterator, optimizer, model.criterion, label_name, target_field)\n",
    "\n",
    "#             if valid_iterator:\n",
    "#                 valid_loss, valid_acc = evaluate(model, valid_iterator, model.criterion, label_name, target_field)\n",
    "\n",
    "#             test_loss, test_acc = evaluate(model, test_iterator, model.criterion, label_name, target_field)\n",
    "\n",
    "#             end_time = time.time()\n",
    "#             epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "\n",
    "#             if test_loss < bestLossesList[idx]:\n",
    "#                 bestLossesList[idx] = test_loss\n",
    "#                 best_model_state = model.state_dict()\n",
    "#                 best_epoch = epoch + 1\n",
    "#                 bad_epochs = 0\n",
    "#             else:\n",
    "#                 bad_epochs += 1\n",
    "\n",
    "#             print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
    "#             print(f'{label_name} Train Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
    "\n",
    "#             if valid_iterator:\n",
    "#                 print(f'{label_name} Valid Loss: {valid_loss:.3f} | Valid Acc: {valid_acc*100:.2f}%')\n",
    "\n",
    "#             print(f'{label_name} Test Loss: {test_loss:.3f} | Test Acc: {test_acc*100:.2f}%')\n",
    "\n",
    "#             if bad_epochs > patience:\n",
    "#                 print(f\"Early stopping at epoch {epoch+1} for {label_name} model.\")\n",
    "                \n",
    "#                 model = model.load_state_dict(best_model_state)\n",
    "                \n",
    "#                 print(f\"Best performing epoch for {label_name} model: {best_epoch}\")\n",
    "\n",
    "#                 break\n",
    "\n",
    "#             # For predictions and ground truth collection\n",
    "#             model.eval()\n",
    "#             y_predict, y_test = [], []\n",
    "#             with torch.no_grad():\n",
    "#                 for batch in test_iterator:\n",
    "#                     predictions = model(getattr(batch, target_field)).squeeze(1)\n",
    "#                     rounded_preds = torch.round(torch.sigmoid(predictions))\n",
    "#                     y_predict += rounded_preds.tolist()\n",
    "#                     y_test += getattr(batch, label_name).tolist()\n",
    "                    \n",
    "#         result.append((y_predict, y_test))\n",
    "#     return result\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6e08004e",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_EPOCHS = 50\n",
    "label_names = [\"InformationTheory\", \"ComputationalLinguistics\", \"ComputerVision\"]\n",
    "models = [model_IT, model_CL, model_CV]\n",
    "optimizers = [optimizer_IT, optimizer_CL, optimizer_CV]\n",
    "iterators = [(train_iterator_IT, validation_IT, test_iterator_IT), (train_iterator_CL, validation_CL, test_iterator_CL), (train_iterator_CV, validation_CV, test_iterator_CV)]\n",
    "model_file_names = [\"RNN_model_IT_T_P1_1000\", \"RNN_model_CL_T_P1_1000.pt\", \"RNN_model_CV_T_P1_1000.pt\"]\n",
    "best_valid_losses = [float(\"inf\"), float(\"inf\"), float(\"inf\")]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fb1f64f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for P1_InformationTheory, using 1000 data of title...\n",
      "Epoch: 01 | Epoch Time: 0m 2s\n",
      "InformationTheory Train Loss: 1.059 | Train Acc: 31.35%\n",
      "InformationTheory Valid Loss: 1.052 | Valid Acc: 58.21%\n",
      "InformationTheory Test Loss: 1.426 | Test Acc: 52.49%\n",
      "Epoch: 02 | Epoch Time: 0m 0s\n",
      "InformationTheory Train Loss: 1.029 | Train Acc: 54.17%\n",
      "InformationTheory Valid Loss: 1.051 | Valid Acc: 59.28%\n",
      "InformationTheory Test Loss: 1.427 | Test Acc: 52.69%\n",
      "Epoch: 03 | Epoch Time: 0m 0s\n",
      "InformationTheory Train Loss: 1.055 | Train Acc: 38.12%\n",
      "InformationTheory Valid Loss: 1.051 | Valid Acc: 62.11%\n",
      "InformationTheory Test Loss: 1.434 | Test Acc: 52.94%\n",
      "Epoch: 04 | Epoch Time: 0m 0s\n",
      "InformationTheory Train Loss: 1.039 | Train Acc: 63.65%\n",
      "InformationTheory Valid Loss: 1.051 | Valid Acc: 61.02%\n",
      "InformationTheory Test Loss: 1.434 | Test Acc: 53.10%\n",
      "Epoch: 05 | Epoch Time: 0m 0s\n",
      "InformationTheory Train Loss: 1.035 | Train Acc: 58.65%\n",
      "InformationTheory Valid Loss: 1.051 | Valid Acc: 61.91%\n",
      "InformationTheory Test Loss: 1.437 | Test Acc: 53.31%\n",
      "Epoch: 06 | Epoch Time: 0m 0s\n",
      "InformationTheory Train Loss: 1.051 | Train Acc: 49.69%\n",
      "InformationTheory Valid Loss: 1.047 | Valid Acc: 63.00%\n",
      "InformationTheory Test Loss: 1.427 | Test Acc: 54.30%\n",
      "Epoch: 07 | Epoch Time: 0m 0s\n",
      "InformationTheory Train Loss: 1.084 | Train Acc: 50.21%\n",
      "InformationTheory Valid Loss: 1.047 | Valid Acc: 63.42%\n",
      "InformationTheory Test Loss: 1.431 | Test Acc: 54.59%\n",
      "Epoch: 08 | Epoch Time: 0m 0s\n",
      "InformationTheory Train Loss: 1.035 | Train Acc: 56.15%\n",
      "InformationTheory Valid Loss: 1.045 | Valid Acc: 65.44%\n",
      "InformationTheory Test Loss: 1.432 | Test Acc: 54.90%\n",
      "Epoch: 09 | Epoch Time: 0m 0s\n",
      "InformationTheory Train Loss: 1.048 | Train Acc: 53.33%\n",
      "InformationTheory Valid Loss: 1.043 | Valid Acc: 63.32%\n",
      "InformationTheory Test Loss: 1.415 | Test Acc: 55.18%\n",
      "Epoch: 10 | Epoch Time: 0m 0s\n",
      "InformationTheory Train Loss: 1.033 | Train Acc: 59.90%\n",
      "InformationTheory Valid Loss: 1.042 | Valid Acc: 65.01%\n",
      "InformationTheory Test Loss: 1.419 | Test Acc: 55.55%\n",
      "Epoch: 11 | Epoch Time: 0m 0s\n",
      "InformationTheory Train Loss: 1.105 | Train Acc: 43.44%\n",
      "InformationTheory Valid Loss: 1.048 | Valid Acc: 59.99%\n",
      "InformationTheory Test Loss: 1.410 | Test Acc: 54.60%\n",
      "Epoch: 12 | Epoch Time: 0m 0s\n",
      "InformationTheory Train Loss: 1.069 | Train Acc: 35.10%\n",
      "InformationTheory Valid Loss: 1.041 | Valid Acc: 65.68%\n",
      "InformationTheory Test Loss: 1.421 | Test Acc: 55.85%\n",
      "Epoch: 13 | Epoch Time: 0m 0s\n",
      "InformationTheory Train Loss: 1.051 | Train Acc: 49.17%\n",
      "InformationTheory Valid Loss: 1.041 | Valid Acc: 64.48%\n",
      "InformationTheory Test Loss: 1.419 | Test Acc: 55.73%\n",
      "Epoch: 14 | Epoch Time: 0m 0s\n",
      "InformationTheory Train Loss: 1.083 | Train Acc: 41.15%\n",
      "InformationTheory Valid Loss: 1.042 | Valid Acc: 61.63%\n",
      "InformationTheory Test Loss: 1.415 | Test Acc: 55.12%\n",
      "Epoch: 15 | Epoch Time: 0m 0s\n",
      "InformationTheory Train Loss: 1.077 | Train Acc: 38.75%\n",
      "InformationTheory Valid Loss: 1.041 | Valid Acc: 66.20%\n",
      "InformationTheory Test Loss: 1.426 | Test Acc: 55.79%\n",
      "Epoch: 16 | Epoch Time: 0m 0s\n",
      "InformationTheory Train Loss: 1.050 | Train Acc: 46.88%\n",
      "InformationTheory Valid Loss: 1.041 | Valid Acc: 65.96%\n",
      "InformationTheory Test Loss: 1.427 | Test Acc: 56.04%\n",
      "Epoch: 17 | Epoch Time: 0m 0s\n",
      "InformationTheory Train Loss: 1.029 | Train Acc: 49.58%\n",
      "InformationTheory Valid Loss: 1.041 | Valid Acc: 67.14%\n",
      "InformationTheory Test Loss: 1.429 | Test Acc: 56.17%\n",
      "Epoch: 18 | Epoch Time: 0m 0s\n",
      "InformationTheory Train Loss: 1.049 | Train Acc: 47.19%\n",
      "InformationTheory Valid Loss: 1.040 | Valid Acc: 66.69%\n",
      "InformationTheory Test Loss: 1.428 | Test Acc: 56.26%\n",
      "Epoch: 19 | Epoch Time: 0m 0s\n",
      "InformationTheory Train Loss: 1.056 | Train Acc: 46.56%\n",
      "InformationTheory Valid Loss: 1.039 | Valid Acc: 66.68%\n",
      "InformationTheory Test Loss: 1.422 | Test Acc: 55.98%\n",
      "Epoch: 20 | Epoch Time: 0m 0s\n",
      "InformationTheory Train Loss: 1.077 | Train Acc: 40.94%\n",
      "InformationTheory Valid Loss: 1.037 | Valid Acc: 65.79%\n",
      "InformationTheory Test Loss: 1.414 | Test Acc: 56.25%\n",
      "Epoch: 21 | Epoch Time: 0m 0s\n",
      "InformationTheory Train Loss: 1.058 | Train Acc: 56.46%\n",
      "InformationTheory Valid Loss: 1.036 | Valid Acc: 64.86%\n",
      "InformationTheory Test Loss: 1.406 | Test Acc: 55.96%\n",
      "Epoch: 22 | Epoch Time: 0m 0s\n",
      "InformationTheory Train Loss: 1.061 | Train Acc: 60.83%\n",
      "InformationTheory Valid Loss: 1.034 | Valid Acc: 63.59%\n",
      "InformationTheory Test Loss: 1.395 | Test Acc: 56.14%\n",
      "Epoch: 23 | Epoch Time: 0m 0s\n",
      "InformationTheory Train Loss: 1.100 | Train Acc: 49.58%\n",
      "InformationTheory Valid Loss: 1.033 | Valid Acc: 61.77%\n",
      "InformationTheory Test Loss: 1.386 | Test Acc: 56.29%\n",
      "Epoch: 24 | Epoch Time: 0m 0s\n",
      "InformationTheory Train Loss: 1.030 | Train Acc: 40.00%\n",
      "InformationTheory Valid Loss: 1.034 | Valid Acc: 63.54%\n",
      "InformationTheory Test Loss: 1.394 | Test Acc: 56.25%\n",
      "Epoch: 25 | Epoch Time: 0m 0s\n",
      "InformationTheory Train Loss: 1.081 | Train Acc: 42.19%\n",
      "InformationTheory Valid Loss: 1.031 | Valid Acc: 62.73%\n",
      "InformationTheory Test Loss: 1.387 | Test Acc: 56.43%\n",
      "Epoch: 26 | Epoch Time: 0m 0s\n",
      "InformationTheory Train Loss: 1.071 | Train Acc: 52.92%\n",
      "InformationTheory Valid Loss: 1.030 | Valid Acc: 60.85%\n",
      "InformationTheory Test Loss: 1.379 | Test Acc: 56.83%\n",
      "Epoch: 27 | Epoch Time: 0m 0s\n",
      "InformationTheory Train Loss: 1.032 | Train Acc: 50.73%\n",
      "InformationTheory Valid Loss: 1.030 | Valid Acc: 61.99%\n",
      "InformationTheory Test Loss: 1.383 | Test Acc: 56.50%\n",
      "Epoch: 28 | Epoch Time: 0m 0s\n",
      "InformationTheory Train Loss: 1.030 | Train Acc: 58.85%\n",
      "InformationTheory Valid Loss: 1.029 | Valid Acc: 61.47%\n",
      "InformationTheory Test Loss: 1.382 | Test Acc: 56.71%\n",
      "Epoch: 29 | Epoch Time: 0m 0s\n",
      "InformationTheory Train Loss: 1.048 | Train Acc: 48.96%\n",
      "InformationTheory Valid Loss: 1.029 | Valid Acc: 62.39%\n",
      "InformationTheory Test Loss: 1.387 | Test Acc: 56.65%\n",
      "Epoch: 30 | Epoch Time: 0m 0s\n",
      "InformationTheory Train Loss: 1.028 | Train Acc: 53.33%\n",
      "InformationTheory Valid Loss: 1.029 | Valid Acc: 62.81%\n",
      "InformationTheory Test Loss: 1.388 | Test Acc: 56.68%\n",
      "Epoch: 31 | Epoch Time: 0m 0s\n",
      "InformationTheory Train Loss: 1.023 | Train Acc: 55.62%\n",
      "InformationTheory Valid Loss: 1.029 | Valid Acc: 63.15%\n",
      "InformationTheory Test Loss: 1.389 | Test Acc: 56.91%\n",
      "Epoch: 32 | Epoch Time: 0m 0s\n",
      "InformationTheory Train Loss: 1.026 | Train Acc: 56.88%\n",
      "InformationTheory Valid Loss: 1.028 | Valid Acc: 64.06%\n",
      "InformationTheory Test Loss: 1.392 | Test Acc: 56.95%\n",
      "Epoch: 33 | Epoch Time: 0m 0s\n",
      "InformationTheory Train Loss: 1.047 | Train Acc: 55.62%\n",
      "InformationTheory Valid Loss: 1.027 | Valid Acc: 63.29%\n",
      "InformationTheory Test Loss: 1.388 | Test Acc: 57.27%\n",
      "Epoch: 34 | Epoch Time: 0m 0s\n",
      "InformationTheory Train Loss: 1.078 | Train Acc: 44.17%\n",
      "InformationTheory Valid Loss: 1.027 | Valid Acc: 63.40%\n",
      "InformationTheory Test Loss: 1.389 | Test Acc: 57.35%\n",
      "Epoch: 35 | Epoch Time: 0m 0s\n",
      "InformationTheory Train Loss: 1.053 | Train Acc: 41.25%\n",
      "InformationTheory Valid Loss: 1.027 | Valid Acc: 64.19%\n",
      "InformationTheory Test Loss: 1.393 | Test Acc: 57.29%\n",
      "Epoch: 36 | Epoch Time: 0m 0s\n",
      "InformationTheory Train Loss: 1.047 | Train Acc: 40.10%\n",
      "InformationTheory Valid Loss: 1.028 | Valid Acc: 65.20%\n",
      "InformationTheory Test Loss: 1.398 | Test Acc: 57.36%\n",
      "Epoch: 37 | Epoch Time: 0m 0s\n",
      "InformationTheory Train Loss: 1.053 | Train Acc: 51.67%\n",
      "InformationTheory Valid Loss: 1.027 | Valid Acc: 65.00%\n",
      "InformationTheory Test Loss: 1.397 | Test Acc: 57.52%\n",
      "Early stopping at epoch 37 for InformationTheory model.\n",
      "Best performing epoch for InformationTheory model: 26\n",
      "Training model for P1_ComputationalLinguistics, using 1000 data of title...\n",
      "Epoch: 01 | Epoch Time: 0m 0s\n",
      "ComputationalLinguistics Train Loss: 1.033 | Train Acc: 61.98%\n",
      "ComputationalLinguistics Valid Loss: 1.046 | Valid Acc: 61.95%\n",
      "ComputationalLinguistics Test Loss: 0.957 | Test Acc: 63.15%\n",
      "Epoch: 02 | Epoch Time: 0m 0s\n",
      "ComputationalLinguistics Train Loss: 1.046 | Train Acc: 51.88%\n",
      "ComputationalLinguistics Valid Loss: 1.045 | Valid Acc: 60.90%\n",
      "ComputationalLinguistics Test Loss: 0.957 | Test Acc: 62.39%\n",
      "Epoch: 03 | Epoch Time: 0m 0s\n",
      "ComputationalLinguistics Train Loss: 1.080 | Train Acc: 40.52%\n",
      "ComputationalLinguistics Valid Loss: 1.045 | Valid Acc: 60.51%\n",
      "ComputationalLinguistics Test Loss: 0.957 | Test Acc: 62.49%\n",
      "Epoch: 04 | Epoch Time: 0m 0s\n",
      "ComputationalLinguistics Train Loss: 1.027 | Train Acc: 46.46%\n",
      "ComputationalLinguistics Valid Loss: 1.046 | Valid Acc: 62.83%\n",
      "ComputationalLinguistics Test Loss: 0.956 | Test Acc: 63.92%\n",
      "Epoch: 05 | Epoch Time: 0m 0s\n",
      "ComputationalLinguistics Train Loss: 1.113 | Train Acc: 37.50%\n",
      "ComputationalLinguistics Valid Loss: 1.044 | Valid Acc: 60.51%\n",
      "ComputationalLinguistics Test Loss: 0.958 | Test Acc: 61.59%\n",
      "Epoch: 06 | Epoch Time: 0m 0s\n",
      "ComputationalLinguistics Train Loss: 1.055 | Train Acc: 43.02%\n",
      "ComputationalLinguistics Valid Loss: 1.043 | Valid Acc: 59.61%\n",
      "ComputationalLinguistics Test Loss: 0.957 | Test Acc: 61.44%\n",
      "Epoch: 07 | Epoch Time: 0m 0s\n",
      "ComputationalLinguistics Train Loss: 1.033 | Train Acc: 41.67%\n",
      "ComputationalLinguistics Valid Loss: 1.044 | Valid Acc: 62.32%\n",
      "ComputationalLinguistics Test Loss: 0.956 | Test Acc: 63.13%\n",
      "Epoch: 08 | Epoch Time: 0m 0s\n",
      "ComputationalLinguistics Train Loss: 1.050 | Train Acc: 57.60%\n",
      "ComputationalLinguistics Valid Loss: 1.043 | Valid Acc: 60.66%\n",
      "ComputationalLinguistics Test Loss: 0.955 | Test Acc: 62.93%\n",
      "Epoch: 09 | Epoch Time: 0m 0s\n",
      "ComputationalLinguistics Train Loss: 1.044 | Train Acc: 35.10%\n",
      "ComputationalLinguistics Valid Loss: 1.043 | Valid Acc: 62.58%\n",
      "ComputationalLinguistics Test Loss: 0.954 | Test Acc: 64.35%\n",
      "Epoch: 10 | Epoch Time: 0m 0s\n",
      "ComputationalLinguistics Train Loss: 1.102 | Train Acc: 52.19%\n",
      "ComputationalLinguistics Valid Loss: 1.043 | Valid Acc: 60.16%\n",
      "ComputationalLinguistics Test Loss: 0.956 | Test Acc: 62.36%\n",
      "Epoch: 11 | Epoch Time: 0m 0s\n",
      "ComputationalLinguistics Train Loss: 1.029 | Train Acc: 34.06%\n",
      "ComputationalLinguistics Valid Loss: 1.044 | Valid Acc: 62.99%\n",
      "ComputationalLinguistics Test Loss: 0.955 | Test Acc: 64.11%\n",
      "Epoch: 12 | Epoch Time: 0m 0s\n",
      "ComputationalLinguistics Train Loss: 1.044 | Train Acc: 67.92%\n",
      "ComputationalLinguistics Valid Loss: 1.043 | Valid Acc: 61.38%\n",
      "ComputationalLinguistics Test Loss: 0.955 | Test Acc: 63.22%\n",
      "Epoch: 13 | Epoch Time: 0m 0s\n",
      "ComputationalLinguistics Train Loss: 1.101 | Train Acc: 45.83%\n",
      "ComputationalLinguistics Valid Loss: 1.043 | Valid Acc: 59.50%\n",
      "ComputationalLinguistics Test Loss: 0.957 | Test Acc: 61.43%\n",
      "Epoch: 14 | Epoch Time: 0m 0s\n",
      "ComputationalLinguistics Train Loss: 1.047 | Train Acc: 43.44%\n",
      "ComputationalLinguistics Valid Loss: 1.043 | Valid Acc: 59.75%\n",
      "ComputationalLinguistics Test Loss: 0.956 | Test Acc: 61.98%\n",
      "Epoch: 15 | Epoch Time: 0m 0s\n",
      "ComputationalLinguistics Train Loss: 1.037 | Train Acc: 42.71%\n",
      "ComputationalLinguistics Valid Loss: 1.043 | Valid Acc: 58.96%\n",
      "ComputationalLinguistics Test Loss: 0.957 | Test Acc: 61.32%\n",
      "Epoch: 16 | Epoch Time: 0m 0s\n",
      "ComputationalLinguistics Train Loss: 1.046 | Train Acc: 40.62%\n",
      "ComputationalLinguistics Valid Loss: 1.043 | Valid Acc: 59.34%\n",
      "ComputationalLinguistics Test Loss: 0.956 | Test Acc: 61.50%\n",
      "Epoch: 17 | Epoch Time: 0m 0s\n",
      "ComputationalLinguistics Train Loss: 1.027 | Train Acc: 48.96%\n",
      "ComputationalLinguistics Valid Loss: 1.043 | Valid Acc: 60.38%\n",
      "ComputationalLinguistics Test Loss: 0.956 | Test Acc: 62.31%\n",
      "Epoch: 18 | Epoch Time: 0m 0s\n",
      "ComputationalLinguistics Train Loss: 1.023 | Train Acc: 59.48%\n",
      "ComputationalLinguistics Valid Loss: 1.043 | Valid Acc: 60.35%\n",
      "ComputationalLinguistics Test Loss: 0.955 | Test Acc: 62.45%\n",
      "Epoch: 19 | Epoch Time: 0m 0s\n",
      "ComputationalLinguistics Train Loss: 1.025 | Train Acc: 53.75%\n",
      "ComputationalLinguistics Valid Loss: 1.043 | Valid Acc: 61.09%\n",
      "ComputationalLinguistics Test Loss: 0.954 | Test Acc: 63.20%\n",
      "Epoch: 20 | Epoch Time: 0m 0s\n",
      "ComputationalLinguistics Train Loss: 1.030 | Train Acc: 61.77%\n",
      "ComputationalLinguistics Valid Loss: 1.043 | Valid Acc: 61.28%\n",
      "ComputationalLinguistics Test Loss: 0.954 | Test Acc: 63.63%\n",
      "Epoch: 21 | Epoch Time: 0m 0s\n",
      "ComputationalLinguistics Train Loss: 1.074 | Train Acc: 38.02%\n",
      "ComputationalLinguistics Valid Loss: 1.043 | Valid Acc: 61.53%\n",
      "ComputationalLinguistics Test Loss: 0.953 | Test Acc: 64.02%\n",
      "Epoch: 22 | Epoch Time: 0m 0s\n",
      "ComputationalLinguistics Train Loss: 1.026 | Train Acc: 54.17%\n",
      "ComputationalLinguistics Valid Loss: 1.043 | Valid Acc: 62.40%\n",
      "ComputationalLinguistics Test Loss: 0.953 | Test Acc: 65.02%\n",
      "Epoch: 23 | Epoch Time: 0m 0s\n",
      "ComputationalLinguistics Train Loss: 1.052 | Train Acc: 42.60%\n",
      "ComputationalLinguistics Valid Loss: 1.043 | Valid Acc: 61.73%\n",
      "ComputationalLinguistics Test Loss: 0.953 | Test Acc: 64.12%\n",
      "Epoch: 24 | Epoch Time: 0m 0s\n",
      "ComputationalLinguistics Train Loss: 1.025 | Train Acc: 56.04%\n",
      "ComputationalLinguistics Valid Loss: 1.043 | Valid Acc: 62.30%\n",
      "ComputationalLinguistics Test Loss: 0.952 | Test Acc: 64.72%\n",
      "Epoch: 25 | Epoch Time: 0m 0s\n",
      "ComputationalLinguistics Train Loss: 1.023 | Train Acc: 66.04%\n",
      "ComputationalLinguistics Valid Loss: 1.043 | Valid Acc: 62.13%\n",
      "ComputationalLinguistics Test Loss: 0.952 | Test Acc: 64.92%\n",
      "Epoch: 26 | Epoch Time: 0m 0s\n",
      "ComputationalLinguistics Train Loss: 1.037 | Train Acc: 46.04%\n",
      "ComputationalLinguistics Valid Loss: 1.044 | Valid Acc: 61.84%\n",
      "ComputationalLinguistics Test Loss: 0.952 | Test Acc: 64.79%\n",
      "Epoch: 27 | Epoch Time: 0m 0s\n",
      "ComputationalLinguistics Train Loss: 1.045 | Train Acc: 46.15%\n",
      "ComputationalLinguistics Valid Loss: 1.044 | Valid Acc: 62.22%\n",
      "ComputationalLinguistics Test Loss: 0.952 | Test Acc: 65.47%\n",
      "Epoch: 28 | Epoch Time: 0m 0s\n",
      "ComputationalLinguistics Train Loss: 1.048 | Train Acc: 36.56%\n",
      "ComputationalLinguistics Valid Loss: 1.044 | Valid Acc: 63.20%\n",
      "ComputationalLinguistics Test Loss: 0.950 | Test Acc: 66.55%\n",
      "Epoch: 29 | Epoch Time: 0m 0s\n",
      "ComputationalLinguistics Train Loss: 1.048 | Train Acc: 33.54%\n",
      "ComputationalLinguistics Valid Loss: 1.044 | Valid Acc: 64.14%\n",
      "ComputationalLinguistics Test Loss: 0.949 | Test Acc: 67.29%\n",
      "Epoch: 30 | Epoch Time: 0m 0s\n",
      "ComputationalLinguistics Train Loss: 1.023 | Train Acc: 62.40%\n",
      "ComputationalLinguistics Valid Loss: 1.044 | Valid Acc: 64.62%\n",
      "ComputationalLinguistics Test Loss: 0.949 | Test Acc: 67.93%\n",
      "Epoch: 31 | Epoch Time: 0m 0s\n",
      "ComputationalLinguistics Train Loss: 1.046 | Train Acc: 65.00%\n",
      "ComputationalLinguistics Valid Loss: 1.043 | Valid Acc: 63.47%\n",
      "ComputationalLinguistics Test Loss: 0.949 | Test Acc: 66.92%\n",
      "Epoch: 32 | Epoch Time: 0m 0s\n",
      "ComputationalLinguistics Train Loss: 1.034 | Train Acc: 46.04%\n",
      "ComputationalLinguistics Valid Loss: 1.043 | Valid Acc: 64.54%\n",
      "ComputationalLinguistics Test Loss: 0.949 | Test Acc: 67.05%\n",
      "Epoch: 33 | Epoch Time: 0m 0s\n",
      "ComputationalLinguistics Train Loss: 1.063 | Train Acc: 50.83%\n",
      "ComputationalLinguistics Valid Loss: 1.043 | Valid Acc: 62.42%\n",
      "ComputationalLinguistics Test Loss: 0.950 | Test Acc: 65.64%\n",
      "Epoch: 34 | Epoch Time: 0m 0s\n",
      "ComputationalLinguistics Train Loss: 1.050 | Train Acc: 33.96%\n",
      "ComputationalLinguistics Valid Loss: 1.043 | Valid Acc: 63.38%\n",
      "ComputationalLinguistics Test Loss: 0.949 | Test Acc: 66.49%\n",
      "Epoch: 35 | Epoch Time: 0m 0s\n",
      "ComputationalLinguistics Train Loss: 1.024 | Train Acc: 47.92%\n",
      "ComputationalLinguistics Valid Loss: 1.043 | Valid Acc: 65.27%\n",
      "ComputationalLinguistics Test Loss: 0.948 | Test Acc: 68.01%\n",
      "Epoch: 36 | Epoch Time: 0m 0s\n",
      "ComputationalLinguistics Train Loss: 1.024 | Train Acc: 73.12%\n",
      "ComputationalLinguistics Valid Loss: 1.044 | Valid Acc: 64.11%\n",
      "ComputationalLinguistics Test Loss: 0.948 | Test Acc: 68.31%\n",
      "Epoch: 37 | Epoch Time: 0m 0s\n",
      "ComputationalLinguistics Train Loss: 1.027 | Train Acc: 52.81%\n",
      "ComputationalLinguistics Valid Loss: 1.044 | Valid Acc: 66.07%\n",
      "ComputationalLinguistics Test Loss: 0.947 | Test Acc: 69.50%\n",
      "Epoch: 38 | Epoch Time: 0m 0s\n",
      "ComputationalLinguistics Train Loss: 1.044 | Train Acc: 40.42%\n",
      "ComputationalLinguistics Valid Loss: 1.044 | Valid Acc: 66.63%\n",
      "ComputationalLinguistics Test Loss: 0.947 | Test Acc: 69.73%\n",
      "Epoch: 39 | Epoch Time: 0m 0s\n",
      "ComputationalLinguistics Train Loss: 1.026 | Train Acc: 46.98%\n",
      "ComputationalLinguistics Valid Loss: 1.045 | Valid Acc: 67.39%\n",
      "ComputationalLinguistics Test Loss: 0.947 | Test Acc: 70.45%\n",
      "Epoch: 40 | Epoch Time: 0m 0s\n",
      "ComputationalLinguistics Train Loss: 1.042 | Train Acc: 42.08%\n",
      "ComputationalLinguistics Valid Loss: 1.045 | Valid Acc: 67.43%\n",
      "ComputationalLinguistics Test Loss: 0.946 | Test Acc: 70.66%\n",
      "Epoch: 41 | Epoch Time: 0m 0s\n",
      "ComputationalLinguistics Train Loss: 1.025 | Train Acc: 67.19%\n",
      "ComputationalLinguistics Valid Loss: 1.045 | Valid Acc: 68.02%\n",
      "ComputationalLinguistics Test Loss: 0.946 | Test Acc: 71.37%\n",
      "Epoch: 42 | Epoch Time: 0m 0s\n",
      "ComputationalLinguistics Train Loss: 1.045 | Train Acc: 49.27%\n",
      "ComputationalLinguistics Valid Loss: 1.046 | Valid Acc: 67.60%\n",
      "ComputationalLinguistics Test Loss: 0.945 | Test Acc: 71.04%\n",
      "Epoch: 43 | Epoch Time: 0m 0s\n",
      "ComputationalLinguistics Train Loss: 1.046 | Train Acc: 36.98%\n",
      "ComputationalLinguistics Valid Loss: 1.046 | Valid Acc: 68.35%\n",
      "ComputationalLinguistics Test Loss: 0.945 | Test Acc: 71.99%\n",
      "Epoch: 44 | Epoch Time: 0m 0s\n",
      "ComputationalLinguistics Train Loss: 1.074 | Train Acc: 46.77%\n",
      "ComputationalLinguistics Valid Loss: 1.046 | Valid Acc: 67.22%\n",
      "ComputationalLinguistics Test Loss: 0.946 | Test Acc: 70.76%\n",
      "Epoch: 45 | Epoch Time: 0m 0s\n",
      "ComputationalLinguistics Train Loss: 1.022 | Train Acc: 55.31%\n",
      "ComputationalLinguistics Valid Loss: 1.047 | Valid Acc: 68.48%\n",
      "ComputationalLinguistics Test Loss: 0.945 | Test Acc: 71.76%\n",
      "Epoch: 46 | Epoch Time: 0m 0s\n",
      "ComputationalLinguistics Train Loss: 1.089 | Train Acc: 56.15%\n",
      "ComputationalLinguistics Valid Loss: 1.045 | Valid Acc: 65.48%\n",
      "ComputationalLinguistics Test Loss: 0.946 | Test Acc: 69.03%\n",
      "Epoch: 47 | Epoch Time: 0m 0s\n",
      "ComputationalLinguistics Train Loss: 1.045 | Train Acc: 49.48%\n",
      "ComputationalLinguistics Valid Loss: 1.045 | Valid Acc: 65.22%\n",
      "ComputationalLinguistics Test Loss: 0.946 | Test Acc: 68.91%\n",
      "Epoch: 48 | Epoch Time: 0m 0s\n",
      "ComputationalLinguistics Train Loss: 1.041 | Train Acc: 38.02%\n",
      "ComputationalLinguistics Valid Loss: 1.046 | Valid Acc: 67.32%\n",
      "ComputationalLinguistics Test Loss: 0.946 | Test Acc: 70.42%\n",
      "Epoch: 49 | Epoch Time: 0m 0s\n",
      "ComputationalLinguistics Train Loss: 1.074 | Train Acc: 41.46%\n",
      "ComputationalLinguistics Valid Loss: 1.046 | Valid Acc: 66.64%\n",
      "ComputationalLinguistics Test Loss: 0.946 | Test Acc: 70.15%\n",
      "Epoch: 50 | Epoch Time: 0m 0s\n",
      "ComputationalLinguistics Train Loss: 1.047 | Train Acc: 59.38%\n",
      "ComputationalLinguistics Valid Loss: 1.047 | Valid Acc: 65.05%\n",
      "ComputationalLinguistics Test Loss: 0.946 | Test Acc: 69.09%\n",
      "Training model for P1_ComputerVision, using 1000 data of title...\n",
      "Epoch: 01 | Epoch Time: 0m 0s\n",
      "ComputerVision Train Loss: 0.681 | Train Acc: 45.62%\n",
      "ComputerVision Valid Loss: 0.678 | Valid Acc: 51.12%\n",
      "ComputerVision Test Loss: 0.658 | Test Acc: 58.17%\n",
      "Epoch: 02 | Epoch Time: 0m 0s\n",
      "ComputerVision Train Loss: 0.679 | Train Acc: 48.96%\n",
      "ComputerVision Valid Loss: 0.678 | Valid Acc: 51.33%\n",
      "ComputerVision Test Loss: 0.658 | Test Acc: 57.95%\n",
      "Epoch: 03 | Epoch Time: 0m 0s\n",
      "ComputerVision Train Loss: 0.680 | Train Acc: 46.46%\n",
      "ComputerVision Valid Loss: 0.678 | Valid Acc: 51.28%\n",
      "ComputerVision Test Loss: 0.658 | Test Acc: 57.86%\n",
      "Epoch: 04 | Epoch Time: 0m 0s\n",
      "ComputerVision Train Loss: 0.677 | Train Acc: 48.54%\n",
      "ComputerVision Valid Loss: 0.677 | Valid Acc: 51.86%\n",
      "ComputerVision Test Loss: 0.660 | Test Acc: 57.53%\n",
      "Epoch: 05 | Epoch Time: 0m 0s\n",
      "ComputerVision Train Loss: 0.678 | Train Acc: 48.85%\n",
      "ComputerVision Valid Loss: 0.678 | Valid Acc: 51.57%\n",
      "ComputerVision Test Loss: 0.659 | Test Acc: 58.01%\n",
      "Epoch: 06 | Epoch Time: 0m 0s\n",
      "ComputerVision Train Loss: 0.678 | Train Acc: 50.10%\n",
      "ComputerVision Valid Loss: 0.677 | Valid Acc: 51.76%\n",
      "ComputerVision Test Loss: 0.658 | Test Acc: 58.27%\n",
      "Epoch: 07 | Epoch Time: 0m 0s\n",
      "ComputerVision Train Loss: 0.677 | Train Acc: 51.77%\n",
      "ComputerVision Valid Loss: 0.677 | Valid Acc: 52.21%\n",
      "ComputerVision Test Loss: 0.659 | Test Acc: 57.80%\n",
      "Epoch: 08 | Epoch Time: 0m 0s\n",
      "ComputerVision Train Loss: 0.679 | Train Acc: 48.54%\n",
      "ComputerVision Valid Loss: 0.676 | Valid Acc: 52.24%\n",
      "ComputerVision Test Loss: 0.660 | Test Acc: 57.77%\n",
      "Epoch: 09 | Epoch Time: 0m 0s\n",
      "ComputerVision Train Loss: 0.675 | Train Acc: 52.50%\n",
      "ComputerVision Valid Loss: 0.676 | Valid Acc: 52.05%\n",
      "ComputerVision Test Loss: 0.659 | Test Acc: 57.71%\n",
      "Epoch: 10 | Epoch Time: 0m 0s\n",
      "ComputerVision Train Loss: 0.681 | Train Acc: 51.88%\n",
      "ComputerVision Valid Loss: 0.676 | Valid Acc: 51.79%\n",
      "ComputerVision Test Loss: 0.658 | Test Acc: 58.21%\n",
      "Epoch: 11 | Epoch Time: 0m 0s\n",
      "ComputerVision Train Loss: 0.676 | Train Acc: 51.35%\n",
      "ComputerVision Valid Loss: 0.677 | Valid Acc: 51.80%\n",
      "ComputerVision Test Loss: 0.657 | Test Acc: 58.10%\n",
      "Epoch: 12 | Epoch Time: 0m 0s\n",
      "ComputerVision Train Loss: 0.682 | Train Acc: 49.38%\n",
      "ComputerVision Valid Loss: 0.675 | Valid Acc: 52.40%\n",
      "ComputerVision Test Loss: 0.658 | Test Acc: 57.95%\n",
      "Epoch: 13 | Epoch Time: 0m 0s\n",
      "ComputerVision Train Loss: 0.675 | Train Acc: 53.65%\n",
      "ComputerVision Valid Loss: 0.676 | Valid Acc: 52.20%\n",
      "ComputerVision Test Loss: 0.657 | Test Acc: 58.33%\n",
      "Epoch: 14 | Epoch Time: 0m 0s\n",
      "ComputerVision Train Loss: 0.678 | Train Acc: 49.27%\n",
      "ComputerVision Valid Loss: 0.676 | Valid Acc: 51.95%\n",
      "ComputerVision Test Loss: 0.657 | Test Acc: 58.48%\n",
      "Epoch: 15 | Epoch Time: 0m 0s\n",
      "ComputerVision Train Loss: 0.675 | Train Acc: 53.02%\n",
      "ComputerVision Valid Loss: 0.675 | Valid Acc: 52.25%\n",
      "ComputerVision Test Loss: 0.657 | Test Acc: 58.41%\n",
      "Epoch: 16 | Epoch Time: 0m 0s\n",
      "ComputerVision Train Loss: 0.675 | Train Acc: 50.10%\n",
      "ComputerVision Valid Loss: 0.675 | Valid Acc: 51.95%\n",
      "ComputerVision Test Loss: 0.658 | Test Acc: 58.19%\n",
      "Epoch: 17 | Epoch Time: 0m 0s\n",
      "ComputerVision Train Loss: 0.674 | Train Acc: 51.77%\n",
      "ComputerVision Valid Loss: 0.675 | Valid Acc: 52.34%\n",
      "ComputerVision Test Loss: 0.659 | Test Acc: 58.18%\n",
      "Epoch: 18 | Epoch Time: 0m 0s\n",
      "ComputerVision Train Loss: 0.678 | Train Acc: 51.46%\n",
      "ComputerVision Valid Loss: 0.675 | Valid Acc: 52.18%\n",
      "ComputerVision Test Loss: 0.659 | Test Acc: 57.99%\n",
      "Epoch: 19 | Epoch Time: 0m 0s\n",
      "ComputerVision Train Loss: 0.680 | Train Acc: 50.31%\n",
      "ComputerVision Valid Loss: 0.675 | Valid Acc: 52.60%\n",
      "ComputerVision Test Loss: 0.660 | Test Acc: 57.77%\n",
      "Epoch: 20 | Epoch Time: 0m 0s\n",
      "ComputerVision Train Loss: 0.677 | Train Acc: 49.58%\n",
      "ComputerVision Valid Loss: 0.674 | Valid Acc: 52.59%\n",
      "ComputerVision Test Loss: 0.659 | Test Acc: 58.01%\n",
      "Epoch: 21 | Epoch Time: 0m 0s\n",
      "ComputerVision Train Loss: 0.677 | Train Acc: 50.00%\n",
      "ComputerVision Valid Loss: 0.674 | Valid Acc: 52.63%\n",
      "ComputerVision Test Loss: 0.659 | Test Acc: 58.18%\n",
      "Epoch: 22 | Epoch Time: 0m 0s\n",
      "ComputerVision Train Loss: 0.679 | Train Acc: 48.54%\n",
      "ComputerVision Valid Loss: 0.674 | Valid Acc: 52.90%\n",
      "ComputerVision Test Loss: 0.660 | Test Acc: 57.64%\n",
      "Epoch: 23 | Epoch Time: 0m 0s\n",
      "ComputerVision Train Loss: 0.678 | Train Acc: 49.17%\n",
      "ComputerVision Valid Loss: 0.674 | Valid Acc: 52.46%\n",
      "ComputerVision Test Loss: 0.659 | Test Acc: 58.21%\n",
      "Epoch: 24 | Epoch Time: 0m 0s\n",
      "ComputerVision Train Loss: 0.673 | Train Acc: 49.58%\n",
      "ComputerVision Valid Loss: 0.674 | Valid Acc: 53.23%\n",
      "ComputerVision Test Loss: 0.660 | Test Acc: 57.63%\n",
      "Epoch: 25 | Epoch Time: 0m 0s\n",
      "ComputerVision Train Loss: 0.677 | Train Acc: 46.35%\n",
      "ComputerVision Valid Loss: 0.674 | Valid Acc: 52.71%\n",
      "ComputerVision Test Loss: 0.660 | Test Acc: 57.85%\n",
      "Early stopping at epoch 25 for ComputerVision model.\n",
      "Best performing epoch for ComputerVision model: 14\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "\n",
    "results, best_model_states = train_loop(models, optimizers, iterators, N_EPOCHS, label_names, target_field, model_file_names, best_valid_losses, \"P1\", \"1000\", 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ed7797de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def evaluate_model(model, iterator, label_field, target_field, best_epoch):\n",
    "def evaluate_model(model, iterator, label_field, target_field):\n",
    "    \n",
    "#     print(f\"Evaluating {label_field} model at epoch {best_epoch}\")\n",
    "\n",
    "    y_predict = []\n",
    "    y_test = []\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch in iterator:\n",
    "            predictions = model(getattr(batch, target_field)).squeeze(1)\n",
    "            rounded_preds = torch.round(torch.sigmoid(predictions))\n",
    "            y_predict += rounded_preds.tolist()\n",
    "            y_test += getattr(batch, label_field).tolist()\n",
    "\n",
    "    y_predict = np.asarray(y_predict)\n",
    "    y_test = np.asarray(y_test)\n",
    "\n",
    "    # Compute metrics\n",
    "    recall = recall_score(y_test, y_predict, average='macro')\n",
    "    precision = precision_score(y_test, y_predict, average='macro')\n",
    "    f1score = f1_score(y_test, y_predict, average='macro')\n",
    "    accuracy = accuracy_score(y_test, y_predict)\n",
    "    matthews = matthews_corrcoef(y_test, y_predict)\n",
    "\n",
    "    # Print metrics\n",
    "    print(f\"{label_field}:\")\n",
    "    print(confusion_matrix(y_test, y_predict))\n",
    "    print('Accuracy:', accuracy)\n",
    "    print('Macro Precision:', precision)\n",
    "    print('Macro Recall:', recall)\n",
    "    print('Macro F1 score:', f1score)\n",
    "    print('MCC:', matthews)\n",
    "    print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9c530d2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "InformationTheory:\n",
      "[[6376 3211]\n",
      " [4590 3889]]\n",
      "Accuracy: 0.5681943983172811\n",
      "Macro Precision: 0.5645900003339387\n",
      "Macro Recall: 0.5618649283703301\n",
      "Macro F1 score: 0.5598532653771587\n",
      "MCC: 0.12642556298626814\n",
      "\n",
      "\n",
      "ComputationalLinguistics:\n",
      "[[12488  2210]\n",
      " [ 2855   513]]\n",
      "Accuracy: 0.7196391010738403\n",
      "Macro Precision: 0.5011584052452778\n",
      "Macro Recall: 0.5009776606056571\n",
      "Macro F1 score: 0.49992116886432636\n",
      "MCC: 0.0021284051998569716\n",
      "\n",
      "\n",
      "ComputerVision:\n",
      "[[8184 3663]\n",
      " [3845 2374]]\n",
      "Accuracy: 0.58441270895605\n",
      "Macro Precision: 0.5367987415647677\n",
      "Macro Recall: 0.5362705985476264\n",
      "Macro F1 score: 0.5364720278007302\n",
      "MCC: 0.07306743138645395\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_IT.load_state_dict(best_model_states[0])\n",
    "model_CL.load_state_dict(best_model_states[1])\n",
    "model_CV.load_state_dict(best_model_states[2])\n",
    "\n",
    "# Evaluate models\n",
    "evaluate_model(model_IT, test_iterator_IT, \"InformationTheory\", target_field)\n",
    "evaluate_model(model_CL, test_iterator_CL, \"ComputationalLinguistics\", target_field)\n",
    "evaluate_model(model_CV, test_iterator_CV, \"ComputerVision\", target_field)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1215ecfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# P2\n",
    "\n",
    "target_field = \"title\"\n",
    "TEXT = Field(sequential=True, tokenize=custom_tokenizer_P2, lower=True)\n",
    "LABEL = data.LabelField(dtype=torch.float, use_vocab = False, preprocessing = int)\n",
    "\n",
    "# Field - P2\n",
    "train_datafield_P2 = [(\"title\", TEXT),\n",
    "                      (\"abstract\", None),\n",
    "                      (\"InformationTheory\", LABEL),\n",
    "                      (\"ComputationalLinguistics\", LABEL),\n",
    "                      (\"ComputerVision\", LABEL)\n",
    "                      ]\n",
    "\n",
    "train_data_whole, test_data = TabularDataset.splits(\n",
    "    path=\"./\",\n",
    "    train=\"train.csv\", test=\"test.csv\", format=\"csv\",\n",
    "    skip_header=True, fields=train_datafield_P2)\n",
    "\n",
    "train_data, valid_data = train_data_whole.split(split_ratio = 0.9, random_state = random.getstate())\n",
    "train_1000, remaining = train_data_whole.split(split_ratio = 1000 / len(train_data_whole), random_state = random.getstate())\n",
    "train_1000, valid_1000 = train_1000.split(split_ratio = 0.9, random_state = random.getstate())\n",
    "\n",
    "\n",
    "# Building vocab - P2\n",
    "MAX_VOCAB_SIZE = 5000\n",
    "\n",
    "TEXT.build_vocab(train_1000, max_size=MAX_VOCAB_SIZE)\n",
    "\n",
    "# Create iterator #2 for P2 train_data\n",
    "\n",
    "train_iterator_IT, validation_IT, test_iterator_IT = generate_label_iterator(train_1000, \"InformationTheory\", target_field, validation=True)\n",
    "train_iterator_CL, validation_CL, test_iterator_CL = generate_label_iterator(train_1000, \"ComputationalLinguistics\", target_field, validation=True)\n",
    "train_iterator_CV, validation_CV, test_iterator_CV = generate_label_iterator(train_1000, \"ComputerVision\", target_field, validation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6cf6569f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2055"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(TEXT.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bcd18041",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_IT, optimizer_IT = generate_model_and_optimizer(pos_weight = pos_weight_IT)\n",
    "model_CL, optimizer_CL = generate_model_and_optimizer(pos_weight = pos_weight_CL)\n",
    "model_CV, optimizer_CV = generate_model_and_optimizer(pos_weight = pos_weight_CV)\n",
    "\n",
    "# Training Loop - P2\n",
    "\n",
    "models = [model_IT, model_CL, model_CV]\n",
    "optimizers = [optimizer_IT, optimizer_CL, optimizer_CV]\n",
    "iterators = [(train_iterator_IT, validation_IT, test_iterator_IT), (train_iterator_CL, validation_CL, test_iterator_CL), (train_iterator_CV, validation_CV, test_iterator_CV)]\n",
    "\n",
    "best_valid_losses = [float(\"inf\"), float(\"inf\"), float(\"inf\")]\n",
    "model_file_names = [\"RNN_model_IT_T_P2_1000.pt\", \"RNN_model_CL_T_P2_1000.pt\", \"RNN_model_T_P2_1000.pt\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9ffeea48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for P2_InformationTheory, using 1000 data of title...\n",
      "Epoch: 01 | Epoch Time: 0m 1s\n",
      "InformationTheory Train Loss: 1.052 | Train Acc: 52.50%\n",
      "InformationTheory Valid Loss: 1.045 | Valid Acc: 51.87%\n",
      "InformationTheory Test Loss: 1.372 | Test Acc: 53.19%\n",
      "Epoch: 02 | Epoch Time: 0m 0s\n",
      "InformationTheory Train Loss: 1.026 | Train Acc: 54.48%\n",
      "InformationTheory Valid Loss: 1.045 | Valid Acc: 52.13%\n",
      "InformationTheory Test Loss: 1.374 | Test Acc: 53.12%\n",
      "Epoch: 03 | Epoch Time: 0m 0s\n",
      "InformationTheory Train Loss: 1.056 | Train Acc: 37.08%\n",
      "InformationTheory Valid Loss: 1.044 | Valid Acc: 53.73%\n",
      "InformationTheory Test Loss: 1.379 | Test Acc: 53.57%\n",
      "Epoch: 04 | Epoch Time: 0m 0s\n",
      "InformationTheory Train Loss: 1.033 | Train Acc: 64.27%\n",
      "InformationTheory Valid Loss: 1.044 | Valid Acc: 53.39%\n",
      "InformationTheory Test Loss: 1.380 | Test Acc: 53.39%\n",
      "Epoch: 05 | Epoch Time: 0m 0s\n",
      "InformationTheory Train Loss: 1.025 | Train Acc: 61.77%\n",
      "InformationTheory Valid Loss: 1.044 | Valid Acc: 54.36%\n",
      "InformationTheory Test Loss: 1.384 | Test Acc: 53.70%\n",
      "Epoch: 06 | Epoch Time: 0m 0s\n",
      "InformationTheory Train Loss: 1.054 | Train Acc: 46.56%\n",
      "InformationTheory Valid Loss: 1.044 | Valid Acc: 53.93%\n",
      "InformationTheory Test Loss: 1.381 | Test Acc: 53.74%\n",
      "Epoch: 07 | Epoch Time: 0m 0s\n",
      "InformationTheory Train Loss: 1.086 | Train Acc: 43.33%\n",
      "InformationTheory Valid Loss: 1.043 | Valid Acc: 55.69%\n",
      "InformationTheory Test Loss: 1.387 | Test Acc: 54.08%\n",
      "Epoch: 08 | Epoch Time: 0m 0s\n",
      "InformationTheory Train Loss: 1.030 | Train Acc: 51.35%\n",
      "InformationTheory Valid Loss: 1.042 | Valid Acc: 57.40%\n",
      "InformationTheory Test Loss: 1.394 | Test Acc: 54.37%\n",
      "Epoch: 09 | Epoch Time: 0m 0s\n",
      "InformationTheory Train Loss: 1.057 | Train Acc: 53.23%\n",
      "InformationTheory Valid Loss: 1.039 | Valid Acc: 54.02%\n",
      "InformationTheory Test Loss: 1.376 | Test Acc: 54.92%\n",
      "Epoch: 10 | Epoch Time: 0m 0s\n",
      "InformationTheory Train Loss: 1.033 | Train Acc: 56.15%\n",
      "InformationTheory Valid Loss: 1.039 | Valid Acc: 55.48%\n",
      "InformationTheory Test Loss: 1.382 | Test Acc: 55.13%\n",
      "Epoch: 11 | Epoch Time: 0m 0s\n",
      "InformationTheory Train Loss: 1.105 | Train Acc: 41.35%\n",
      "InformationTheory Valid Loss: 1.046 | Valid Acc: 49.66%\n",
      "InformationTheory Test Loss: 1.366 | Test Acc: 53.32%\n",
      "Epoch: 12 | Epoch Time: 0m 0s\n",
      "InformationTheory Train Loss: 1.070 | Train Acc: 34.17%\n",
      "InformationTheory Valid Loss: 1.038 | Valid Acc: 57.45%\n",
      "InformationTheory Test Loss: 1.387 | Test Acc: 55.99%\n",
      "Epoch: 13 | Epoch Time: 0m 0s\n",
      "InformationTheory Train Loss: 1.053 | Train Acc: 48.85%\n",
      "InformationTheory Valid Loss: 1.038 | Valid Acc: 56.61%\n",
      "InformationTheory Test Loss: 1.382 | Test Acc: 55.85%\n",
      "Epoch: 14 | Epoch Time: 0m 0s\n",
      "InformationTheory Train Loss: 1.084 | Train Acc: 39.38%\n",
      "InformationTheory Valid Loss: 1.041 | Valid Acc: 52.48%\n",
      "InformationTheory Test Loss: 1.373 | Test Acc: 54.74%\n",
      "Epoch: 15 | Epoch Time: 0m 0s\n",
      "InformationTheory Train Loss: 1.084 | Train Acc: 40.62%\n",
      "InformationTheory Valid Loss: 1.037 | Valid Acc: 57.54%\n",
      "InformationTheory Test Loss: 1.385 | Test Acc: 55.74%\n",
      "Epoch: 16 | Epoch Time: 0m 0s\n",
      "InformationTheory Train Loss: 1.053 | Train Acc: 46.77%\n",
      "InformationTheory Valid Loss: 1.036 | Valid Acc: 57.92%\n",
      "InformationTheory Test Loss: 1.388 | Test Acc: 55.65%\n",
      "Epoch: 17 | Epoch Time: 0m 0s\n",
      "InformationTheory Train Loss: 1.033 | Train Acc: 50.10%\n",
      "InformationTheory Valid Loss: 1.037 | Valid Acc: 59.80%\n",
      "InformationTheory Test Loss: 1.395 | Test Acc: 55.81%\n",
      "Epoch: 18 | Epoch Time: 0m 0s\n",
      "InformationTheory Train Loss: 1.050 | Train Acc: 45.10%\n",
      "InformationTheory Valid Loss: 1.037 | Valid Acc: 59.53%\n",
      "InformationTheory Test Loss: 1.396 | Test Acc: 55.64%\n",
      "Epoch: 19 | Epoch Time: 0m 0s\n",
      "InformationTheory Train Loss: 1.050 | Train Acc: 41.04%\n",
      "InformationTheory Valid Loss: 1.037 | Valid Acc: 58.93%\n",
      "InformationTheory Test Loss: 1.390 | Test Acc: 55.66%\n",
      "Epoch: 20 | Epoch Time: 0m 0s\n",
      "InformationTheory Train Loss: 1.079 | Train Acc: 40.00%\n",
      "InformationTheory Valid Loss: 1.037 | Valid Acc: 58.92%\n",
      "InformationTheory Test Loss: 1.390 | Test Acc: 55.68%\n",
      "Epoch: 21 | Epoch Time: 0m 0s\n",
      "InformationTheory Train Loss: 1.050 | Train Acc: 59.69%\n",
      "InformationTheory Valid Loss: 1.036 | Valid Acc: 58.35%\n",
      "InformationTheory Test Loss: 1.384 | Test Acc: 56.17%\n",
      "Epoch: 22 | Epoch Time: 0m 0s\n",
      "InformationTheory Train Loss: 1.062 | Train Acc: 60.10%\n",
      "InformationTheory Valid Loss: 1.034 | Valid Acc: 57.91%\n",
      "InformationTheory Test Loss: 1.382 | Test Acc: 56.07%\n",
      "Early stopping at epoch 22 for InformationTheory model.\n",
      "Best performing epoch for InformationTheory model: 11\n",
      "Training model for P2_ComputationalLinguistics, using 1000 data of title...\n",
      "Epoch: 01 | Epoch Time: 0m 0s\n",
      "ComputationalLinguistics Train Loss: 1.034 | Train Acc: 40.31%\n",
      "ComputationalLinguistics Valid Loss: 1.054 | Valid Acc: 48.44%\n",
      "ComputationalLinguistics Test Loss: 0.973 | Test Acc: 49.51%\n",
      "Epoch: 02 | Epoch Time: 0m 0s\n",
      "ComputationalLinguistics Train Loss: 1.046 | Train Acc: 54.58%\n",
      "ComputationalLinguistics Valid Loss: 1.054 | Valid Acc: 47.65%\n",
      "ComputationalLinguistics Test Loss: 0.973 | Test Acc: 48.59%\n",
      "Epoch: 03 | Epoch Time: 0m 0s\n",
      "ComputationalLinguistics Train Loss: 1.076 | Train Acc: 39.58%\n",
      "ComputationalLinguistics Valid Loss: 1.053 | Valid Acc: 46.61%\n",
      "ComputationalLinguistics Test Loss: 0.974 | Test Acc: 47.23%\n",
      "Epoch: 04 | Epoch Time: 0m 0s\n",
      "ComputationalLinguistics Train Loss: 1.028 | Train Acc: 42.50%\n",
      "ComputationalLinguistics Valid Loss: 1.053 | Valid Acc: 49.70%\n",
      "ComputationalLinguistics Test Loss: 0.971 | Test Acc: 51.23%\n",
      "Epoch: 05 | Epoch Time: 0m 0s\n",
      "ComputationalLinguistics Train Loss: 1.089 | Train Acc: 37.19%\n",
      "ComputationalLinguistics Valid Loss: 1.053 | Valid Acc: 46.25%\n",
      "ComputationalLinguistics Test Loss: 0.973 | Test Acc: 47.28%\n",
      "Epoch: 06 | Epoch Time: 0m 0s\n",
      "ComputationalLinguistics Train Loss: 1.053 | Train Acc: 46.88%\n",
      "ComputationalLinguistics Valid Loss: 1.053 | Valid Acc: 48.17%\n",
      "ComputationalLinguistics Test Loss: 0.972 | Test Acc: 49.24%\n",
      "Epoch: 07 | Epoch Time: 0m 0s\n",
      "ComputationalLinguistics Train Loss: 1.028 | Train Acc: 52.08%\n",
      "ComputationalLinguistics Valid Loss: 1.053 | Valid Acc: 49.32%\n",
      "ComputationalLinguistics Test Loss: 0.970 | Test Acc: 50.71%\n",
      "Epoch: 08 | Epoch Time: 0m 0s\n",
      "ComputationalLinguistics Train Loss: 1.053 | Train Acc: 59.48%\n",
      "ComputationalLinguistics Valid Loss: 1.051 | Valid Acc: 47.67%\n",
      "ComputationalLinguistics Test Loss: 0.973 | Test Acc: 47.71%\n",
      "Epoch: 09 | Epoch Time: 0m 0s\n",
      "ComputationalLinguistics Train Loss: 1.047 | Train Acc: 34.79%\n",
      "ComputationalLinguistics Valid Loss: 1.050 | Valid Acc: 50.10%\n",
      "ComputationalLinguistics Test Loss: 0.969 | Test Acc: 51.13%\n",
      "Epoch: 10 | Epoch Time: 0m 0s\n",
      "ComputationalLinguistics Train Loss: 1.103 | Train Acc: 51.46%\n",
      "ComputationalLinguistics Valid Loss: 1.050 | Valid Acc: 47.55%\n",
      "ComputationalLinguistics Test Loss: 0.974 | Test Acc: 46.49%\n",
      "Epoch: 11 | Epoch Time: 0m 0s\n",
      "ComputationalLinguistics Train Loss: 1.029 | Train Acc: 33.85%\n",
      "ComputationalLinguistics Valid Loss: 1.050 | Valid Acc: 50.37%\n",
      "ComputationalLinguistics Test Loss: 0.969 | Test Acc: 50.34%\n",
      "Epoch: 12 | Epoch Time: 0m 0s\n",
      "ComputationalLinguistics Train Loss: 1.051 | Train Acc: 65.62%\n",
      "ComputationalLinguistics Valid Loss: 1.049 | Valid Acc: 48.81%\n",
      "ComputationalLinguistics Test Loss: 0.971 | Test Acc: 48.97%\n",
      "Epoch: 13 | Epoch Time: 0m 0s\n",
      "ComputationalLinguistics Train Loss: 1.095 | Train Acc: 45.10%\n",
      "ComputationalLinguistics Valid Loss: 1.050 | Valid Acc: 47.14%\n",
      "ComputationalLinguistics Test Loss: 0.973 | Test Acc: 46.77%\n",
      "Epoch: 14 | Epoch Time: 0m 0s\n",
      "ComputationalLinguistics Train Loss: 1.048 | Train Acc: 41.25%\n",
      "ComputationalLinguistics Valid Loss: 1.049 | Valid Acc: 48.02%\n",
      "ComputationalLinguistics Test Loss: 0.971 | Test Acc: 48.18%\n",
      "Epoch: 15 | Epoch Time: 0m 0s\n",
      "ComputationalLinguistics Train Loss: 1.054 | Train Acc: 59.90%\n",
      "ComputationalLinguistics Valid Loss: 1.049 | Valid Acc: 46.32%\n",
      "ComputationalLinguistics Test Loss: 0.974 | Test Acc: 45.32%\n",
      "Epoch: 16 | Epoch Time: 0m 0s\n",
      "ComputationalLinguistics Train Loss: 1.054 | Train Acc: 43.33%\n",
      "ComputationalLinguistics Valid Loss: 1.049 | Valid Acc: 46.63%\n",
      "ComputationalLinguistics Test Loss: 0.973 | Test Acc: 46.28%\n",
      "Epoch: 17 | Epoch Time: 0m 0s\n",
      "ComputationalLinguistics Train Loss: 1.026 | Train Acc: 52.60%\n",
      "ComputationalLinguistics Valid Loss: 1.048 | Valid Acc: 48.45%\n",
      "ComputationalLinguistics Test Loss: 0.971 | Test Acc: 48.13%\n",
      "Epoch: 18 | Epoch Time: 0m 0s\n",
      "ComputationalLinguistics Train Loss: 1.024 | Train Acc: 59.27%\n",
      "ComputationalLinguistics Valid Loss: 1.047 | Valid Acc: 47.92%\n",
      "ComputationalLinguistics Test Loss: 0.971 | Test Acc: 47.49%\n",
      "Epoch: 19 | Epoch Time: 0m 0s\n",
      "ComputationalLinguistics Train Loss: 1.028 | Train Acc: 47.60%\n",
      "ComputationalLinguistics Valid Loss: 1.047 | Valid Acc: 49.58%\n",
      "ComputationalLinguistics Test Loss: 0.969 | Test Acc: 49.57%\n",
      "Epoch: 20 | Epoch Time: 0m 0s\n",
      "ComputationalLinguistics Train Loss: 1.029 | Train Acc: 59.27%\n",
      "ComputationalLinguistics Valid Loss: 1.046 | Valid Acc: 50.15%\n",
      "ComputationalLinguistics Test Loss: 0.968 | Test Acc: 49.98%\n",
      "Epoch: 21 | Epoch Time: 0m 0s\n",
      "ComputationalLinguistics Train Loss: 1.075 | Train Acc: 36.25%\n",
      "ComputationalLinguistics Valid Loss: 1.045 | Valid Acc: 49.67%\n",
      "ComputationalLinguistics Test Loss: 0.968 | Test Acc: 49.35%\n",
      "Epoch: 22 | Epoch Time: 0m 0s\n",
      "ComputationalLinguistics Train Loss: 1.028 | Train Acc: 53.23%\n",
      "ComputationalLinguistics Valid Loss: 1.045 | Valid Acc: 50.87%\n",
      "ComputationalLinguistics Test Loss: 0.966 | Test Acc: 51.33%\n",
      "Epoch: 23 | Epoch Time: 0m 0s\n",
      "ComputationalLinguistics Train Loss: 1.044 | Train Acc: 49.17%\n",
      "ComputationalLinguistics Valid Loss: 1.044 | Valid Acc: 53.37%\n",
      "ComputationalLinguistics Test Loss: 0.964 | Test Acc: 53.66%\n",
      "Epoch: 24 | Epoch Time: 0m 0s\n",
      "ComputationalLinguistics Train Loss: 1.030 | Train Acc: 53.96%\n",
      "ComputationalLinguistics Valid Loss: 1.044 | Valid Acc: 52.96%\n",
      "ComputationalLinguistics Test Loss: 0.963 | Test Acc: 53.76%\n",
      "Epoch: 25 | Epoch Time: 0m 0s\n",
      "ComputationalLinguistics Train Loss: 1.028 | Train Acc: 64.06%\n",
      "ComputationalLinguistics Valid Loss: 1.043 | Valid Acc: 52.47%\n",
      "ComputationalLinguistics Test Loss: 0.963 | Test Acc: 52.81%\n",
      "Epoch: 26 | Epoch Time: 0m 0s\n",
      "ComputationalLinguistics Train Loss: 1.047 | Train Acc: 42.08%\n",
      "ComputationalLinguistics Valid Loss: 1.044 | Valid Acc: 53.46%\n",
      "ComputationalLinguistics Test Loss: 0.963 | Test Acc: 54.23%\n",
      "Epoch: 27 | Epoch Time: 0m 0s\n",
      "ComputationalLinguistics Train Loss: 1.042 | Train Acc: 59.69%\n",
      "ComputationalLinguistics Valid Loss: 1.043 | Valid Acc: 51.95%\n",
      "ComputationalLinguistics Test Loss: 0.964 | Test Acc: 51.89%\n",
      "Epoch: 28 | Epoch Time: 0m 0s\n",
      "ComputationalLinguistics Train Loss: 1.050 | Train Acc: 36.15%\n",
      "ComputationalLinguistics Valid Loss: 1.042 | Valid Acc: 52.94%\n",
      "ComputationalLinguistics Test Loss: 0.962 | Test Acc: 53.43%\n",
      "Epoch: 29 | Epoch Time: 0m 0s\n",
      "ComputationalLinguistics Train Loss: 1.047 | Train Acc: 32.40%\n",
      "ComputationalLinguistics Valid Loss: 1.042 | Valid Acc: 53.88%\n",
      "ComputationalLinguistics Test Loss: 0.961 | Test Acc: 54.88%\n",
      "Epoch: 30 | Epoch Time: 0m 0s\n",
      "ComputationalLinguistics Train Loss: 1.024 | Train Acc: 56.88%\n",
      "ComputationalLinguistics Valid Loss: 1.042 | Valid Acc: 54.80%\n",
      "ComputationalLinguistics Test Loss: 0.960 | Test Acc: 56.03%\n",
      "Epoch: 31 | Epoch Time: 0m 0s\n",
      "ComputationalLinguistics Train Loss: 1.046 | Train Acc: 65.21%\n",
      "ComputationalLinguistics Valid Loss: 1.042 | Valid Acc: 53.01%\n",
      "ComputationalLinguistics Test Loss: 0.961 | Test Acc: 54.00%\n",
      "Epoch: 32 | Epoch Time: 0m 0s\n",
      "ComputationalLinguistics Train Loss: 1.046 | Train Acc: 34.27%\n",
      "ComputationalLinguistics Valid Loss: 1.042 | Valid Acc: 54.31%\n",
      "ComputationalLinguistics Test Loss: 0.960 | Test Acc: 55.38%\n",
      "Epoch: 33 | Epoch Time: 0m 0s\n",
      "ComputationalLinguistics Train Loss: 1.062 | Train Acc: 55.00%\n",
      "ComputationalLinguistics Valid Loss: 1.042 | Valid Acc: 51.77%\n",
      "ComputationalLinguistics Test Loss: 0.963 | Test Acc: 52.12%\n",
      "Epoch: 34 | Epoch Time: 0m 0s\n",
      "ComputationalLinguistics Train Loss: 1.048 | Train Acc: 32.71%\n",
      "ComputationalLinguistics Valid Loss: 1.043 | Valid Acc: 52.61%\n",
      "ComputationalLinguistics Test Loss: 0.963 | Test Acc: 53.65%\n",
      "Epoch: 35 | Epoch Time: 0m 0s\n",
      "ComputationalLinguistics Train Loss: 1.023 | Train Acc: 49.58%\n",
      "ComputationalLinguistics Valid Loss: 1.042 | Valid Acc: 54.87%\n",
      "ComputationalLinguistics Test Loss: 0.961 | Test Acc: 55.68%\n",
      "Epoch: 36 | Epoch Time: 0m 0s\n",
      "ComputationalLinguistics Train Loss: 1.028 | Train Acc: 73.02%\n",
      "ComputationalLinguistics Valid Loss: 1.041 | Valid Acc: 52.43%\n",
      "ComputationalLinguistics Test Loss: 0.962 | Test Acc: 52.78%\n",
      "Epoch: 37 | Epoch Time: 0m 0s\n",
      "ComputationalLinguistics Train Loss: 1.028 | Train Acc: 51.56%\n",
      "ComputationalLinguistics Valid Loss: 1.041 | Valid Acc: 55.51%\n",
      "ComputationalLinguistics Test Loss: 0.959 | Test Acc: 56.72%\n",
      "Epoch: 38 | Epoch Time: 0m 0s\n",
      "ComputationalLinguistics Train Loss: 1.048 | Train Acc: 39.38%\n",
      "ComputationalLinguistics Valid Loss: 1.041 | Valid Acc: 55.10%\n",
      "ComputationalLinguistics Test Loss: 0.959 | Test Acc: 56.30%\n",
      "Epoch: 39 | Epoch Time: 0m 0s\n",
      "ComputationalLinguistics Train Loss: 1.024 | Train Acc: 50.10%\n",
      "ComputationalLinguistics Valid Loss: 1.041 | Valid Acc: 57.12%\n",
      "ComputationalLinguistics Test Loss: 0.958 | Test Acc: 58.28%\n",
      "Epoch: 40 | Epoch Time: 0m 0s\n",
      "ComputationalLinguistics Train Loss: 1.044 | Train Acc: 45.52%\n",
      "ComputationalLinguistics Valid Loss: 1.041 | Valid Acc: 57.02%\n",
      "ComputationalLinguistics Test Loss: 0.957 | Test Acc: 58.16%\n",
      "Epoch: 41 | Epoch Time: 0m 0s\n",
      "ComputationalLinguistics Train Loss: 1.029 | Train Acc: 67.60%\n",
      "ComputationalLinguistics Valid Loss: 1.041 | Valid Acc: 58.67%\n",
      "ComputationalLinguistics Test Loss: 0.955 | Test Acc: 60.05%\n",
      "Epoch: 42 | Epoch Time: 0m 0s\n",
      "ComputationalLinguistics Train Loss: 1.044 | Train Acc: 51.46%\n",
      "ComputationalLinguistics Valid Loss: 1.040 | Valid Acc: 57.69%\n",
      "ComputationalLinguistics Test Loss: 0.955 | Test Acc: 59.33%\n",
      "Epoch: 43 | Epoch Time: 0m 0s\n",
      "ComputationalLinguistics Train Loss: 1.043 | Train Acc: 33.75%\n",
      "ComputationalLinguistics Valid Loss: 1.040 | Valid Acc: 59.30%\n",
      "ComputationalLinguistics Test Loss: 0.953 | Test Acc: 60.93%\n",
      "Epoch: 44 | Epoch Time: 0m 0s\n",
      "ComputationalLinguistics Train Loss: 1.074 | Train Acc: 43.85%\n",
      "ComputationalLinguistics Valid Loss: 1.039 | Valid Acc: 59.31%\n",
      "ComputationalLinguistics Test Loss: 0.953 | Test Acc: 60.33%\n",
      "Epoch: 45 | Epoch Time: 0m 0s\n",
      "ComputationalLinguistics Train Loss: 1.020 | Train Acc: 55.31%\n",
      "ComputationalLinguistics Valid Loss: 1.040 | Valid Acc: 61.18%\n",
      "ComputationalLinguistics Test Loss: 0.952 | Test Acc: 63.03%\n",
      "Epoch: 46 | Epoch Time: 0m 0s\n",
      "ComputationalLinguistics Train Loss: 1.093 | Train Acc: 54.48%\n",
      "ComputationalLinguistics Valid Loss: 1.039 | Valid Acc: 56.87%\n",
      "ComputationalLinguistics Test Loss: 0.956 | Test Acc: 58.25%\n",
      "Epoch: 47 | Epoch Time: 0m 0s\n",
      "ComputationalLinguistics Train Loss: 1.044 | Train Acc: 48.23%\n",
      "ComputationalLinguistics Valid Loss: 1.040 | Valid Acc: 57.26%\n",
      "ComputationalLinguistics Test Loss: 0.955 | Test Acc: 58.67%\n",
      "Epoch: 48 | Epoch Time: 0m 0s\n",
      "ComputationalLinguistics Train Loss: 1.043 | Train Acc: 37.92%\n",
      "ComputationalLinguistics Valid Loss: 1.040 | Valid Acc: 59.46%\n",
      "ComputationalLinguistics Test Loss: 0.954 | Test Acc: 60.89%\n",
      "Epoch: 49 | Epoch Time: 0m 0s\n",
      "ComputationalLinguistics Train Loss: 1.073 | Train Acc: 40.83%\n",
      "ComputationalLinguistics Valid Loss: 1.039 | Valid Acc: 57.54%\n",
      "ComputationalLinguistics Test Loss: 0.954 | Test Acc: 58.73%\n",
      "Epoch: 50 | Epoch Time: 0m 0s\n",
      "ComputationalLinguistics Train Loss: 1.056 | Train Acc: 65.31%\n",
      "ComputationalLinguistics Valid Loss: 1.039 | Valid Acc: 56.91%\n",
      "ComputationalLinguistics Test Loss: 0.956 | Test Acc: 58.36%\n",
      "Training model for P2_ComputerVision, using 1000 data of title...\n",
      "Epoch: 01 | Epoch Time: 0m 0s\n",
      "ComputerVision Train Loss: 0.674 | Train Acc: 49.79%\n",
      "ComputerVision Valid Loss: 0.674 | Valid Acc: 52.57%\n",
      "ComputerVision Test Loss: 0.674 | Test Acc: 54.35%\n",
      "Epoch: 02 | Epoch Time: 0m 0s\n",
      "ComputerVision Train Loss: 0.671 | Train Acc: 50.62%\n",
      "ComputerVision Valid Loss: 0.674 | Valid Acc: 52.26%\n",
      "ComputerVision Test Loss: 0.674 | Test Acc: 54.38%\n",
      "Epoch: 03 | Epoch Time: 0m 0s\n",
      "ComputerVision Train Loss: 0.676 | Train Acc: 48.33%\n",
      "ComputerVision Valid Loss: 0.673 | Valid Acc: 52.21%\n",
      "ComputerVision Test Loss: 0.674 | Test Acc: 54.68%\n",
      "Epoch: 04 | Epoch Time: 0m 0s\n",
      "ComputerVision Train Loss: 0.679 | Train Acc: 47.60%\n",
      "ComputerVision Valid Loss: 0.674 | Valid Acc: 52.44%\n",
      "ComputerVision Test Loss: 0.677 | Test Acc: 53.64%\n",
      "Epoch: 05 | Epoch Time: 0m 0s\n",
      "ComputerVision Train Loss: 0.678 | Train Acc: 48.44%\n",
      "ComputerVision Valid Loss: 0.674 | Valid Acc: 52.04%\n",
      "ComputerVision Test Loss: 0.675 | Test Acc: 54.21%\n",
      "Epoch: 06 | Epoch Time: 0m 0s\n",
      "ComputerVision Train Loss: 0.680 | Train Acc: 48.02%\n",
      "ComputerVision Valid Loss: 0.673 | Valid Acc: 52.29%\n",
      "ComputerVision Test Loss: 0.674 | Test Acc: 54.50%\n",
      "Epoch: 07 | Epoch Time: 0m 0s\n",
      "ComputerVision Train Loss: 0.679 | Train Acc: 49.58%\n",
      "ComputerVision Valid Loss: 0.673 | Valid Acc: 52.71%\n",
      "ComputerVision Test Loss: 0.676 | Test Acc: 53.76%\n",
      "Epoch: 08 | Epoch Time: 0m 0s\n",
      "ComputerVision Train Loss: 0.676 | Train Acc: 50.31%\n",
      "ComputerVision Valid Loss: 0.673 | Valid Acc: 52.48%\n",
      "ComputerVision Test Loss: 0.675 | Test Acc: 54.10%\n",
      "Epoch: 09 | Epoch Time: 0m 0s\n",
      "ComputerVision Train Loss: 0.679 | Train Acc: 48.44%\n",
      "ComputerVision Valid Loss: 0.673 | Valid Acc: 52.91%\n",
      "ComputerVision Test Loss: 0.674 | Test Acc: 53.90%\n",
      "Epoch: 10 | Epoch Time: 0m 0s\n",
      "ComputerVision Train Loss: 0.676 | Train Acc: 50.83%\n",
      "ComputerVision Valid Loss: 0.673 | Valid Acc: 52.57%\n",
      "ComputerVision Test Loss: 0.672 | Test Acc: 54.91%\n",
      "Epoch: 11 | Epoch Time: 0m 0s\n",
      "ComputerVision Train Loss: 0.673 | Train Acc: 52.71%\n",
      "ComputerVision Valid Loss: 0.673 | Valid Acc: 52.44%\n",
      "ComputerVision Test Loss: 0.671 | Test Acc: 55.54%\n",
      "Epoch: 12 | Epoch Time: 0m 0s\n",
      "ComputerVision Train Loss: 0.679 | Train Acc: 47.81%\n",
      "ComputerVision Valid Loss: 0.673 | Valid Acc: 52.92%\n",
      "ComputerVision Test Loss: 0.674 | Test Acc: 54.05%\n",
      "Epoch: 13 | Epoch Time: 0m 0s\n",
      "ComputerVision Train Loss: 0.678 | Train Acc: 53.65%\n",
      "ComputerVision Valid Loss: 0.673 | Valid Acc: 52.63%\n",
      "ComputerVision Test Loss: 0.672 | Test Acc: 55.21%\n",
      "Epoch: 14 | Epoch Time: 0m 0s\n",
      "ComputerVision Train Loss: 0.681 | Train Acc: 46.77%\n",
      "ComputerVision Valid Loss: 0.673 | Valid Acc: 52.54%\n",
      "ComputerVision Test Loss: 0.671 | Test Acc: 55.33%\n",
      "Epoch: 15 | Epoch Time: 0m 0s\n",
      "ComputerVision Train Loss: 0.677 | Train Acc: 51.25%\n",
      "ComputerVision Valid Loss: 0.673 | Valid Acc: 52.51%\n",
      "ComputerVision Test Loss: 0.673 | Test Acc: 54.55%\n",
      "Epoch: 16 | Epoch Time: 0m 0s\n",
      "ComputerVision Train Loss: 0.679 | Train Acc: 44.79%\n",
      "ComputerVision Valid Loss: 0.673 | Valid Acc: 52.32%\n",
      "ComputerVision Test Loss: 0.673 | Test Acc: 54.30%\n",
      "Epoch: 17 | Epoch Time: 0m 0s\n",
      "ComputerVision Train Loss: 0.676 | Train Acc: 48.02%\n",
      "ComputerVision Valid Loss: 0.673 | Valid Acc: 52.56%\n",
      "ComputerVision Test Loss: 0.675 | Test Acc: 53.71%\n",
      "Epoch: 18 | Epoch Time: 0m 0s\n",
      "ComputerVision Train Loss: 0.675 | Train Acc: 51.04%\n",
      "ComputerVision Valid Loss: 0.673 | Valid Acc: 52.24%\n",
      "ComputerVision Test Loss: 0.675 | Test Acc: 53.74%\n",
      "Epoch: 19 | Epoch Time: 0m 0s\n",
      "ComputerVision Train Loss: 0.681 | Train Acc: 49.79%\n",
      "ComputerVision Valid Loss: 0.673 | Valid Acc: 52.55%\n",
      "ComputerVision Test Loss: 0.676 | Test Acc: 53.40%\n",
      "Epoch: 20 | Epoch Time: 0m 0s\n",
      "ComputerVision Train Loss: 0.673 | Train Acc: 51.67%\n",
      "ComputerVision Valid Loss: 0.673 | Valid Acc: 52.52%\n",
      "ComputerVision Test Loss: 0.676 | Test Acc: 53.58%\n",
      "Epoch: 21 | Epoch Time: 0m 0s\n",
      "ComputerVision Train Loss: 0.677 | Train Acc: 48.54%\n",
      "ComputerVision Valid Loss: 0.673 | Valid Acc: 52.46%\n",
      "ComputerVision Test Loss: 0.674 | Test Acc: 54.41%\n",
      "Epoch: 22 | Epoch Time: 0m 0s\n",
      "ComputerVision Train Loss: 0.677 | Train Acc: 49.58%\n",
      "ComputerVision Valid Loss: 0.673 | Valid Acc: 52.84%\n",
      "ComputerVision Test Loss: 0.675 | Test Acc: 54.00%\n",
      "Epoch: 23 | Epoch Time: 0m 0s\n",
      "ComputerVision Train Loss: 0.675 | Train Acc: 48.75%\n",
      "ComputerVision Valid Loss: 0.673 | Valid Acc: 52.89%\n",
      "ComputerVision Test Loss: 0.673 | Test Acc: 55.34%\n",
      "Epoch: 24 | Epoch Time: 0m 0s\n",
      "ComputerVision Train Loss: 0.677 | Train Acc: 49.69%\n",
      "ComputerVision Valid Loss: 0.673 | Valid Acc: 53.14%\n",
      "ComputerVision Test Loss: 0.676 | Test Acc: 54.20%\n",
      "Epoch: 25 | Epoch Time: 0m 0s\n",
      "ComputerVision Train Loss: 0.682 | Train Acc: 46.56%\n",
      "ComputerVision Valid Loss: 0.672 | Valid Acc: 52.87%\n",
      "ComputerVision Test Loss: 0.674 | Test Acc: 54.70%\n",
      "Early stopping at epoch 25 for ComputerVision model.\n",
      "Best performing epoch for ComputerVision model: 14\n"
     ]
    }
   ],
   "source": [
    "results_P2_1000_title, best_model_states = train_loop(models, optimizers, iterators, N_EPOCHS, label_names, target_field, model_file_names, best_valid_losses, \"P2\", \"1000\", 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "91a11859",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('-', 590), ('\\n  ', 444), ('for', 345), ('and', 237), (':', 223), ('of', 222), ('in', 158), ('a', 147), ('with', 139), ('network', 128), ('imag', 123), ('the', 119), ('learn', 117), ('on', 83), ('use', 83), ('to', 79), ('neural', 73), ('deep', 70), ('model', 70), ('base', 63), ('detect', 59), ('gener', 58), ('multi', 57), ('code', 57), ('from', 52), ('classif', 49), ('segment', 48), ('via', 48), ('recognit', 46), ('data', 46), ('channel', 41), ('object', 39), ('featur', 39), ('3d', 36), ('analysi', 36), ('visual', 34), ('convolut', 33), ('video', 32), ('text', 31), ('languag', 30), ('supervis', 30), ('inform', 30), ('semant', 28), ('an', 28), ('improv', 27), ('system', 27), ('optim', 26), ('attent', 26), ('adversari', 26), ('approach', 25)]\n"
     ]
    }
   ],
   "source": [
    "print(TEXT.vocab.freqs.most_common(50))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5871668e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "InformationTheory:\n",
      "[[4549 5038]\n",
      " [3401 5078]]\n",
      "Accuracy: 0.5328794420458319\n",
      "Macro Precision: 0.5370891619478204\n",
      "Macro Recall: 0.5366940465004669\n",
      "Macro F1 score: 0.5324785856287286\n",
      "MCC: 0.07378215050204674\n",
      "\n",
      "\n",
      "ComputationalLinguistics:\n",
      "[[10251  4447]\n",
      " [ 2243  1125]]\n",
      "Accuracy: 0.6296911325141149\n",
      "Macro Precision: 0.511188098212483\n",
      "Macro Recall: 0.5157339785431404\n",
      "Macro F1 score: 0.502824804373967\n",
      "MCC: 0.02653550807606708\n",
      "\n",
      "\n",
      "ComputerVision:\n",
      "[[7326 4521]\n",
      " [3559 2660]]\n",
      "Accuracy: 0.5527510240230267\n",
      "Macro Precision: 0.5217291176372192\n",
      "Macro Recall: 0.5230529498737134\n",
      "Macro F1 score: 0.5207844290775578\n",
      "MCC: 0.04476249589515029\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model_IT.load_state_dict(best_model_states[0])\n",
    "model_CL.load_state_dict(best_model_states[1])\n",
    "model_CV.load_state_dict(best_model_states[2])\n",
    "\n",
    "evaluate_model(model_IT, test_iterator_IT, \"InformationTheory\", target_field)\n",
    "evaluate_model(model_CL, test_iterator_CL, \"ComputationalLinguistics\", target_field)\n",
    "evaluate_model(model_CV, test_iterator_CV, \"ComputerVision\", target_field)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "53f023a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using all data to train models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f45fe857",
   "metadata": {},
   "outputs": [],
   "source": [
    "# P1\n",
    "target_field = \"title\"\n",
    "\n",
    "TEXT = data.Field(sequential=True, tokenize=custom_tokenizer, lower=True)\n",
    "LABEL = data.LabelField(dtype=torch.float, use_vocab = False, preprocessing = int)\n",
    "\n",
    "train_datafield = [(\"title\", TEXT), \n",
    "                   (\"abstract\", None),\n",
    "                   (\"InformationTheory\", LABEL), \n",
    "                   (\"ComputationalLinguistics\", LABEL),\n",
    "                   (\"ComputerVision\", LABEL)\n",
    "                   ]\n",
    "\n",
    "# Dataset - P1\n",
    "train_data_whole, test_data = TabularDataset.splits(\n",
    "    path = \"./\",\n",
    "    train = \"train.csv\", test = \"test.csv\", format = \"csv\",\n",
    "    skip_header = True, fields = train_datafield)\n",
    "\n",
    "\n",
    "train_data, valid_data = train_data_whole.split(split_ratio = 0.9, random_state = random.getstate())\n",
    "train_1000, remaining = train_data_whole.split(split_ratio = 1000 / len(train_data_whole), random_state = random.getstate())\n",
    "train_1000, valid_1000 = train_1000.split(split_ratio = 0.9, random_state = random.getstate())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3b65a3e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building vocab\n",
    "MAX_VOCAB_SIZE = 5000\n",
    "\n",
    "TEXT.build_vocab(train_data, max_size = MAX_VOCAB_SIZE)\n",
    "# LABEL.build_vocab(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "59eea1f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run generate_label_iterator functions\n",
    "\n",
    "train_iterator_IT, validation_IT, test_iterator_IT = generate_label_iterator(train_data, \"InformationTheory\", target_field, validation = True)\n",
    "train_iterator_CL, validation_CL, test_iterator_CL = generate_label_iterator(train_data, \"ComputationalLinguistics\", target_field, validation = True)\n",
    "train_iterator_CV, validation_CV, test_iterator_CV = generate_label_iterator(train_data, \"ComputerVision\", target_field, validation = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8699a45a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53998 58502\n",
      "85503 26997\n",
      "85499 27001\n"
     ]
    }
   ],
   "source": [
    "# Initialize counts\n",
    "negative_IT_count, positive_IT_count = 0, 0\n",
    "negative_CL_count, positive_CL_count = 0, 0\n",
    "negative_CV_count, positive_CV_count = 0, 0\n",
    "\n",
    "# Iterate through the dataset\n",
    "for example in train_data.examples:\n",
    "    if getattr(example, \"InformationTheory\") == 0:\n",
    "        negative_IT_count += 1\n",
    "    else:\n",
    "        positive_IT_count += 1\n",
    "\n",
    "    if getattr(example, \"ComputationalLinguistics\") == 0:\n",
    "        negative_CL_count += 1\n",
    "    else:\n",
    "        positive_CL_count += 1\n",
    "\n",
    "    if getattr(example, \"ComputerVision\") == 0:\n",
    "        negative_CV_count += 1\n",
    "    else:\n",
    "        positive_CV_count += 1\n",
    "        \n",
    "print(negative_CV_count, positive_CV_count)\n",
    "print(negative_IT_count, positive_IT_count)\n",
    "print(negative_CL_count, positive_CL_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c96953a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_weight_IT = torch.tensor([negative_IT_count / positive_IT_count])\n",
    "pos_weight_CL = torch.tensor([negative_CL_count / positive_CL_count])\n",
    "pos_weight_CV = torch.tensor([negative_CV_count / positive_CV_count])\n",
    "\n",
    "\n",
    "model_IT, optimizer_IT = generate_model_and_optimizer(pos_weight = pos_weight_IT)\n",
    "model_CL, optimizer_CL = generate_model_and_optimizer(pos_weight = pos_weight_CL)\n",
    "model_CV, optimizer_CV = generate_model_and_optimizer(pos_weight = pos_weight_CV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9c6d324c",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_EPOCHS = 30\n",
    "label_names = [\"InformationTheory\", \"ComputationalLinguistics\", \"ComputerVision\"]\n",
    "models = [model_IT, model_CL, model_CV]\n",
    "optimizers = [optimizer_IT, optimizer_CL, optimizer_CV]\n",
    "iterators = [(train_iterator_IT, validation_IT, test_iterator_IT), (train_iterator_CL, validation_CL, test_iterator_CL), (train_iterator_CV, validation_CV, test_iterator_CV)]\n",
    "model_file_names = [\"RNN_model_IT_A_P1_ALL\", \"RNN_model_CL_A_P1_ALL.pt\", \"RNN_model_CV_A_P1_ALL.pt\"]\n",
    "best_valid_losses = [float(\"inf\"), float(\"inf\"), float(\"inf\")]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0d270de3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('-', 75579), ('\\n  ', 55115), (':', 27824), ('learning', 15365), ('based', 10318), ('networks', 9616), ('deep', 8914), ('image', 8753), ('neural', 8506), ('detection', 7289), ('network', 6760), ('multi', 6631), ('segmentation', 5242), ('recognition', 5184), ('data', 4231), ('analysis', 4159), ('language', 4123), ('classification', 4113), ('object', 3703), ('convolutional', 3649), ('codes', 3637), ('images', 3597), ('model', 3515), ('estimation', 3473), ('models', 3444), ('visual', 3408), ('3d', 3369), ('information', 3242), ('semantic', 3144), ('text', 3098), ('video', 3058), ('adversarial', 2929), ('supervised', 2925), ('systems', 2806), ('domain', 2747), ('channel', 2676), ('approach', 2664), ('attention', 2633), ('generation', 2509), ('efficient', 2463), ('end', 2456), ('machine', 2363), ('time', 2295), ('unsupervised', 2289), ('self', 2254), ('training', 2219), ('graph', 2184), ('mimo', 2163), ('translation', 2130), ('robust', 2077)]\n",
      "5002\n"
     ]
    }
   ],
   "source": [
    "print(TEXT.vocab.freqs.most_common(50))\n",
    "print(len(TEXT.vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0e97362f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for P1_InformationTheory, using ALL data of title...\n",
      "Epoch: 01 | Epoch Time: 0m 7s\n",
      "InformationTheory Train Loss: 1.055 | Train Acc: 48.71%\n",
      "InformationTheory Valid Loss: 1.040 | Valid Acc: 59.54%\n",
      "InformationTheory Test Loss: 1.401 | Test Acc: 55.49%\n",
      "Epoch: 02 | Epoch Time: 0m 7s\n",
      "InformationTheory Train Loss: 1.054 | Train Acc: 48.95%\n",
      "InformationTheory Valid Loss: 1.025 | Valid Acc: 69.20%\n",
      "InformationTheory Test Loss: 1.413 | Test Acc: 59.14%\n",
      "Epoch: 03 | Epoch Time: 0m 7s\n",
      "InformationTheory Train Loss: 0.969 | Train Acc: 61.23%\n",
      "InformationTheory Valid Loss: 0.811 | Valid Acc: 78.21%\n",
      "InformationTheory Test Loss: 1.185 | Test Acc: 72.98%\n",
      "Epoch: 04 | Epoch Time: 0m 7s\n",
      "InformationTheory Train Loss: 0.742 | Train Acc: 77.84%\n",
      "InformationTheory Valid Loss: 0.701 | Valid Acc: 80.53%\n",
      "InformationTheory Test Loss: 1.056 | Test Acc: 76.62%\n",
      "Epoch: 05 | Epoch Time: 0m 7s\n",
      "InformationTheory Train Loss: 0.622 | Train Acc: 82.10%\n",
      "InformationTheory Valid Loss: 0.590 | Valid Acc: 86.90%\n",
      "InformationTheory Test Loss: 1.019 | Test Acc: 80.16%\n",
      "Epoch: 06 | Epoch Time: 0m 7s\n",
      "InformationTheory Train Loss: 0.431 | Train Acc: 88.37%\n",
      "InformationTheory Valid Loss: 0.451 | Valid Acc: 87.82%\n",
      "InformationTheory Test Loss: 0.730 | Test Acc: 84.68%\n",
      "Epoch: 07 | Epoch Time: 0m 7s\n",
      "InformationTheory Train Loss: 0.320 | Train Acc: 91.59%\n",
      "InformationTheory Valid Loss: 0.419 | Valid Acc: 86.80%\n",
      "InformationTheory Test Loss: 0.634 | Test Acc: 84.98%\n",
      "Epoch: 08 | Epoch Time: 0m 7s\n",
      "InformationTheory Train Loss: 0.282 | Train Acc: 92.79%\n",
      "InformationTheory Valid Loss: 0.352 | Valid Acc: 91.05%\n",
      "InformationTheory Test Loss: 0.597 | Test Acc: 88.34%\n",
      "Epoch: 09 | Epoch Time: 0m 7s\n",
      "InformationTheory Train Loss: 0.243 | Train Acc: 93.77%\n",
      "InformationTheory Valid Loss: 0.342 | Valid Acc: 90.08%\n",
      "InformationTheory Test Loss: 0.516 | Test Acc: 88.46%\n",
      "Epoch: 10 | Epoch Time: 0m 7s\n",
      "InformationTheory Train Loss: 0.225 | Train Acc: 94.36%\n",
      "InformationTheory Valid Loss: 0.320 | Valid Acc: 92.63%\n",
      "InformationTheory Test Loss: 0.626 | Test Acc: 88.84%\n",
      "Epoch: 11 | Epoch Time: 0m 7s\n",
      "InformationTheory Train Loss: 0.212 | Train Acc: 94.54%\n",
      "InformationTheory Valid Loss: 0.311 | Valid Acc: 92.31%\n",
      "InformationTheory Test Loss: 0.544 | Test Acc: 89.60%\n",
      "Epoch: 12 | Epoch Time: 0m 7s\n",
      "InformationTheory Train Loss: 0.199 | Train Acc: 94.92%\n",
      "InformationTheory Valid Loss: 0.335 | Valid Acc: 89.43%\n",
      "InformationTheory Test Loss: 0.469 | Test Acc: 88.50%\n",
      "Epoch: 13 | Epoch Time: 0m 7s\n",
      "InformationTheory Train Loss: 0.185 | Train Acc: 95.18%\n",
      "InformationTheory Valid Loss: 0.314 | Valid Acc: 93.28%\n",
      "InformationTheory Test Loss: 0.628 | Test Acc: 89.36%\n",
      "Epoch: 14 | Epoch Time: 0m 7s\n",
      "InformationTheory Train Loss: 0.178 | Train Acc: 95.50%\n",
      "InformationTheory Valid Loss: 0.305 | Valid Acc: 91.91%\n",
      "InformationTheory Test Loss: 0.505 | Test Acc: 89.77%\n",
      "Epoch: 15 | Epoch Time: 0m 7s\n",
      "InformationTheory Train Loss: 0.170 | Train Acc: 95.70%\n",
      "InformationTheory Valid Loss: 0.304 | Valid Acc: 91.87%\n",
      "InformationTheory Test Loss: 0.487 | Test Acc: 89.61%\n",
      "Epoch: 16 | Epoch Time: 0m 7s\n",
      "InformationTheory Train Loss: 0.161 | Train Acc: 95.93%\n",
      "InformationTheory Valid Loss: 0.302 | Valid Acc: 92.77%\n",
      "InformationTheory Test Loss: 0.542 | Test Acc: 90.04%\n",
      "Epoch: 17 | Epoch Time: 0m 7s\n",
      "InformationTheory Train Loss: 0.154 | Train Acc: 96.09%\n",
      "InformationTheory Valid Loss: 0.304 | Valid Acc: 92.01%\n",
      "InformationTheory Test Loss: 0.485 | Test Acc: 90.01%\n",
      "Epoch: 18 | Epoch Time: 0m 7s\n",
      "InformationTheory Train Loss: 0.147 | Train Acc: 96.25%\n",
      "InformationTheory Valid Loss: 0.313 | Valid Acc: 91.60%\n",
      "InformationTheory Test Loss: 0.483 | Test Acc: 89.87%\n",
      "Early stopping at epoch 18 for InformationTheory model.\n",
      "Best performing epoch for InformationTheory model: 12\n",
      "Training model for P1_ComputationalLinguistics, using ALL data of title...\n",
      "Epoch: 01 | Epoch Time: 0m 7s\n",
      "ComputationalLinguistics Train Loss: 1.055 | Train Acc: 48.27%\n",
      "ComputationalLinguistics Valid Loss: 1.046 | Valid Acc: 58.59%\n",
      "ComputationalLinguistics Test Loss: 0.965 | Test Acc: 57.31%\n",
      "Epoch: 02 | Epoch Time: 0m 7s\n",
      "ComputationalLinguistics Train Loss: 1.054 | Train Acc: 49.46%\n",
      "ComputationalLinguistics Valid Loss: 1.033 | Valid Acc: 64.82%\n",
      "ComputationalLinguistics Test Loss: 0.946 | Test Acc: 65.42%\n",
      "Epoch: 03 | Epoch Time: 0m 7s\n",
      "ComputationalLinguistics Train Loss: 1.033 | Train Acc: 53.12%\n",
      "ComputationalLinguistics Valid Loss: 1.039 | Valid Acc: 64.95%\n",
      "ComputationalLinguistics Test Loss: 0.949 | Test Acc: 68.53%\n",
      "Epoch: 04 | Epoch Time: 0m 7s\n",
      "ComputationalLinguistics Train Loss: 0.911 | Train Acc: 68.72%\n",
      "ComputationalLinguistics Valid Loss: 0.839 | Valid Acc: 77.42%\n",
      "ComputationalLinguistics Test Loss: 0.761 | Test Acc: 78.54%\n",
      "Epoch: 05 | Epoch Time: 0m 7s\n",
      "ComputationalLinguistics Train Loss: 0.796 | Train Acc: 75.06%\n",
      "ComputationalLinguistics Valid Loss: 0.786 | Valid Acc: 75.06%\n",
      "ComputationalLinguistics Test Loss: 0.748 | Test Acc: 75.01%\n",
      "Epoch: 06 | Epoch Time: 0m 7s\n",
      "ComputationalLinguistics Train Loss: 0.732 | Train Acc: 77.97%\n",
      "ComputationalLinguistics Valid Loss: 0.721 | Valid Acc: 73.42%\n",
      "ComputationalLinguistics Test Loss: 0.728 | Test Acc: 71.36%\n",
      "Epoch: 07 | Epoch Time: 0m 7s\n",
      "ComputationalLinguistics Train Loss: 0.615 | Train Acc: 82.25%\n",
      "ComputationalLinguistics Valid Loss: 0.619 | Valid Acc: 78.59%\n",
      "ComputationalLinguistics Test Loss: 0.633 | Test Acc: 76.40%\n",
      "Epoch: 08 | Epoch Time: 0m 7s\n",
      "ComputationalLinguistics Train Loss: 0.517 | Train Acc: 85.78%\n",
      "ComputationalLinguistics Valid Loss: 0.592 | Valid Acc: 80.00%\n",
      "ComputationalLinguistics Test Loss: 0.601 | Test Acc: 78.21%\n",
      "Epoch: 09 | Epoch Time: 0m 7s\n",
      "ComputationalLinguistics Train Loss: 0.453 | Train Acc: 87.67%\n",
      "ComputationalLinguistics Valid Loss: 0.507 | Valid Acc: 85.35%\n",
      "ComputationalLinguistics Test Loss: 0.526 | Test Acc: 83.75%\n",
      "Epoch: 10 | Epoch Time: 0m 7s\n",
      "ComputationalLinguistics Train Loss: 0.399 | Train Acc: 89.45%\n",
      "ComputationalLinguistics Valid Loss: 0.477 | Valid Acc: 84.85%\n",
      "ComputationalLinguistics Test Loss: 0.507 | Test Acc: 83.24%\n",
      "Epoch: 11 | Epoch Time: 0m 7s\n",
      "ComputationalLinguistics Train Loss: 0.365 | Train Acc: 90.52%\n",
      "ComputationalLinguistics Valid Loss: 0.465 | Valid Acc: 86.93%\n",
      "ComputationalLinguistics Test Loss: 0.471 | Test Acc: 85.98%\n",
      "Epoch: 12 | Epoch Time: 0m 7s\n",
      "ComputationalLinguistics Train Loss: 0.344 | Train Acc: 90.96%\n",
      "ComputationalLinguistics Valid Loss: 0.508 | Valid Acc: 81.64%\n",
      "ComputationalLinguistics Test Loss: 0.545 | Test Acc: 79.42%\n",
      "Epoch: 13 | Epoch Time: 0m 7s\n",
      "ComputationalLinguistics Train Loss: 0.323 | Train Acc: 91.38%\n",
      "ComputationalLinguistics Valid Loss: 0.430 | Valid Acc: 87.82%\n",
      "ComputationalLinguistics Test Loss: 0.447 | Test Acc: 86.57%\n",
      "Epoch: 14 | Epoch Time: 0m 7s\n",
      "ComputationalLinguistics Train Loss: 0.310 | Train Acc: 91.73%\n",
      "ComputationalLinguistics Valid Loss: 0.428 | Valid Acc: 88.85%\n",
      "ComputationalLinguistics Test Loss: 0.437 | Test Acc: 88.34%\n",
      "Epoch: 15 | Epoch Time: 0m 7s\n",
      "ComputationalLinguistics Train Loss: 0.292 | Train Acc: 92.34%\n",
      "ComputationalLinguistics Valid Loss: 0.427 | Valid Acc: 87.42%\n",
      "ComputationalLinguistics Test Loss: 0.456 | Test Acc: 85.66%\n",
      "Epoch: 16 | Epoch Time: 0m 7s\n",
      "ComputationalLinguistics Train Loss: 0.282 | Train Acc: 92.42%\n",
      "ComputationalLinguistics Valid Loss: 0.403 | Valid Acc: 88.21%\n",
      "ComputationalLinguistics Test Loss: 0.435 | Test Acc: 86.86%\n",
      "Epoch: 17 | Epoch Time: 0m 7s\n",
      "ComputationalLinguistics Train Loss: 0.269 | Train Acc: 92.75%\n",
      "ComputationalLinguistics Valid Loss: 0.420 | Valid Acc: 89.94%\n",
      "ComputationalLinguistics Test Loss: 0.433 | Test Acc: 89.20%\n",
      "Epoch: 18 | Epoch Time: 0m 7s\n",
      "ComputationalLinguistics Train Loss: 0.259 | Train Acc: 93.07%\n",
      "ComputationalLinguistics Valid Loss: 0.424 | Valid Acc: 89.06%\n",
      "ComputationalLinguistics Test Loss: 0.434 | Test Acc: 88.59%\n",
      "Epoch: 19 | Epoch Time: 0m 7s\n",
      "ComputationalLinguistics Train Loss: 0.249 | Train Acc: 93.23%\n",
      "ComputationalLinguistics Valid Loss: 0.403 | Valid Acc: 88.13%\n",
      "ComputationalLinguistics Test Loss: 0.437 | Test Acc: 86.48%\n",
      "Epoch: 20 | Epoch Time: 0m 7s\n",
      "ComputationalLinguistics Train Loss: 0.239 | Train Acc: 93.37%\n",
      "ComputationalLinguistics Valid Loss: 0.400 | Valid Acc: 89.38%\n",
      "ComputationalLinguistics Test Loss: 0.420 | Test Acc: 88.31%\n",
      "Epoch: 21 | Epoch Time: 0m 7s\n",
      "ComputationalLinguistics Train Loss: 0.230 | Train Acc: 93.55%\n",
      "ComputationalLinguistics Valid Loss: 0.395 | Valid Acc: 88.85%\n",
      "ComputationalLinguistics Test Loss: 0.421 | Test Acc: 87.68%\n",
      "Epoch: 22 | Epoch Time: 0m 7s\n",
      "ComputationalLinguistics Train Loss: 0.223 | Train Acc: 93.89%\n",
      "ComputationalLinguistics Valid Loss: 0.402 | Valid Acc: 89.33%\n",
      "ComputationalLinguistics Test Loss: 0.427 | Test Acc: 88.00%\n",
      "Epoch: 23 | Epoch Time: 0m 7s\n",
      "ComputationalLinguistics Train Loss: 0.213 | Train Acc: 93.96%\n",
      "ComputationalLinguistics Valid Loss: 0.394 | Valid Acc: 89.56%\n",
      "ComputationalLinguistics Test Loss: 0.416 | Test Acc: 88.85%\n",
      "Epoch: 24 | Epoch Time: 0m 7s\n",
      "ComputationalLinguistics Train Loss: 0.211 | Train Acc: 94.03%\n",
      "ComputationalLinguistics Valid Loss: 0.399 | Valid Acc: 88.92%\n",
      "ComputationalLinguistics Test Loss: 0.434 | Test Acc: 87.39%\n",
      "Epoch: 25 | Epoch Time: 0m 7s\n",
      "ComputationalLinguistics Train Loss: 0.201 | Train Acc: 94.31%\n",
      "ComputationalLinguistics Valid Loss: 0.399 | Valid Acc: 90.02%\n",
      "ComputationalLinguistics Test Loss: 0.414 | Test Acc: 89.05%\n",
      "Epoch: 26 | Epoch Time: 0m 7s\n",
      "ComputationalLinguistics Train Loss: 0.198 | Train Acc: 94.47%\n",
      "ComputationalLinguistics Valid Loss: 0.409 | Valid Acc: 89.96%\n",
      "ComputationalLinguistics Test Loss: 0.424 | Test Acc: 89.24%\n",
      "Epoch: 27 | Epoch Time: 0m 7s\n",
      "ComputationalLinguistics Train Loss: 0.185 | Train Acc: 94.77%\n",
      "ComputationalLinguistics Valid Loss: 0.410 | Valid Acc: 89.73%\n",
      "ComputationalLinguistics Test Loss: 0.424 | Test Acc: 88.87%\n",
      "Epoch: 28 | Epoch Time: 0m 7s\n",
      "ComputationalLinguistics Train Loss: 0.188 | Train Acc: 94.64%\n",
      "ComputationalLinguistics Valid Loss: 0.402 | Valid Acc: 90.47%\n",
      "ComputationalLinguistics Test Loss: 0.415 | Test Acc: 89.63%\n",
      "Epoch: 29 | Epoch Time: 0m 7s\n",
      "ComputationalLinguistics Train Loss: 0.177 | Train Acc: 94.94%\n",
      "ComputationalLinguistics Valid Loss: 0.396 | Valid Acc: 89.52%\n",
      "ComputationalLinguistics Test Loss: 0.423 | Test Acc: 88.45%\n",
      "Epoch: 30 | Epoch Time: 0m 7s\n",
      "ComputationalLinguistics Train Loss: 0.173 | Train Acc: 94.97%\n",
      "ComputationalLinguistics Valid Loss: 0.400 | Valid Acc: 89.39%\n",
      "ComputationalLinguistics Test Loss: 0.420 | Test Acc: 88.53%\n",
      "Training model for P1_ComputerVision, using ALL data of title...\n",
      "Epoch: 01 | Epoch Time: 0m 7s\n",
      "ComputerVision Train Loss: 0.666 | Train Acc: 49.98%\n",
      "ComputerVision Valid Loss: 0.662 | Valid Acc: 53.04%\n",
      "ComputerVision Test Loss: 0.676 | Test Acc: 50.65%\n",
      "Epoch: 02 | Epoch Time: 0m 7s\n",
      "ComputerVision Train Loss: 0.666 | Train Acc: 50.07%\n",
      "ComputerVision Valid Loss: 0.655 | Valid Acc: 55.76%\n",
      "ComputerVision Test Loss: 0.678 | Test Acc: 49.89%\n",
      "Epoch: 03 | Epoch Time: 0m 7s\n",
      "ComputerVision Train Loss: 0.665 | Train Acc: 50.41%\n",
      "ComputerVision Valid Loss: 0.648 | Valid Acc: 56.47%\n",
      "ComputerVision Test Loss: 0.678 | Test Acc: 49.32%\n",
      "Epoch: 04 | Epoch Time: 0m 7s\n",
      "ComputerVision Train Loss: 0.664 | Train Acc: 50.85%\n",
      "ComputerVision Valid Loss: 0.641 | Valid Acc: 58.09%\n",
      "ComputerVision Test Loss: 0.677 | Test Acc: 50.33%\n",
      "Epoch: 05 | Epoch Time: 0m 7s\n",
      "ComputerVision Train Loss: 0.611 | Train Acc: 62.40%\n",
      "ComputerVision Valid Loss: 0.563 | Valid Acc: 70.83%\n",
      "ComputerVision Test Loss: 0.591 | Test Acc: 67.76%\n",
      "Epoch: 06 | Epoch Time: 0m 7s\n",
      "ComputerVision Train Loss: 0.534 | Train Acc: 72.04%\n",
      "ComputerVision Valid Loss: 0.518 | Valid Acc: 73.10%\n",
      "ComputerVision Test Loss: 0.546 | Test Acc: 70.58%\n",
      "Epoch: 07 | Epoch Time: 0m 7s\n",
      "ComputerVision Train Loss: 0.504 | Train Acc: 73.93%\n",
      "ComputerVision Valid Loss: 0.506 | Valid Acc: 73.96%\n",
      "ComputerVision Test Loss: 0.549 | Test Acc: 70.12%\n",
      "Epoch: 08 | Epoch Time: 0m 7s\n",
      "ComputerVision Train Loss: 0.461 | Train Acc: 76.87%\n",
      "ComputerVision Valid Loss: 0.463 | Valid Acc: 77.05%\n",
      "ComputerVision Test Loss: 0.501 | Test Acc: 73.69%\n",
      "Epoch: 09 | Epoch Time: 0m 7s\n",
      "ComputerVision Train Loss: 0.397 | Train Acc: 81.01%\n",
      "ComputerVision Valid Loss: 0.430 | Valid Acc: 78.85%\n",
      "ComputerVision Test Loss: 0.494 | Test Acc: 74.66%\n",
      "Epoch: 10 | Epoch Time: 0m 7s\n",
      "ComputerVision Train Loss: 0.341 | Train Acc: 84.28%\n",
      "ComputerVision Valid Loss: 0.374 | Valid Acc: 82.54%\n",
      "ComputerVision Test Loss: 0.406 | Test Acc: 80.58%\n",
      "Epoch: 11 | Epoch Time: 0m 7s\n",
      "ComputerVision Train Loss: 0.304 | Train Acc: 86.47%\n",
      "ComputerVision Valid Loss: 0.360 | Valid Acc: 83.57%\n",
      "ComputerVision Test Loss: 0.410 | Test Acc: 80.49%\n",
      "Epoch: 12 | Epoch Time: 0m 7s\n",
      "ComputerVision Train Loss: 0.278 | Train Acc: 87.85%\n",
      "ComputerVision Valid Loss: 0.348 | Valid Acc: 84.35%\n",
      "ComputerVision Test Loss: 0.348 | Test Acc: 84.06%\n",
      "Epoch: 13 | Epoch Time: 0m 7s\n",
      "ComputerVision Train Loss: 0.257 | Train Acc: 88.84%\n",
      "ComputerVision Valid Loss: 0.333 | Valid Acc: 85.19%\n",
      "ComputerVision Test Loss: 0.383 | Test Acc: 82.02%\n",
      "Epoch: 14 | Epoch Time: 0m 7s\n",
      "ComputerVision Train Loss: 0.246 | Train Acc: 89.29%\n",
      "ComputerVision Valid Loss: 0.321 | Valid Acc: 85.60%\n",
      "ComputerVision Test Loss: 0.364 | Test Acc: 82.96%\n",
      "Epoch: 15 | Epoch Time: 0m 7s\n",
      "ComputerVision Train Loss: 0.232 | Train Acc: 90.08%\n",
      "ComputerVision Valid Loss: 0.312 | Valid Acc: 86.09%\n",
      "ComputerVision Test Loss: 0.319 | Test Acc: 85.73%\n",
      "Epoch: 16 | Epoch Time: 0m 7s\n",
      "ComputerVision Train Loss: 0.224 | Train Acc: 90.49%\n",
      "ComputerVision Valid Loss: 0.304 | Valid Acc: 86.99%\n",
      "ComputerVision Test Loss: 0.331 | Test Acc: 85.41%\n",
      "Epoch: 17 | Epoch Time: 0m 7s\n",
      "ComputerVision Train Loss: 0.215 | Train Acc: 90.83%\n",
      "ComputerVision Valid Loss: 0.304 | Valid Acc: 86.65%\n",
      "ComputerVision Test Loss: 0.341 | Test Acc: 84.36%\n",
      "Epoch: 18 | Epoch Time: 0m 7s\n",
      "ComputerVision Train Loss: 0.208 | Train Acc: 91.21%\n",
      "ComputerVision Valid Loss: 0.292 | Valid Acc: 87.31%\n",
      "ComputerVision Test Loss: 0.316 | Test Acc: 85.86%\n",
      "Epoch: 19 | Epoch Time: 0m 7s\n",
      "ComputerVision Train Loss: 0.202 | Train Acc: 91.55%\n",
      "ComputerVision Valid Loss: 0.290 | Valid Acc: 87.56%\n",
      "ComputerVision Test Loss: 0.315 | Test Acc: 85.99%\n",
      "Epoch: 20 | Epoch Time: 0m 7s\n",
      "ComputerVision Train Loss: 0.198 | Train Acc: 91.79%\n",
      "ComputerVision Valid Loss: 0.288 | Valid Acc: 87.23%\n",
      "ComputerVision Test Loss: 0.310 | Test Acc: 85.98%\n",
      "Epoch: 21 | Epoch Time: 0m 7s\n",
      "ComputerVision Train Loss: 0.191 | Train Acc: 92.08%\n",
      "ComputerVision Valid Loss: 0.286 | Valid Acc: 87.43%\n",
      "ComputerVision Test Loss: 0.322 | Test Acc: 85.28%\n",
      "Epoch: 22 | Epoch Time: 0m 7s\n",
      "ComputerVision Train Loss: 0.185 | Train Acc: 92.28%\n",
      "ComputerVision Valid Loss: 0.288 | Valid Acc: 87.37%\n",
      "ComputerVision Test Loss: 0.320 | Test Acc: 85.31%\n",
      "Epoch: 23 | Epoch Time: 0m 7s\n",
      "ComputerVision Train Loss: 0.183 | Train Acc: 92.46%\n",
      "ComputerVision Valid Loss: 0.283 | Valid Acc: 87.54%\n",
      "ComputerVision Test Loss: 0.320 | Test Acc: 85.18%\n",
      "Epoch: 24 | Epoch Time: 0m 7s\n",
      "ComputerVision Train Loss: 0.177 | Train Acc: 92.68%\n",
      "ComputerVision Valid Loss: 0.279 | Valid Acc: 87.65%\n",
      "ComputerVision Test Loss: 0.288 | Test Acc: 87.30%\n",
      "Epoch: 25 | Epoch Time: 0m 7s\n",
      "ComputerVision Train Loss: 0.174 | Train Acc: 92.81%\n",
      "ComputerVision Valid Loss: 0.277 | Valid Acc: 87.68%\n",
      "ComputerVision Test Loss: 0.299 | Test Acc: 86.36%\n",
      "Epoch: 26 | Epoch Time: 0m 7s\n",
      "ComputerVision Train Loss: 0.171 | Train Acc: 92.91%\n",
      "ComputerVision Valid Loss: 0.276 | Valid Acc: 87.51%\n",
      "ComputerVision Test Loss: 0.301 | Test Acc: 86.29%\n",
      "Epoch: 27 | Epoch Time: 0m 7s\n",
      "ComputerVision Train Loss: 0.166 | Train Acc: 93.13%\n",
      "ComputerVision Valid Loss: 0.273 | Valid Acc: 87.58%\n",
      "ComputerVision Test Loss: 0.292 | Test Acc: 87.03%\n",
      "Epoch: 28 | Epoch Time: 0m 7s\n",
      "ComputerVision Train Loss: 0.162 | Train Acc: 93.32%\n",
      "ComputerVision Valid Loss: 0.277 | Valid Acc: 87.63%\n",
      "ComputerVision Test Loss: 0.294 | Test Acc: 86.57%\n",
      "Epoch: 29 | Epoch Time: 0m 7s\n",
      "ComputerVision Train Loss: 0.158 | Train Acc: 93.52%\n",
      "ComputerVision Valid Loss: 0.276 | Valid Acc: 87.51%\n",
      "ComputerVision Test Loss: 0.296 | Test Acc: 86.56%\n",
      "Epoch: 30 | Epoch Time: 0m 7s\n",
      "ComputerVision Train Loss: 0.155 | Train Acc: 93.60%\n",
      "ComputerVision Valid Loss: 0.271 | Valid Acc: 87.62%\n",
      "ComputerVision Test Loss: 0.295 | Test Acc: 86.74%\n",
      "Early stopping at epoch 30 for ComputerVision model.\n",
      "Best performing epoch for ComputerVision model: 24\n"
     ]
    }
   ],
   "source": [
    "RESULTS_T_P1_ALL, best_model_states = train_loop(models, optimizers, iterators, N_EPOCHS, label_names, target_field, model_file_names, best_valid_losses, \"P1\", \"ALL\", 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e03f53d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "InformationTheory:\n",
      "[[8133 1454]\n",
      " [ 629 7850]]\n",
      "Accuracy: 0.8847005424554412\n",
      "Macro Precision: 0.8859679333273538\n",
      "Macro Recall: 0.8870765061972792\n",
      "Macro F1 score: 0.8846722426984712\n",
      "MCC: 0.773043644658014\n",
      "\n",
      "\n",
      "ComputationalLinguistics:\n",
      "[[13334  1364]\n",
      " [  616  2752]]\n",
      "Accuracy: 0.8904018598472269\n",
      "Macro Precision: 0.8122262975850862\n",
      "Macro Recall: 0.8621501980168258\n",
      "Macro F1 score: 0.8331604117640299\n",
      "MCC: 0.6725260307125648\n",
      "\n",
      "\n",
      "ComputerVision:\n",
      "[[10423  1424]\n",
      " [  877  5342]]\n",
      "Accuracy: 0.8726336765194288\n",
      "Macro Precision: 0.8559626476997166\n",
      "Macro Recall: 0.8693906684727787\n",
      "Macro F1 score: 0.8616937013321913\n",
      "MCC: 0.725229013167947\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model_IT.load_state_dict(best_model_states[0])\n",
    "model_CL.load_state_dict(best_model_states[1])\n",
    "model_CV.load_state_dict(best_model_states[2])\n",
    "\n",
    "evaluate_model(model_IT, test_iterator_IT, \"InformationTheory\", target_field)\n",
    "evaluate_model(model_CL, test_iterator_CL, \"ComputationalLinguistics\", target_field)\n",
    "evaluate_model(model_CV, test_iterator_CV, \"ComputerVision\", target_field)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b67465ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# P2\n",
    "def custom_tokenizer_P2(text):\n",
    "    return [ps.stem(tok.text) for tok in spacy_en.tokenizer(text)]\n",
    "\n",
    "target_field = \"title\"\n",
    "TEXT = data.Field(sequential=True, tokenize=custom_tokenizer_P2, lower=False)\n",
    "LABEL = data.LabelField(dtype=torch.float, use_vocab = False, preprocessing = int)\n",
    "\n",
    "train_datafield = [(\"title\", TEXT), \n",
    "                   (\"abstract\", None),\n",
    "                   (\"InformationTheory\", LABEL), \n",
    "                   (\"ComputationalLinguistics\", LABEL),\n",
    "                   (\"ComputerVision\", LABEL)\n",
    "                   ]\n",
    "\n",
    "train_data_whole, test_data = TabularDataset.splits(\n",
    "    path = \"./\",\n",
    "    train = \"train.csv\", test = \"test.csv\", format = \"csv\",\n",
    "    skip_header = True, fields = train_datafield)\n",
    "\n",
    "train_data, valid_data = train_data_whole.split(split_ratio = 0.9, random_state = random.getstate())\n",
    "train_1000, remaining = train_data_whole.split(split_ratio = 1000 / len(train_data_whole), random_state = random.getstate())\n",
    "train_1000, valid_1000 = train_1000.split(split_ratio = 0.9, random_state = random.getstate())\n",
    "\n",
    "# Building vocab\n",
    "MAX_VOCAB_SIZE = 5000\n",
    "\n",
    "TEXT.build_vocab(train_data, max_size = MAX_VOCAB_SIZE)\n",
    "# LABEL.build_vocab(train_data)\n",
    "\n",
    "train_iterator_IT, validation_IT, test_iterator_IT = generate_label_iterator(train_data, \"InformationTheory\", target_field, validation = True)\n",
    "train_iterator_CL, validation_CL, test_iterator_CL = generate_label_iterator(train_data, \"ComputationalLinguistics\", target_field, validation = True)\n",
    "train_iterator_CV, validation_CV, test_iterator_CV = generate_label_iterator(train_data, \"ComputerVision\", target_field, validation = True)\n",
    "\n",
    "\n",
    "model_IT, optimizer_IT = generate_model_and_optimizer(pos_weight = pos_weight_IT)\n",
    "model_CL, optimizer_CL = generate_model_and_optimizer(pos_weight = pos_weight_CL)\n",
    "model_CV, optimizer_CV = generate_model_and_optimizer(pos_weight = pos_weight_CV)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5ced7af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_EPOCHS = 30\n",
    "label_names = [\"InformationTheory\", \"ComputationalLinguistics\", \"ComputerVision\"]\n",
    "models = [model_IT, model_CL, model_CV]\n",
    "optimizers = [optimizer_IT, optimizer_CL, optimizer_CV]\n",
    "iterators = [(train_iterator_IT, validation_IT, test_iterator_IT), (train_iterator_CL, validation_CL, test_iterator_CL), (train_iterator_CV, validation_CV, test_iterator_CV)]\n",
    "model_file_names = [\"RNN_model_IT\", \"RNN_model_CL.pt\", \"RNN_model_CV.pt\"]\n",
    "best_valid_losses = [float(\"inf\"), float(\"inf\"), float(\"inf\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "19781a66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for P2_InformationTheory, using ALL data of title...\n",
      "Epoch: 01 | Epoch Time: 0m 8s\n",
      "InformationTheory Train Loss: 1.056 | Train Acc: 49.32%\n",
      "InformationTheory Valid Loss: 1.035 | Valid Acc: 64.34%\n",
      "InformationTheory Test Loss: 1.421 | Test Acc: 54.86%\n",
      "Epoch: 02 | Epoch Time: 0m 8s\n",
      "InformationTheory Train Loss: 1.055 | Train Acc: 49.15%\n",
      "InformationTheory Valid Loss: 1.025 | Valid Acc: 69.75%\n",
      "InformationTheory Test Loss: 1.423 | Test Acc: 57.06%\n",
      "Epoch: 03 | Epoch Time: 0m 8s\n",
      "InformationTheory Train Loss: 1.054 | Train Acc: 50.17%\n",
      "InformationTheory Valid Loss: 1.016 | Valid Acc: 70.48%\n",
      "InformationTheory Test Loss: 1.414 | Test Acc: 58.57%\n",
      "Epoch: 04 | Epoch Time: 0m 8s\n",
      "InformationTheory Train Loss: 1.053 | Train Acc: 49.85%\n",
      "InformationTheory Valid Loss: 1.008 | Valid Acc: 70.15%\n",
      "InformationTheory Test Loss: 1.410 | Test Acc: 59.97%\n",
      "Epoch: 05 | Epoch Time: 0m 8s\n",
      "InformationTheory Train Loss: 1.053 | Train Acc: 49.39%\n",
      "InformationTheory Valid Loss: 1.002 | Valid Acc: 72.70%\n",
      "InformationTheory Test Loss: 1.411 | Test Acc: 61.07%\n",
      "Epoch: 06 | Epoch Time: 0m 8s\n",
      "InformationTheory Train Loss: 1.015 | Train Acc: 54.03%\n",
      "InformationTheory Valid Loss: 0.971 | Valid Acc: 57.01%\n",
      "InformationTheory Test Loss: 1.298 | Test Acc: 60.97%\n",
      "Epoch: 07 | Epoch Time: 0m 8s\n",
      "InformationTheory Train Loss: 0.971 | Train Acc: 60.02%\n",
      "InformationTheory Valid Loss: 1.045 | Valid Acc: 36.43%\n",
      "InformationTheory Test Loss: 1.313 | Test Acc: 50.50%\n",
      "Epoch: 08 | Epoch Time: 0m 8s\n",
      "InformationTheory Train Loss: 1.055 | Train Acc: 50.57%\n",
      "InformationTheory Valid Loss: 1.062 | Valid Acc: 73.24%\n",
      "InformationTheory Test Loss: 1.503 | Test Acc: 52.19%\n",
      "Epoch: 09 | Epoch Time: 0m 8s\n",
      "InformationTheory Train Loss: 1.052 | Train Acc: 50.51%\n",
      "InformationTheory Valid Loss: 1.033 | Valid Acc: 44.03%\n",
      "InformationTheory Test Loss: 1.361 | Test Acc: 52.59%\n",
      "Epoch: 10 | Epoch Time: 0m 8s\n",
      "InformationTheory Train Loss: 1.050 | Train Acc: 49.32%\n",
      "InformationTheory Valid Loss: 1.030 | Valid Acc: 67.77%\n",
      "InformationTheory Test Loss: 1.422 | Test Acc: 56.66%\n",
      "Epoch: 11 | Epoch Time: 0m 8s\n",
      "InformationTheory Train Loss: 1.049 | Train Acc: 49.28%\n",
      "InformationTheory Valid Loss: 1.023 | Valid Acc: 45.39%\n",
      "InformationTheory Test Loss: 1.347 | Test Acc: 53.55%\n",
      "Epoch: 12 | Epoch Time: 0m 8s\n",
      "InformationTheory Train Loss: 1.050 | Train Acc: 50.09%\n",
      "InformationTheory Valid Loss: 1.043 | Valid Acc: 75.17%\n",
      "InformationTheory Test Loss: 1.489 | Test Acc: 54.64%\n",
      "Early stopping at epoch 12 for InformationTheory model.\n",
      "Best performing epoch for InformationTheory model: 6\n",
      "Training model for P2_ComputationalLinguistics, using ALL data of title...\n",
      "Epoch: 01 | Epoch Time: 0m 8s\n",
      "ComputationalLinguistics Train Loss: 1.056 | Train Acc: 49.65%\n",
      "ComputationalLinguistics Valid Loss: 1.051 | Valid Acc: 53.18%\n",
      "ComputationalLinguistics Test Loss: 0.973 | Test Acc: 52.62%\n",
      "Epoch: 02 | Epoch Time: 0m 8s\n",
      "ComputationalLinguistics Train Loss: 1.055 | Train Acc: 50.02%\n",
      "ComputationalLinguistics Valid Loss: 1.042 | Valid Acc: 52.11%\n",
      "ComputationalLinguistics Test Loss: 0.966 | Test Acc: 50.54%\n",
      "Epoch: 03 | Epoch Time: 0m 8s\n",
      "ComputationalLinguistics Train Loss: 1.054 | Train Acc: 48.82%\n",
      "ComputationalLinguistics Valid Loss: 1.035 | Valid Acc: 55.33%\n",
      "ComputationalLinguistics Test Loss: 0.958 | Test Acc: 54.00%\n",
      "Epoch: 04 | Epoch Time: 0m 8s\n",
      "ComputationalLinguistics Train Loss: 1.054 | Train Acc: 50.91%\n",
      "ComputationalLinguistics Valid Loss: 1.028 | Valid Acc: 56.85%\n",
      "ComputationalLinguistics Test Loss: 0.953 | Test Acc: 55.51%\n",
      "Epoch: 05 | Epoch Time: 0m 8s\n",
      "ComputationalLinguistics Train Loss: 1.053 | Train Acc: 49.30%\n",
      "ComputationalLinguistics Valid Loss: 1.023 | Valid Acc: 57.39%\n",
      "ComputationalLinguistics Test Loss: 0.948 | Test Acc: 56.11%\n",
      "Epoch: 06 | Epoch Time: 0m 8s\n",
      "ComputationalLinguistics Train Loss: 1.053 | Train Acc: 50.62%\n",
      "ComputationalLinguistics Valid Loss: 1.017 | Valid Acc: 59.80%\n",
      "ComputationalLinguistics Test Loss: 0.942 | Test Acc: 58.16%\n",
      "Epoch: 07 | Epoch Time: 0m 8s\n",
      "ComputationalLinguistics Train Loss: 1.023 | Train Acc: 54.51%\n",
      "ComputationalLinguistics Valid Loss: 0.946 | Valid Acc: 59.69%\n",
      "ComputationalLinguistics Test Loss: 0.900 | Test Acc: 56.44%\n",
      "Epoch: 08 | Epoch Time: 0m 8s\n",
      "ComputationalLinguistics Train Loss: 0.928 | Train Acc: 67.97%\n",
      "ComputationalLinguistics Valid Loss: 0.934 | Valid Acc: 69.60%\n",
      "ComputationalLinguistics Test Loss: 0.873 | Test Acc: 67.82%\n",
      "Epoch: 09 | Epoch Time: 0m 8s\n",
      "ComputationalLinguistics Train Loss: 0.890 | Train Acc: 70.75%\n",
      "ComputationalLinguistics Valid Loss: 0.950 | Valid Acc: 67.33%\n",
      "ComputationalLinguistics Test Loss: 0.881 | Test Acc: 66.66%\n",
      "Epoch: 10 | Epoch Time: 0m 8s\n",
      "ComputationalLinguistics Train Loss: 0.820 | Train Acc: 74.99%\n",
      "ComputationalLinguistics Valid Loss: 0.896 | Valid Acc: 65.91%\n",
      "ComputationalLinguistics Test Loss: 0.864 | Test Acc: 63.97%\n",
      "Epoch: 11 | Epoch Time: 0m 8s\n",
      "ComputationalLinguistics Train Loss: 0.793 | Train Acc: 75.61%\n",
      "ComputationalLinguistics Valid Loss: 0.842 | Valid Acc: 69.62%\n",
      "ComputationalLinguistics Test Loss: 0.817 | Test Acc: 68.08%\n",
      "Epoch: 12 | Epoch Time: 0m 8s\n",
      "ComputationalLinguistics Train Loss: 0.728 | Train Acc: 78.57%\n",
      "ComputationalLinguistics Valid Loss: 0.727 | Valid Acc: 78.19%\n",
      "ComputationalLinguistics Test Loss: 0.693 | Test Acc: 77.47%\n",
      "Epoch: 13 | Epoch Time: 0m 8s\n",
      "ComputationalLinguistics Train Loss: 0.918 | Train Acc: 63.85%\n",
      "ComputationalLinguistics Valid Loss: 0.943 | Valid Acc: 63.52%\n",
      "ComputationalLinguistics Test Loss: 0.882 | Test Acc: 62.58%\n",
      "Epoch: 14 | Epoch Time: 0m 8s\n",
      "ComputationalLinguistics Train Loss: 1.052 | Train Acc: 52.09%\n",
      "ComputationalLinguistics Valid Loss: 0.969 | Valid Acc: 72.48%\n",
      "ComputationalLinguistics Test Loss: 0.887 | Test Acc: 73.22%\n",
      "Epoch: 15 | Epoch Time: 0m 8s\n",
      "ComputationalLinguistics Train Loss: 0.929 | Train Acc: 65.59%\n",
      "ComputationalLinguistics Valid Loss: 0.727 | Valid Acc: 75.10%\n",
      "ComputationalLinguistics Test Loss: 0.742 | Test Acc: 72.44%\n",
      "Epoch: 16 | Epoch Time: 0m 8s\n",
      "ComputationalLinguistics Train Loss: 0.811 | Train Acc: 70.58%\n",
      "ComputationalLinguistics Valid Loss: 0.653 | Valid Acc: 83.17%\n",
      "ComputationalLinguistics Test Loss: 0.633 | Test Acc: 82.50%\n",
      "Epoch: 17 | Epoch Time: 0m 8s\n",
      "ComputationalLinguistics Train Loss: 0.759 | Train Acc: 73.75%\n",
      "ComputationalLinguistics Valid Loss: 0.712 | Valid Acc: 83.21%\n",
      "ComputationalLinguistics Test Loss: 0.664 | Test Acc: 83.13%\n",
      "Epoch: 18 | Epoch Time: 0m 8s\n",
      "ComputationalLinguistics Train Loss: 0.901 | Train Acc: 67.31%\n",
      "ComputationalLinguistics Valid Loss: 1.032 | Valid Acc: 50.53%\n",
      "ComputationalLinguistics Test Loss: 0.971 | Test Acc: 48.05%\n",
      "Epoch: 19 | Epoch Time: 0m 8s\n",
      "ComputationalLinguistics Train Loss: 1.059 | Train Acc: 51.68%\n",
      "ComputationalLinguistics Valid Loss: 1.053 | Valid Acc: 30.80%\n",
      "ComputationalLinguistics Test Loss: 1.038 | Test Acc: 24.52%\n",
      "Epoch: 20 | Epoch Time: 0m 8s\n",
      "ComputationalLinguistics Train Loss: 1.062 | Train Acc: 50.51%\n",
      "ComputationalLinguistics Valid Loss: 1.001 | Valid Acc: 45.78%\n",
      "ComputationalLinguistics Test Loss: 0.958 | Test Acc: 39.87%\n",
      "Epoch: 21 | Epoch Time: 0m 8s\n",
      "ComputationalLinguistics Train Loss: 1.059 | Train Acc: 50.08%\n",
      "ComputationalLinguistics Valid Loss: 0.980 | Valid Acc: 61.52%\n",
      "ComputationalLinguistics Test Loss: 0.918 | Test Acc: 59.99%\n",
      "Epoch: 22 | Epoch Time: 0m 8s\n",
      "ComputationalLinguistics Train Loss: 1.040 | Train Acc: 54.58%\n",
      "ComputationalLinguistics Valid Loss: 1.002 | Valid Acc: 67.65%\n",
      "ComputationalLinguistics Test Loss: 0.921 | Test Acc: 68.27%\n",
      "Early stopping at epoch 22 for ComputationalLinguistics model.\n",
      "Best performing epoch for ComputationalLinguistics model: 16\n",
      "Training model for P2_ComputerVision, using ALL data of title...\n",
      "Epoch: 01 | Epoch Time: 0m 8s\n",
      "ComputerVision Train Loss: 0.666 | Train Acc: 50.05%\n",
      "ComputerVision Valid Loss: 0.662 | Valid Acc: 54.23%\n",
      "ComputerVision Test Loss: 0.681 | Test Acc: 48.66%\n",
      "Epoch: 02 | Epoch Time: 0m 8s\n",
      "ComputerVision Train Loss: 0.666 | Train Acc: 50.09%\n",
      "ComputerVision Valid Loss: 0.656 | Valid Acc: 56.15%\n",
      "ComputerVision Test Loss: 0.679 | Test Acc: 50.56%\n",
      "Epoch: 03 | Epoch Time: 0m 8s\n",
      "ComputerVision Train Loss: 0.666 | Train Acc: 50.25%\n",
      "ComputerVision Valid Loss: 0.651 | Valid Acc: 58.49%\n",
      "ComputerVision Test Loss: 0.676 | Test Acc: 52.06%\n",
      "Epoch: 04 | Epoch Time: 0m 8s\n",
      "ComputerVision Train Loss: 0.665 | Train Acc: 50.24%\n",
      "ComputerVision Valid Loss: 0.647 | Valid Acc: 59.48%\n",
      "ComputerVision Test Loss: 0.672 | Test Acc: 53.94%\n",
      "Epoch: 05 | Epoch Time: 0m 7s\n",
      "ComputerVision Train Loss: 0.665 | Train Acc: 50.18%\n",
      "ComputerVision Valid Loss: 0.643 | Valid Acc: 60.05%\n",
      "ComputerVision Test Loss: 0.671 | Test Acc: 54.06%\n",
      "Epoch: 06 | Epoch Time: 0m 8s\n",
      "ComputerVision Train Loss: 0.665 | Train Acc: 50.41%\n",
      "ComputerVision Valid Loss: 0.640 | Valid Acc: 60.77%\n",
      "ComputerVision Test Loss: 0.670 | Test Acc: 53.75%\n",
      "Epoch: 07 | Epoch Time: 0m 8s\n",
      "ComputerVision Train Loss: 0.664 | Train Acc: 51.14%\n",
      "ComputerVision Valid Loss: 0.633 | Valid Acc: 61.71%\n",
      "ComputerVision Test Loss: 0.665 | Test Acc: 55.36%\n",
      "Epoch: 08 | Epoch Time: 0m 8s\n",
      "ComputerVision Train Loss: 0.616 | Train Acc: 63.06%\n",
      "ComputerVision Valid Loss: 0.584 | Valid Acc: 70.15%\n",
      "ComputerVision Test Loss: 0.604 | Test Acc: 68.38%\n",
      "Epoch: 09 | Epoch Time: 0m 8s\n",
      "ComputerVision Train Loss: 0.558 | Train Acc: 70.94%\n",
      "ComputerVision Valid Loss: 0.532 | Valid Acc: 73.10%\n",
      "ComputerVision Test Loss: 0.556 | Test Acc: 71.59%\n",
      "Epoch: 10 | Epoch Time: 0m 7s\n",
      "ComputerVision Train Loss: 0.512 | Train Acc: 73.82%\n",
      "ComputerVision Valid Loss: 0.508 | Valid Acc: 74.56%\n",
      "ComputerVision Test Loss: 0.545 | Test Acc: 71.94%\n",
      "Epoch: 11 | Epoch Time: 0m 7s\n",
      "ComputerVision Train Loss: 0.455 | Train Acc: 77.79%\n",
      "ComputerVision Valid Loss: 0.460 | Valid Acc: 78.30%\n",
      "ComputerVision Test Loss: 0.488 | Test Acc: 76.49%\n",
      "Epoch: 12 | Epoch Time: 0m 8s\n",
      "ComputerVision Train Loss: 0.377 | Train Acc: 82.44%\n",
      "ComputerVision Valid Loss: 0.388 | Valid Acc: 82.24%\n",
      "ComputerVision Test Loss: 0.404 | Test Acc: 81.57%\n",
      "Epoch: 13 | Epoch Time: 0m 7s\n",
      "ComputerVision Train Loss: 0.321 | Train Acc: 85.99%\n",
      "ComputerVision Valid Loss: 0.405 | Valid Acc: 80.79%\n",
      "ComputerVision Test Loss: 0.489 | Test Acc: 75.89%\n",
      "Epoch: 14 | Epoch Time: 0m 7s\n",
      "ComputerVision Train Loss: 0.293 | Train Acc: 87.50%\n",
      "ComputerVision Valid Loss: 0.343 | Valid Acc: 85.07%\n",
      "ComputerVision Test Loss: 0.382 | Test Acc: 83.29%\n",
      "Epoch: 15 | Epoch Time: 0m 7s\n",
      "ComputerVision Train Loss: 0.264 | Train Acc: 88.94%\n",
      "ComputerVision Valid Loss: 0.331 | Valid Acc: 85.79%\n",
      "ComputerVision Test Loss: 0.332 | Test Acc: 86.27%\n",
      "Epoch: 16 | Epoch Time: 0m 8s\n",
      "ComputerVision Train Loss: 0.250 | Train Acc: 89.54%\n",
      "ComputerVision Valid Loss: 0.312 | Valid Acc: 86.76%\n",
      "ComputerVision Test Loss: 0.326 | Test Acc: 86.07%\n",
      "Epoch: 17 | Epoch Time: 0m 8s\n",
      "ComputerVision Train Loss: 0.237 | Train Acc: 90.13%\n",
      "ComputerVision Valid Loss: 0.304 | Valid Acc: 86.88%\n",
      "ComputerVision Test Loss: 0.340 | Test Acc: 85.19%\n",
      "Epoch: 18 | Epoch Time: 0m 7s\n",
      "ComputerVision Train Loss: 0.227 | Train Acc: 90.56%\n",
      "ComputerVision Valid Loss: 0.295 | Valid Acc: 87.42%\n",
      "ComputerVision Test Loss: 0.324 | Test Acc: 86.02%\n",
      "Epoch: 19 | Epoch Time: 0m 7s\n",
      "ComputerVision Train Loss: 0.217 | Train Acc: 90.83%\n",
      "ComputerVision Valid Loss: 0.287 | Valid Acc: 87.76%\n",
      "ComputerVision Test Loss: 0.299 | Test Acc: 87.60%\n",
      "Epoch: 20 | Epoch Time: 0m 7s\n",
      "ComputerVision Train Loss: 0.212 | Train Acc: 91.36%\n",
      "ComputerVision Valid Loss: 0.291 | Valid Acc: 87.67%\n",
      "ComputerVision Test Loss: 0.324 | Test Acc: 85.83%\n",
      "Epoch: 21 | Epoch Time: 0m 8s\n",
      "ComputerVision Train Loss: 0.205 | Train Acc: 91.60%\n",
      "ComputerVision Valid Loss: 0.292 | Valid Acc: 87.61%\n",
      "ComputerVision Test Loss: 0.339 | Test Acc: 84.82%\n",
      "Epoch: 22 | Epoch Time: 0m 8s\n",
      "ComputerVision Train Loss: 0.198 | Train Acc: 91.94%\n",
      "ComputerVision Valid Loss: 0.288 | Valid Acc: 87.80%\n",
      "ComputerVision Test Loss: 0.324 | Test Acc: 85.90%\n",
      "Epoch: 23 | Epoch Time: 0m 8s\n",
      "ComputerVision Train Loss: 0.192 | Train Acc: 92.07%\n",
      "ComputerVision Valid Loss: 0.282 | Valid Acc: 88.11%\n",
      "ComputerVision Test Loss: 0.318 | Test Acc: 86.08%\n",
      "Epoch: 24 | Epoch Time: 0m 8s\n",
      "ComputerVision Train Loss: 0.186 | Train Acc: 92.44%\n",
      "ComputerVision Valid Loss: 0.273 | Valid Acc: 88.59%\n",
      "ComputerVision Test Loss: 0.285 | Test Acc: 88.07%\n",
      "Epoch: 25 | Epoch Time: 0m 7s\n",
      "ComputerVision Train Loss: 0.183 | Train Acc: 92.45%\n",
      "ComputerVision Valid Loss: 0.269 | Valid Acc: 88.70%\n",
      "ComputerVision Test Loss: 0.287 | Test Acc: 88.04%\n",
      "Epoch: 26 | Epoch Time: 0m 8s\n",
      "ComputerVision Train Loss: 0.177 | Train Acc: 92.74%\n",
      "ComputerVision Valid Loss: 0.281 | Valid Acc: 87.67%\n",
      "ComputerVision Test Loss: 0.331 | Test Acc: 85.24%\n",
      "Epoch: 27 | Epoch Time: 0m 7s\n",
      "ComputerVision Train Loss: 0.172 | Train Acc: 93.04%\n",
      "ComputerVision Valid Loss: 0.268 | Valid Acc: 88.33%\n",
      "ComputerVision Test Loss: 0.288 | Test Acc: 87.80%\n",
      "Epoch: 28 | Epoch Time: 0m 8s\n",
      "ComputerVision Train Loss: 0.169 | Train Acc: 93.16%\n",
      "ComputerVision Valid Loss: 0.265 | Valid Acc: 88.76%\n",
      "ComputerVision Test Loss: 0.287 | Test Acc: 87.63%\n",
      "Epoch: 29 | Epoch Time: 0m 8s\n",
      "ComputerVision Train Loss: 0.166 | Train Acc: 93.32%\n",
      "ComputerVision Valid Loss: 0.269 | Valid Acc: 88.19%\n",
      "ComputerVision Test Loss: 0.263 | Test Acc: 88.92%\n",
      "Epoch: 30 | Epoch Time: 0m 8s\n",
      "ComputerVision Train Loss: 0.161 | Train Acc: 93.49%\n",
      "ComputerVision Valid Loss: 0.265 | Valid Acc: 88.28%\n",
      "ComputerVision Test Loss: 0.270 | Test Acc: 88.51%\n"
     ]
    }
   ],
   "source": [
    "RESULTS_T_P2_ALL, best_model_states = train_loop(models, optimizers, iterators, N_EPOCHS, label_names, target_field, model_file_names, best_valid_losses, \"P2\", \"ALL\", 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "80699bab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "InformationTheory:\n",
      "[[4770 4817]\n",
      " [2235 6244]]\n",
      "Accuracy: 0.6096534927488099\n",
      "Macro Precision: 0.6227240529305369\n",
      "Macro Recall: 0.6169781795932355\n",
      "Macro F1 score: 0.6070375877585626\n",
      "MCC: 0.2396333558093955\n",
      "\n",
      "\n",
      "ComputationalLinguistics:\n",
      "[[12539  2159]\n",
      " [ 1005  2363]]\n",
      "Accuracy: 0.8248643861397099\n",
      "Macro Precision: 0.7241768960203225\n",
      "Macro Recall: 0.7773562959912783\n",
      "Macro F1 score: 0.7434771662515958\n",
      "MCC: 0.4987058192041421\n",
      "\n",
      "\n",
      "ComputerVision:\n",
      "[[10816  1031]\n",
      " [  973  5246]]\n",
      "Accuracy: 0.8890733975423447\n",
      "Macro Precision: 0.8766074978858318\n",
      "Macro Recall: 0.8782588633799385\n",
      "Macro F1 score: 0.8774213806972979\n",
      "MCC: 0.7548645549783282\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model_IT.load_state_dict(best_model_states[0])\n",
    "model_CL.load_state_dict(best_model_states[1])\n",
    "model_CV.load_state_dict(best_model_states[2])\n",
    "\n",
    "evaluate_model(model_IT, test_iterator_IT, \"InformationTheory\", target_field)\n",
    "evaluate_model(model_CL, test_iterator_CL, \"ComputationalLinguistics\", target_field)\n",
    "evaluate_model(model_CV, test_iterator_CV, \"ComputerVision\", target_field)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d9464bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"Abstract\" models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a63207e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# P1\n",
    "target_field = \"abstract\"\n",
    "\n",
    "TEXT = data.Field(sequential=True, tokenize=custom_tokenizer, lower=True)\n",
    "LABEL = data.LabelField(dtype=torch.float, use_vocab = False, preprocessing = int)\n",
    "\n",
    "train_datafield = [(\"title\", None), \n",
    "                   (\"abstract\", TEXT),\n",
    "                   (\"InformationTheory\", LABEL), \n",
    "                   (\"ComputationalLinguistics\", LABEL),\n",
    "                   (\"ComputerVision\", LABEL)\n",
    "                   ]\n",
    "\n",
    "# Dataset - P1\n",
    "train_data_whole, test_data = TabularDataset.splits(\n",
    "    path = \"./\",\n",
    "    train = \"train.csv\", test = \"test.csv\", format = \"csv\",\n",
    "    skip_header = True, fields = train_datafield)\n",
    "\n",
    "train_data, valid_data = train_data_whole.split(split_ratio = 0.9, random_state = random.getstate())\n",
    "train_1000, remaining = train_data_whole.split(split_ratio = 1000 / len(train_data_whole), random_state = random.getstate())\n",
    "train_1000, valid_1000 = train_1000.split(split_ratio = 0.9, random_state = random.getstate())\n",
    "\n",
    "\n",
    "# Building vocab\n",
    "MAX_VOCAB_SIZE = 5000\n",
    "\n",
    "TEXT.build_vocab(train_1000, max_size = MAX_VOCAB_SIZE)\n",
    "\n",
    "# Run generate_label_iterator functions\n",
    "\n",
    "\n",
    "train_iterator_IT, validation_IT, test_iterator_IT = generate_label_iterator(train_1000, \"InformationTheory\", target_field, validation = True)\n",
    "train_iterator_CL, validation_CL, test_iterator_CL = generate_label_iterator(train_1000, \"ComputationalLinguistics\", target_field, validation = True)\n",
    "train_iterator_CV, validation_CV, test_iterator_CV = generate_label_iterator(train_1000, \"ComputerVision\", target_field, validation = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b32604c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "439 461\n",
      "682 218\n",
      "679 221\n"
     ]
    }
   ],
   "source": [
    "# Initialize counts\n",
    "negative_IT_count, positive_IT_count = 0, 0\n",
    "negative_CL_count, positive_CL_count = 0, 0\n",
    "negative_CV_count, positive_CV_count = 0, 0\n",
    "\n",
    "# Iterate through the dataset\n",
    "for example in train_1000.examples:\n",
    "    if getattr(example, \"InformationTheory\") == 0:\n",
    "        negative_IT_count += 1\n",
    "    else:\n",
    "        positive_IT_count += 1\n",
    "\n",
    "    if getattr(example, \"ComputationalLinguistics\") == 0:\n",
    "        negative_CL_count += 1\n",
    "    else:\n",
    "        positive_CL_count += 1\n",
    "\n",
    "    if getattr(example, \"ComputerVision\") == 0:\n",
    "        negative_CV_count += 1\n",
    "    else:\n",
    "        positive_CV_count += 1\n",
    "        \n",
    "print(negative_CV_count, positive_CV_count)\n",
    "print(negative_IT_count, positive_IT_count)\n",
    "print(negative_CL_count, positive_CL_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9d257bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_weight_IT = torch.tensor([negative_IT_count / positive_IT_count])\n",
    "pos_weight_CL = torch.tensor([negative_CL_count / positive_CL_count])\n",
    "pos_weight_CV = torch.tensor([negative_CV_count / positive_CV_count])\n",
    "\n",
    "\n",
    "model_IT, optimizer_IT = generate_model_and_optimizer(pos_weight = pos_weight_IT)\n",
    "model_CL, optimizer_CL = generate_model_and_optimizer(pos_weight = pos_weight_CL)\n",
    "model_CV, optimizer_CV = generate_model_and_optimizer(pos_weight = pos_weight_CV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3bd6fd05",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "N_EPOCHS = 30\n",
    "label_names = [\"InformationTheory\", \"ComputationalLinguistics\", \"ComputerVision\"]\n",
    "models = [model_IT, model_CL, model_CV]\n",
    "optimizers = [optimizer_IT, optimizer_CL, optimizer_CV]\n",
    "iterators = [(train_iterator_IT, validation_IT, test_iterator_IT), (train_iterator_CL, validation_CL, test_iterator_CL), (train_iterator_CV, validation_CV, test_iterator_CV)]\n",
    "model_file_names = [\"RNN_model_IT\", \"RNN_model_CL.pt\", \"RNN_model_CV.pt\"]\n",
    "best_valid_losses = [float(\"inf\"), float(\"inf\"), float(\"inf\")]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "090453ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('\\n', 12511), ('.', 6260), ('-', 4841), (')', 1470), ('(', 1412), ('  ', 900), ('model', 640), ('data', 578), ('based', 544), ('image', 542), ('learning', 492), ('performance', 466), ('proposed', 455), ('method', 436), ('paper', 434), ('$', 432), ('results', 429), ('models', 418), ('network', 418), ('propose', 404), ('images', 393), ('information', 363), ('methods', 341), ('approach', 329), ('state', 324), ('neural', 299), ('dataset', 296), ('new', 294), ('task', 294), ('problem', 289), ('networks', 284), ('training', 274), ('features', 274), ('different', 266), ('art', 265), ('deep', 261), ('work', 255), ('classification', 254), ('\"', 252), ('large', 231), ('time', 224), ('system', 222), ('multi', 220), ('novel', 216), ('framework', 214), ('object', 214), ('use', 207), ('high', 203), ('detection', 201), ('%', 199), ('datasets', 197), ('multiple', 197), ('accuracy', 194), ('channel', 192), ('language', 191), ('tasks', 186), ('recognition', 185), ('segmentation', 184), ('codes', 180), ('present', 179), (':', 179), ('domain', 178), ('algorithm', 177), ('human', 175), ('systems', 174), ('demonstrate', 173), ('analysis', 172), ('knowledge', 168), ('feature', 166), ('experiments', 166), ('visual', 166), ('text', 165), ('existing', 165), ('end', 164), ('trained', 160), ('semantic', 156), ('rate', 156), ('real', 155), ('3d', 154), ('number', 152), ('low', 152), ('input', 144), ('set', 140), ('user', 138), ('approaches', 137), ('convolutional', 136), ('video', 136), ('recent', 134), ('available', 133), ('attention', 132), ('compared', 131), ('level', 131), ('algorithms', 130), ('study', 130), ('applications', 128), ('single', 128), ('given', 124), ('non', 123), ('loss', 121), ('improve', 120), ('quality', 118), ('error', 118), ('research', 118), ('process', 116), ('machine', 115), ('better', 113), ('design', 110), ('code', 110), ('optimal', 108), ('techniques', 107), ('supervised', 106), ('outperforms', 106), ('scale', 105), ('provide', 104), ('cnn', 104), ('achieve', 102), ('representation', 101), ('order', 100), ('objects', 100), ('/', 100), ('experimental', 99), ('context', 99), ('challenging', 99), ('processing', 99), ('class', 98), ('natural', 98), ('local', 98), ('effective', 98), ('small', 97), ('reconstruction', 96), ('scheme', 96), ('field', 96), ('terms', 95), ('region', 95), ('previous', 94), ('introduce', 94), ('evaluate', 94), ('achieves', 94), ('channels', 94), ('problems', 94), ('significant', 93), ('space', 92), ('architecture', 92), ('target', 91), ('linear', 91), ('vision', 90), ('point', 90), ('known', 89), ('address', 88), ('learn', 88), ('random', 87), ('important', 87), ('specific', 86), ('users', 86), ('world', 85), ('simple', 84), ('power', 84), ('estimation', 84), ('generation', 83), ('limited', 83), ('best', 83), ('function', 82), ('noise', 82), ('graph', 81), ('finally', 81), ('source', 81), ('signal', 81), ('word', 81), ('adversarial', 80), ('efficiency', 79), ('shown', 79), ('depth', 79), ('significantly', 79), ('optimization', 79), ('obtained', 78), ('spatial', 78), ('computer', 78), ('benchmark', 78), ('feedback', 78), ('self', 77), ('distribution', 77), ('representations', 76), ('effectiveness', 76), ('generated', 76), ('1', 76), (';', 76), ('recently', 75), ('translation', 75), ('current', 75), ('efficient', 75), ('general', 74), ('parameters', 74), ('layer', 74), ('question', 74), ('prediction', 74), ('pre', 73), ('achieved', 73), ('sequence', 73), ('generate', 73), ('communication', 73)]\n"
     ]
    }
   ],
   "source": [
    "print(TEXT.vocab.freqs.most_common(200))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a97e7131",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for P1_InformationTheory, using 1000 data of abstract...\n",
      "Epoch: 01 | Epoch Time: 0m 3s\n",
      "InformationTheory Train Loss: 1.054 | Train Acc: 39.90%\n",
      "InformationTheory Valid Loss: 1.048 | Valid Acc: 65.81%\n",
      "InformationTheory Test Loss: 1.429 | Test Acc: 52.15%\n",
      "Epoch: 02 | Epoch Time: 0m 3s\n",
      "InformationTheory Train Loss: 1.032 | Train Acc: 51.98%\n",
      "InformationTheory Valid Loss: 1.050 | Valid Acc: 70.74%\n",
      "InformationTheory Test Loss: 1.453 | Test Acc: 52.63%\n",
      "Epoch: 03 | Epoch Time: 0m 3s\n",
      "InformationTheory Train Loss: 1.055 | Train Acc: 52.40%\n",
      "InformationTheory Valid Loss: 1.054 | Valid Acc: 73.15%\n",
      "InformationTheory Test Loss: 1.478 | Test Acc: 52.52%\n",
      "Epoch: 04 | Epoch Time: 0m 3s\n",
      "InformationTheory Train Loss: 1.034 | Train Acc: 65.31%\n",
      "InformationTheory Valid Loss: 1.049 | Valid Acc: 72.80%\n",
      "InformationTheory Test Loss: 1.480 | Test Acc: 53.03%\n",
      "Epoch: 05 | Epoch Time: 0m 3s\n",
      "InformationTheory Train Loss: 1.032 | Train Acc: 59.79%\n",
      "InformationTheory Valid Loss: 1.050 | Valid Acc: 73.22%\n",
      "InformationTheory Test Loss: 1.493 | Test Acc: 53.10%\n",
      "Epoch: 06 | Epoch Time: 0m 4s\n",
      "InformationTheory Train Loss: 1.061 | Train Acc: 57.71%\n",
      "InformationTheory Valid Loss: 1.053 | Valid Acc: 60.36%\n",
      "InformationTheory Test Loss: 1.421 | Test Acc: 51.58%\n",
      "Epoch: 07 | Epoch Time: 0m 4s\n",
      "InformationTheory Train Loss: 1.080 | Train Acc: 51.46%\n",
      "InformationTheory Valid Loss: 1.060 | Valid Acc: 45.32%\n",
      "InformationTheory Test Loss: 1.370 | Test Acc: 48.54%\n",
      "Epoch: 08 | Epoch Time: 0m 3s\n",
      "InformationTheory Train Loss: 1.037 | Train Acc: 63.12%\n",
      "InformationTheory Valid Loss: 1.060 | Valid Acc: 47.37%\n",
      "InformationTheory Test Loss: 1.391 | Test Acc: 48.62%\n",
      "Epoch: 09 | Epoch Time: 0m 4s\n",
      "InformationTheory Train Loss: 1.052 | Train Acc: 56.15%\n",
      "InformationTheory Valid Loss: 1.068 | Valid Acc: 43.61%\n",
      "InformationTheory Test Loss: 1.329 | Test Acc: 48.92%\n",
      "Epoch: 10 | Epoch Time: 0m 3s\n",
      "InformationTheory Train Loss: 1.038 | Train Acc: 57.08%\n",
      "InformationTheory Valid Loss: 1.067 | Valid Acc: 45.64%\n",
      "InformationTheory Test Loss: 1.365 | Test Acc: 48.70%\n",
      "Epoch: 11 | Epoch Time: 0m 3s\n",
      "InformationTheory Train Loss: 1.100 | Train Acc: 45.73%\n",
      "InformationTheory Valid Loss: 1.074 | Valid Acc: 25.21%\n",
      "InformationTheory Test Loss: 1.260 | Test Acc: 47.63%\n",
      "Epoch: 12 | Epoch Time: 0m 3s\n",
      "InformationTheory Train Loss: 1.059 | Train Acc: 41.15%\n",
      "InformationTheory Valid Loss: 1.074 | Valid Acc: 45.70%\n",
      "InformationTheory Test Loss: 1.356 | Test Acc: 48.67%\n",
      "Epoch: 13 | Epoch Time: 0m 3s\n",
      "InformationTheory Train Loss: 1.056 | Train Acc: 47.60%\n",
      "InformationTheory Valid Loss: 1.058 | Valid Acc: 43.85%\n",
      "InformationTheory Test Loss: 1.343 | Test Acc: 48.89%\n",
      "Epoch: 14 | Epoch Time: 0m 3s\n",
      "InformationTheory Train Loss: 1.086 | Train Acc: 40.21%\n",
      "InformationTheory Valid Loss: 1.051 | Valid Acc: 26.12%\n",
      "InformationTheory Test Loss: 1.309 | Test Acc: 47.44%\n",
      "Epoch: 15 | Epoch Time: 0m 3s\n",
      "InformationTheory Train Loss: 1.076 | Train Acc: 47.19%\n",
      "InformationTheory Valid Loss: 1.075 | Valid Acc: 45.66%\n",
      "InformationTheory Test Loss: 1.343 | Test Acc: 48.79%\n",
      "Epoch: 16 | Epoch Time: 0m 3s\n",
      "InformationTheory Train Loss: 1.044 | Train Acc: 61.15%\n",
      "InformationTheory Valid Loss: 1.085 | Valid Acc: 43.74%\n",
      "InformationTheory Test Loss: 1.303 | Test Acc: 48.94%\n",
      "Epoch: 17 | Epoch Time: 0m 3s\n",
      "InformationTheory Train Loss: 1.037 | Train Acc: 46.88%\n",
      "InformationTheory Valid Loss: 1.079 | Valid Acc: 45.41%\n",
      "InformationTheory Test Loss: 1.328 | Test Acc: 48.70%\n",
      "Early stopping at epoch 17 for InformationTheory model.\n",
      "Best performing epoch for InformationTheory model: 11\n",
      "Training model for P1_ComputationalLinguistics, using 1000 data of abstract...\n",
      "Epoch: 01 | Epoch Time: 0m 3s\n",
      "ComputationalLinguistics Train Loss: 1.031 | Train Acc: 63.12%\n",
      "ComputationalLinguistics Valid Loss: 1.041 | Valid Acc: 67.96%\n",
      "ComputationalLinguistics Test Loss: 0.956 | Test Acc: 70.17%\n",
      "Epoch: 02 | Epoch Time: 0m 3s\n",
      "ComputationalLinguistics Train Loss: 1.048 | Train Acc: 55.31%\n",
      "ComputationalLinguistics Valid Loss: 1.044 | Valid Acc: 64.52%\n",
      "ComputationalLinguistics Test Loss: 0.954 | Test Acc: 71.27%\n",
      "Epoch: 03 | Epoch Time: 0m 3s\n",
      "ComputationalLinguistics Train Loss: 1.074 | Train Acc: 39.90%\n",
      "ComputationalLinguistics Valid Loss: 1.041 | Valid Acc: 44.00%\n",
      "ComputationalLinguistics Test Loss: 0.969 | Test Acc: 42.18%\n",
      "Epoch: 04 | Epoch Time: 0m 3s\n",
      "ComputationalLinguistics Train Loss: 1.028 | Train Acc: 48.33%\n",
      "ComputationalLinguistics Valid Loss: 1.040 | Valid Acc: 65.82%\n",
      "ComputationalLinguistics Test Loss: 0.956 | Test Acc: 66.84%\n",
      "Epoch: 05 | Epoch Time: 0m 3s\n",
      "ComputationalLinguistics Train Loss: 1.117 | Train Acc: 35.42%\n",
      "ComputationalLinguistics Valid Loss: 1.043 | Valid Acc: 63.11%\n",
      "ComputationalLinguistics Test Loss: 0.955 | Test Acc: 69.83%\n",
      "Epoch: 06 | Epoch Time: 0m 3s\n",
      "ComputationalLinguistics Train Loss: 1.051 | Train Acc: 45.73%\n",
      "ComputationalLinguistics Valid Loss: 1.047 | Valid Acc: 57.79%\n",
      "ComputationalLinguistics Test Loss: 0.955 | Test Acc: 64.90%\n",
      "Epoch: 07 | Epoch Time: 0m 3s\n",
      "ComputationalLinguistics Train Loss: 1.029 | Train Acc: 43.02%\n",
      "ComputationalLinguistics Valid Loss: 1.050 | Valid Acc: 75.04%\n",
      "ComputationalLinguistics Test Loss: 0.946 | Test Acc: 79.45%\n",
      "Epoch: 08 | Epoch Time: 0m 3s\n",
      "ComputationalLinguistics Train Loss: 1.049 | Train Acc: 58.44%\n",
      "ComputationalLinguistics Valid Loss: 1.055 | Valid Acc: 54.91%\n",
      "ComputationalLinguistics Test Loss: 0.953 | Test Acc: 62.26%\n",
      "Epoch: 09 | Epoch Time: 0m 3s\n",
      "ComputationalLinguistics Train Loss: 1.045 | Train Acc: 32.29%\n",
      "ComputationalLinguistics Valid Loss: 1.057 | Valid Acc: 74.92%\n",
      "ComputationalLinguistics Test Loss: 0.947 | Test Acc: 79.48%\n",
      "Epoch: 10 | Epoch Time: 0m 3s\n",
      "ComputationalLinguistics Train Loss: 1.113 | Train Acc: 50.42%\n",
      "ComputationalLinguistics Valid Loss: 1.048 | Valid Acc: 48.49%\n",
      "ComputationalLinguistics Test Loss: 0.961 | Test Acc: 55.42%\n",
      "Epoch: 11 | Epoch Time: 0m 3s\n",
      "ComputationalLinguistics Train Loss: 1.029 | Train Acc: 34.27%\n",
      "ComputationalLinguistics Valid Loss: 1.046 | Valid Acc: 74.73%\n",
      "ComputationalLinguistics Test Loss: 0.948 | Test Acc: 79.13%\n",
      "Epoch: 12 | Epoch Time: 0m 3s\n",
      "ComputationalLinguistics Train Loss: 1.048 | Train Acc: 56.46%\n",
      "ComputationalLinguistics Valid Loss: 1.049 | Valid Acc: 65.91%\n",
      "ComputationalLinguistics Test Loss: 0.950 | Test Acc: 73.34%\n",
      "Epoch: 13 | Epoch Time: 0m 3s\n",
      "ComputationalLinguistics Train Loss: 1.111 | Train Acc: 37.92%\n",
      "ComputationalLinguistics Valid Loss: 1.042 | Valid Acc: 41.54%\n",
      "ComputationalLinguistics Test Loss: 0.965 | Test Acc: 44.56%\n",
      "Early stopping at epoch 13 for ComputationalLinguistics model.\n",
      "Best performing epoch for ComputationalLinguistics model: 7\n",
      "Training model for P1_ComputerVision, using 1000 data of abstract...\n",
      "Epoch: 01 | Epoch Time: 0m 3s\n",
      "ComputerVision Train Loss: 0.678 | Train Acc: 50.10%\n",
      "ComputerVision Valid Loss: 0.677 | Valid Acc: 50.16%\n",
      "ComputerVision Test Loss: 0.692 | Test Acc: 42.30%\n",
      "Epoch: 02 | Epoch Time: 0m 3s\n",
      "ComputerVision Train Loss: 0.675 | Train Acc: 51.67%\n",
      "ComputerVision Valid Loss: 0.677 | Valid Acc: 50.93%\n",
      "ComputerVision Test Loss: 0.698 | Test Acc: 38.77%\n",
      "Epoch: 03 | Epoch Time: 0m 3s\n",
      "ComputerVision Train Loss: 0.678 | Train Acc: 47.08%\n",
      "ComputerVision Valid Loss: 0.678 | Valid Acc: 50.21%\n",
      "ComputerVision Test Loss: 0.690 | Test Acc: 43.75%\n",
      "Epoch: 04 | Epoch Time: 0m 3s\n",
      "ComputerVision Train Loss: 0.678 | Train Acc: 48.96%\n",
      "ComputerVision Valid Loss: 0.679 | Valid Acc: 50.91%\n",
      "ComputerVision Test Loss: 0.704 | Test Acc: 38.19%\n",
      "Epoch: 05 | Epoch Time: 0m 3s\n",
      "ComputerVision Train Loss: 0.678 | Train Acc: 48.54%\n",
      "ComputerVision Valid Loss: 0.677 | Valid Acc: 51.73%\n",
      "ComputerVision Test Loss: 0.704 | Test Acc: 37.64%\n",
      "Epoch: 06 | Epoch Time: 0m 3s\n",
      "ComputerVision Train Loss: 0.679 | Train Acc: 48.44%\n",
      "ComputerVision Valid Loss: 0.677 | Valid Acc: 51.41%\n",
      "ComputerVision Test Loss: 0.695 | Test Acc: 40.96%\n",
      "Epoch: 07 | Epoch Time: 0m 3s\n",
      "ComputerVision Train Loss: 0.680 | Train Acc: 47.60%\n",
      "ComputerVision Valid Loss: 0.679 | Valid Acc: 50.12%\n",
      "ComputerVision Test Loss: 0.694 | Test Acc: 43.71%\n",
      "Epoch: 08 | Epoch Time: 0m 3s\n",
      "ComputerVision Train Loss: 0.677 | Train Acc: 52.71%\n",
      "ComputerVision Valid Loss: 0.677 | Valid Acc: 50.74%\n",
      "ComputerVision Test Loss: 0.694 | Test Acc: 40.78%\n",
      "Epoch: 09 | Epoch Time: 0m 3s\n",
      "ComputerVision Train Loss: 0.675 | Train Acc: 49.69%\n",
      "ComputerVision Valid Loss: 0.678 | Valid Acc: 50.16%\n",
      "ComputerVision Test Loss: 0.690 | Test Acc: 45.12%\n",
      "Epoch: 10 | Epoch Time: 0m 3s\n",
      "ComputerVision Train Loss: 0.675 | Train Acc: 52.29%\n",
      "ComputerVision Valid Loss: 0.678 | Valid Acc: 49.95%\n",
      "ComputerVision Test Loss: 0.679 | Test Acc: 51.32%\n",
      "Epoch: 11 | Epoch Time: 0m 3s\n",
      "ComputerVision Train Loss: 0.677 | Train Acc: 50.62%\n",
      "ComputerVision Valid Loss: 0.679 | Valid Acc: 49.07%\n",
      "ComputerVision Test Loss: 0.674 | Test Acc: 54.37%\n",
      "Epoch: 12 | Epoch Time: 0m 3s\n",
      "ComputerVision Train Loss: 0.681 | Train Acc: 48.12%\n",
      "ComputerVision Valid Loss: 0.678 | Valid Acc: 50.23%\n",
      "ComputerVision Test Loss: 0.686 | Test Acc: 47.32%\n",
      "Epoch: 13 | Epoch Time: 0m 3s\n",
      "ComputerVision Train Loss: 0.680 | Train Acc: 51.46%\n",
      "ComputerVision Valid Loss: 0.678 | Valid Acc: 49.14%\n",
      "ComputerVision Test Loss: 0.674 | Test Acc: 55.03%\n",
      "Epoch: 14 | Epoch Time: 0m 3s\n",
      "ComputerVision Train Loss: 0.678 | Train Acc: 46.88%\n",
      "ComputerVision Valid Loss: 0.680 | Valid Acc: 49.30%\n",
      "ComputerVision Test Loss: 0.671 | Test Acc: 55.63%\n",
      "Epoch: 15 | Epoch Time: 0m 3s\n",
      "ComputerVision Train Loss: 0.677 | Train Acc: 49.38%\n",
      "ComputerVision Valid Loss: 0.683 | Valid Acc: 49.30%\n",
      "ComputerVision Test Loss: 0.670 | Test Acc: 54.54%\n",
      "Epoch: 16 | Epoch Time: 0m 3s\n",
      "ComputerVision Train Loss: 0.676 | Train Acc: 49.17%\n",
      "ComputerVision Valid Loss: 0.684 | Valid Acc: 49.21%\n",
      "ComputerVision Test Loss: 0.667 | Test Acc: 54.85%\n",
      "Epoch: 17 | Epoch Time: 0m 3s\n",
      "ComputerVision Train Loss: 0.679 | Train Acc: 51.77%\n",
      "ComputerVision Valid Loss: 0.682 | Valid Acc: 48.91%\n",
      "ComputerVision Test Loss: 0.674 | Test Acc: 53.54%\n",
      "Epoch: 18 | Epoch Time: 0m 3s\n",
      "ComputerVision Train Loss: 0.678 | Train Acc: 49.17%\n",
      "ComputerVision Valid Loss: 0.679 | Valid Acc: 49.41%\n",
      "ComputerVision Test Loss: 0.677 | Test Acc: 53.34%\n",
      "Epoch: 19 | Epoch Time: 0m 3s\n",
      "ComputerVision Train Loss: 0.678 | Train Acc: 49.69%\n",
      "ComputerVision Valid Loss: 0.678 | Valid Acc: 50.22%\n",
      "ComputerVision Test Loss: 0.686 | Test Acc: 47.77%\n",
      "Epoch: 20 | Epoch Time: 0m 3s\n",
      "ComputerVision Train Loss: 0.678 | Train Acc: 48.33%\n",
      "ComputerVision Valid Loss: 0.677 | Valid Acc: 51.07%\n",
      "ComputerVision Test Loss: 0.692 | Test Acc: 42.69%\n",
      "Epoch: 21 | Epoch Time: 0m 3s\n",
      "ComputerVision Train Loss: 0.679 | Train Acc: 48.23%\n",
      "ComputerVision Valid Loss: 0.678 | Valid Acc: 50.76%\n",
      "ComputerVision Test Loss: 0.684 | Test Acc: 48.54%\n",
      "Epoch: 22 | Epoch Time: 0m 3s\n",
      "ComputerVision Train Loss: 0.675 | Train Acc: 50.31%\n",
      "ComputerVision Valid Loss: 0.678 | Valid Acc: 50.83%\n",
      "ComputerVision Test Loss: 0.698 | Test Acc: 40.82%\n",
      "Early stopping at epoch 22 for ComputerVision model.\n",
      "Best performing epoch for ComputerVision model: 16\n"
     ]
    }
   ],
   "source": [
    "RESULTS_A_P1_1000, best_model_states = train_loop(models, optimizers, iterators, N_EPOCHS, label_names, target_field, model_file_names, best_valid_losses, \"P1\", \"1000\", 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "dc61f1fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "InformationTheory:\n",
      "[[ 250 9337]\n",
      " [ 130 8349]]\n",
      "Accuracy: 0.47597697332004874\n",
      "Macro Precision: 0.5649815197271705\n",
      "Macro Recall: 0.5053724912725004\n",
      "Macro F1 score: 0.34417316107419726\n",
      "MCC: 0.03736911278625885\n",
      "\n",
      "\n",
      "ComputationalLinguistics:\n",
      "[[14290   408]\n",
      " [ 3309    59]]\n",
      "Accuracy: 0.794254400531385\n",
      "Macro Precision: 0.46915814152862734\n",
      "Macro Recall: 0.494879467983913\n",
      "Macro F1 score: 0.4578405710461319\n",
      "MCC: -0.0251337799575223\n",
      "\n",
      "\n",
      "ComputerVision:\n",
      "[[8050 3797]\n",
      " [4367 1852]]\n",
      "Accuracy: 0.5481014059559394\n",
      "Macro Precision: 0.4880751899463206\n",
      "Macro Recall: 0.4886469962678598\n",
      "Macro F1 score: 0.48781710920354693\n",
      "MCC: -0.02327078967671577\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_IT.load_state_dict(best_model_states[0])\n",
    "model_CL.load_state_dict(best_model_states[1])\n",
    "model_CV.load_state_dict(best_model_states[2])\n",
    "\n",
    "# Evaluate models\n",
    "evaluate_model(model_IT, test_iterator_IT, \"InformationTheory\", target_field)\n",
    "evaluate_model(model_CL, test_iterator_CL, \"ComputationalLinguistics\", target_field)\n",
    "evaluate_model(model_CV, test_iterator_CV, \"ComputerVision\", target_field)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "0f11721c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#P2\n",
    "\n",
    "target_field = \"abstract\"\n",
    "\n",
    "TEXT = data.Field(sequential=True, tokenize=custom_tokenizer_P2, lower=False)\n",
    "LABEL = data.LabelField(dtype=torch.float, use_vocab = False, preprocessing = int)\n",
    "\n",
    "train_datafield = [(\"title\", None), \n",
    "                   (\"abstract\", TEXT),\n",
    "                   (\"InformationTheory\", LABEL), \n",
    "                   (\"ComputationalLinguistics\", LABEL),\n",
    "                   (\"ComputerVision\", LABEL)\n",
    "                   ]\n",
    "\n",
    "# Dataset\n",
    "train_data_whole, test_data = TabularDataset.splits(\n",
    "    path = \"./\",\n",
    "    train = \"train.csv\", test = \"test.csv\", format = \"csv\",\n",
    "    skip_header = True, fields = train_datafield)\n",
    "\n",
    "train_data, valid_data = train_data_whole.split(split_ratio = 0.9, random_state = random.getstate())\n",
    "train_1000, remaining = train_data_whole.split(split_ratio = 1000 / len(train_data_whole), random_state = random.getstate())\n",
    "train_1000, valid_1000 = train_1000.split(split_ratio = 0.9, random_state = random.getstate())\n",
    "# Building vocab\n",
    "MAX_VOCAB_SIZE = 5000\n",
    "\n",
    "TEXT.build_vocab(train_1000, max_size = MAX_VOCAB_SIZE)\n",
    "\n",
    "# Run generate_label_iterator functions\n",
    "train_iterator_IT, validation_IT, test_iterator_IT = generate_label_iterator(train_1000, \"InformationTheory\", target_field, validation = True)\n",
    "train_iterator_CL, validation_CL, test_iterator_CL = generate_label_iterator(train_1000, \"ComputationalLinguistics\", target_field, validation = True)\n",
    "train_iterator_CV, validation_CV, test_iterator_CV = generate_label_iterator(train_1000, \"ComputerVision\", target_field, validation = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "1ad21b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model_IT, optimizer_IT = generate_model_and_optimizer(pos_weight = pos_weight_IT)\n",
    "model_CL, optimizer_CL = generate_model_and_optimizer(pos_weight = pos_weight_CL)\n",
    "model_CV, optimizer_CV = generate_model_and_optimizer(pos_weight = pos_weight_CV)\n",
    "\n",
    "N_EPOCHS = 30\n",
    "label_names = [\"InformationTheory\", \"ComputationalLinguistics\", \"ComputerVision\"]\n",
    "models = [model_IT, model_CL, model_CV]\n",
    "optimizers = [optimizer_IT, optimizer_CL, optimizer_CV]\n",
    "iterators = [(train_iterator_IT, validation_IT, test_iterator_IT), (train_iterator_CL, validation_CL, test_iterator_CL), (train_iterator_CV, validation_CV, test_iterator_CV)]\n",
    "model_file_names = [\"RNN_model_IT\", \"RNN_model_CL.pt\", \"RNN_model_CV.pt\"]\n",
    "best_valid_losses = [float(\"inf\"), float(\"inf\"), float(\"inf\")]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "2a319cdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for P2_InformationTheory, using 1000 data of abstract...\n",
      "Epoch: 01 | Epoch Time: 0m 5s\n",
      "InformationTheory Train Loss: 1.056 | Train Acc: 52.50%\n",
      "InformationTheory Valid Loss: 1.053 | Valid Acc: 68.65%\n",
      "InformationTheory Test Loss: 1.458 | Test Acc: 53.02%\n",
      "Epoch: 02 | Epoch Time: 0m 5s\n",
      "InformationTheory Train Loss: 1.031 | Train Acc: 53.75%\n",
      "InformationTheory Valid Loss: 1.053 | Valid Acc: 72.33%\n",
      "InformationTheory Test Loss: 1.473 | Test Acc: 52.45%\n",
      "Epoch: 03 | Epoch Time: 0m 5s\n",
      "InformationTheory Train Loss: 1.056 | Train Acc: 47.08%\n",
      "InformationTheory Valid Loss: 1.060 | Valid Acc: 73.42%\n",
      "InformationTheory Test Loss: 1.501 | Test Acc: 52.27%\n",
      "Epoch: 04 | Epoch Time: 0m 5s\n",
      "InformationTheory Train Loss: 1.034 | Train Acc: 65.21%\n",
      "InformationTheory Valid Loss: 1.053 | Valid Acc: 72.90%\n",
      "InformationTheory Test Loss: 1.477 | Test Acc: 52.35%\n",
      "Epoch: 05 | Epoch Time: 0m 5s\n",
      "InformationTheory Train Loss: 1.034 | Train Acc: 68.23%\n",
      "InformationTheory Valid Loss: 1.052 | Valid Acc: 72.93%\n",
      "InformationTheory Test Loss: 1.476 | Test Acc: 52.84%\n",
      "Epoch: 06 | Epoch Time: 0m 5s\n",
      "InformationTheory Train Loss: 1.060 | Train Acc: 57.81%\n",
      "InformationTheory Valid Loss: 1.063 | Valid Acc: 51.37%\n",
      "InformationTheory Test Loss: 1.400 | Test Acc: 48.43%\n",
      "Epoch: 07 | Epoch Time: 0m 5s\n",
      "InformationTheory Train Loss: 1.076 | Train Acc: 53.02%\n",
      "InformationTheory Valid Loss: 1.080 | Valid Acc: 50.50%\n",
      "InformationTheory Test Loss: 1.355 | Test Acc: 48.64%\n",
      "Epoch: 08 | Epoch Time: 0m 5s\n",
      "InformationTheory Train Loss: 1.041 | Train Acc: 63.02%\n",
      "InformationTheory Valid Loss: 1.073 | Valid Acc: 51.11%\n",
      "InformationTheory Test Loss: 1.377 | Test Acc: 48.52%\n",
      "Epoch: 09 | Epoch Time: 0m 5s\n",
      "InformationTheory Train Loss: 1.036 | Train Acc: 61.67%\n",
      "InformationTheory Valid Loss: 1.092 | Valid Acc: 49.84%\n",
      "InformationTheory Test Loss: 1.325 | Test Acc: 49.26%\n",
      "Epoch: 10 | Epoch Time: 0m 5s\n",
      "InformationTheory Train Loss: 1.038 | Train Acc: 61.35%\n",
      "InformationTheory Valid Loss: 1.087 | Valid Acc: 51.13%\n",
      "InformationTheory Test Loss: 1.360 | Test Acc: 48.53%\n",
      "Epoch: 11 | Epoch Time: 0m 5s\n",
      "InformationTheory Train Loss: 1.094 | Train Acc: 45.94%\n",
      "InformationTheory Valid Loss: 1.099 | Valid Acc: 25.67%\n",
      "InformationTheory Test Loss: 1.253 | Test Acc: 47.39%\n",
      "Epoch: 12 | Epoch Time: 0m 5s\n",
      "InformationTheory Train Loss: 1.062 | Train Acc: 41.15%\n",
      "InformationTheory Valid Loss: 1.092 | Valid Acc: 51.13%\n",
      "InformationTheory Test Loss: 1.358 | Test Acc: 48.51%\n",
      "Epoch: 13 | Epoch Time: 0m 5s\n",
      "InformationTheory Train Loss: 1.060 | Train Acc: 52.08%\n",
      "InformationTheory Valid Loss: 1.071 | Valid Acc: 48.08%\n",
      "InformationTheory Test Loss: 1.330 | Test Acc: 49.19%\n",
      "Epoch: 14 | Epoch Time: 0m 5s\n",
      "InformationTheory Train Loss: 1.084 | Train Acc: 38.96%\n",
      "InformationTheory Valid Loss: 1.059 | Valid Acc: 24.40%\n",
      "InformationTheory Test Loss: 1.284 | Test Acc: 47.05%\n",
      "Epoch: 15 | Epoch Time: 0m 5s\n",
      "InformationTheory Train Loss: 1.065 | Train Acc: 47.50%\n",
      "InformationTheory Valid Loss: 1.094 | Valid Acc: 51.13%\n",
      "InformationTheory Test Loss: 1.347 | Test Acc: 48.52%\n",
      "Epoch: 16 | Epoch Time: 0m 5s\n",
      "InformationTheory Train Loss: 1.045 | Train Acc: 61.35%\n",
      "InformationTheory Valid Loss: 1.113 | Valid Acc: 50.36%\n",
      "InformationTheory Test Loss: 1.314 | Test Acc: 49.16%\n",
      "Epoch: 17 | Epoch Time: 0m 5s\n",
      "InformationTheory Train Loss: 1.036 | Train Acc: 50.10%\n",
      "InformationTheory Valid Loss: 1.105 | Valid Acc: 51.13%\n",
      "InformationTheory Test Loss: 1.331 | Test Acc: 48.52%\n",
      "Early stopping at epoch 17 for InformationTheory model.\n",
      "Best performing epoch for InformationTheory model: 11\n",
      "Training model for P2_ComputationalLinguistics, using 1000 data of abstract...\n",
      "Epoch: 01 | Epoch Time: 0m 5s\n",
      "ComputationalLinguistics Train Loss: 1.034 | Train Acc: 48.65%\n",
      "ComputationalLinguistics Valid Loss: 1.038 | Valid Acc: 44.50%\n",
      "ComputationalLinguistics Test Loss: 0.979 | Test Acc: 37.39%\n",
      "Epoch: 02 | Epoch Time: 0m 5s\n",
      "ComputationalLinguistics Train Loss: 1.050 | Train Acc: 49.27%\n",
      "ComputationalLinguistics Valid Loss: 1.038 | Valid Acc: 32.60%\n",
      "ComputationalLinguistics Test Loss: 0.975 | Test Acc: 27.17%\n",
      "Epoch: 03 | Epoch Time: 0m 5s\n",
      "ComputationalLinguistics Train Loss: 1.069 | Train Acc: 45.21%\n",
      "ComputationalLinguistics Valid Loss: 1.046 | Valid Acc: 26.35%\n",
      "ComputationalLinguistics Test Loss: 0.997 | Test Acc: 20.70%\n",
      "Epoch: 04 | Epoch Time: 0m 5s\n",
      "ComputationalLinguistics Train Loss: 1.030 | Train Acc: 48.12%\n",
      "ComputationalLinguistics Valid Loss: 1.037 | Valid Acc: 50.10%\n",
      "ComputationalLinguistics Test Loss: 0.976 | Test Acc: 43.66%\n",
      "Epoch: 05 | Epoch Time: 0m 5s\n",
      "ComputationalLinguistics Train Loss: 1.103 | Train Acc: 36.56%\n",
      "ComputationalLinguistics Valid Loss: 1.047 | Valid Acc: 32.50%\n",
      "ComputationalLinguistics Test Loss: 1.002 | Test Acc: 25.38%\n",
      "Epoch: 06 | Epoch Time: 0m 5s\n",
      "ComputationalLinguistics Train Loss: 1.058 | Train Acc: 45.83%\n",
      "ComputationalLinguistics Valid Loss: 1.045 | Valid Acc: 24.63%\n",
      "ComputationalLinguistics Test Loss: 0.994 | Test Acc: 19.66%\n",
      "Epoch: 07 | Epoch Time: 0m 5s\n",
      "ComputationalLinguistics Train Loss: 1.033 | Train Acc: 40.42%\n",
      "ComputationalLinguistics Valid Loss: 1.037 | Valid Acc: 55.12%\n",
      "ComputationalLinguistics Test Loss: 0.970 | Test Acc: 48.98%\n",
      "Epoch: 08 | Epoch Time: 0m 5s\n",
      "ComputationalLinguistics Train Loss: 1.053 | Train Acc: 55.83%\n",
      "ComputationalLinguistics Valid Loss: 1.041 | Valid Acc: 28.04%\n",
      "ComputationalLinguistics Test Loss: 0.978 | Test Acc: 24.63%\n",
      "Epoch: 09 | Epoch Time: 0m 5s\n",
      "ComputationalLinguistics Train Loss: 1.048 | Train Acc: 34.58%\n",
      "ComputationalLinguistics Valid Loss: 1.035 | Valid Acc: 63.47%\n",
      "ComputationalLinguistics Test Loss: 0.959 | Test Acc: 62.64%\n",
      "Epoch: 10 | Epoch Time: 0m 5s\n",
      "ComputationalLinguistics Train Loss: 1.104 | Train Acc: 46.04%\n",
      "ComputationalLinguistics Valid Loss: 1.045 | Valid Acc: 25.08%\n",
      "ComputationalLinguistics Test Loss: 0.988 | Test Acc: 20.35%\n",
      "Epoch: 11 | Epoch Time: 0m 5s\n",
      "ComputationalLinguistics Train Loss: 1.034 | Train Acc: 31.46%\n",
      "ComputationalLinguistics Valid Loss: 1.036 | Valid Acc: 60.26%\n",
      "ComputationalLinguistics Test Loss: 0.962 | Test Acc: 56.89%\n",
      "Epoch: 12 | Epoch Time: 0m 5s\n",
      "ComputationalLinguistics Train Loss: 1.051 | Train Acc: 51.15%\n",
      "ComputationalLinguistics Valid Loss: 1.037 | Valid Acc: 45.14%\n",
      "ComputationalLinguistics Test Loss: 0.963 | Test Acc: 44.75%\n",
      "Epoch: 13 | Epoch Time: 0m 5s\n",
      "ComputationalLinguistics Train Loss: 1.102 | Train Acc: 36.56%\n",
      "ComputationalLinguistics Valid Loss: 1.041 | Valid Acc: 26.69%\n",
      "ComputationalLinguistics Test Loss: 0.983 | Test Acc: 21.53%\n",
      "Epoch: 14 | Epoch Time: 0m 5s\n",
      "ComputationalLinguistics Train Loss: 1.046 | Train Acc: 38.85%\n",
      "ComputationalLinguistics Valid Loss: 1.042 | Valid Acc: 53.52%\n",
      "ComputationalLinguistics Test Loss: 0.987 | Test Acc: 46.93%\n",
      "Epoch: 15 | Epoch Time: 0m 5s\n",
      "ComputationalLinguistics Train Loss: 1.054 | Train Acc: 49.79%\n",
      "ComputationalLinguistics Valid Loss: 1.042 | Valid Acc: 25.70%\n",
      "ComputationalLinguistics Test Loss: 0.986 | Test Acc: 20.78%\n",
      "Early stopping at epoch 15 for ComputationalLinguistics model.\n",
      "Best performing epoch for ComputationalLinguistics model: 9\n",
      "Training model for P2_ComputerVision, using 1000 data of abstract...\n",
      "Epoch: 01 | Epoch Time: 0m 5s\n",
      "ComputerVision Train Loss: 0.675 | Train Acc: 51.56%\n",
      "ComputerVision Valid Loss: 0.679 | Valid Acc: 49.82%\n",
      "ComputerVision Test Loss: 0.693 | Test Acc: 48.81%\n",
      "Epoch: 02 | Epoch Time: 0m 5s\n",
      "ComputerVision Train Loss: 0.675 | Train Acc: 52.19%\n",
      "ComputerVision Valid Loss: 0.680 | Valid Acc: 49.85%\n",
      "ComputerVision Test Loss: 0.694 | Test Acc: 49.30%\n",
      "Epoch: 03 | Epoch Time: 0m 5s\n",
      "ComputerVision Train Loss: 0.680 | Train Acc: 45.94%\n",
      "ComputerVision Valid Loss: 0.679 | Valid Acc: 48.68%\n",
      "ComputerVision Test Loss: 0.686 | Test Acc: 49.95%\n",
      "Epoch: 04 | Epoch Time: 0m 5s\n",
      "ComputerVision Train Loss: 0.676 | Train Acc: 49.27%\n",
      "ComputerVision Valid Loss: 0.679 | Valid Acc: 50.12%\n",
      "ComputerVision Test Loss: 0.697 | Test Acc: 44.60%\n",
      "Epoch: 05 | Epoch Time: 0m 5s\n",
      "ComputerVision Train Loss: 0.680 | Train Acc: 46.77%\n",
      "ComputerVision Valid Loss: 0.679 | Valid Acc: 48.39%\n",
      "ComputerVision Test Loss: 0.681 | Test Acc: 52.88%\n",
      "Epoch: 06 | Epoch Time: 0m 5s\n",
      "ComputerVision Train Loss: 0.678 | Train Acc: 48.65%\n",
      "ComputerVision Valid Loss: 0.679 | Valid Acc: 47.90%\n",
      "ComputerVision Test Loss: 0.675 | Test Acc: 57.15%\n",
      "Epoch: 07 | Epoch Time: 0m 5s\n",
      "ComputerVision Train Loss: 0.680 | Train Acc: 47.29%\n",
      "ComputerVision Valid Loss: 0.680 | Valid Acc: 47.13%\n",
      "ComputerVision Test Loss: 0.679 | Test Acc: 53.74%\n",
      "Epoch: 08 | Epoch Time: 0m 5s\n",
      "ComputerVision Train Loss: 0.676 | Train Acc: 53.02%\n",
      "ComputerVision Valid Loss: 0.679 | Valid Acc: 47.83%\n",
      "ComputerVision Test Loss: 0.675 | Test Acc: 57.35%\n",
      "Epoch: 09 | Epoch Time: 0m 5s\n",
      "ComputerVision Train Loss: 0.676 | Train Acc: 50.62%\n",
      "ComputerVision Valid Loss: 0.680 | Valid Acc: 47.45%\n",
      "ComputerVision Test Loss: 0.673 | Test Acc: 58.71%\n",
      "Epoch: 10 | Epoch Time: 0m 5s\n",
      "ComputerVision Train Loss: 0.676 | Train Acc: 52.40%\n",
      "ComputerVision Valid Loss: 0.682 | Valid Acc: 48.07%\n",
      "ComputerVision Test Loss: 0.663 | Test Acc: 64.32%\n",
      "Epoch: 11 | Epoch Time: 0m 5s\n",
      "ComputerVision Train Loss: 0.676 | Train Acc: 49.69%\n",
      "ComputerVision Valid Loss: 0.684 | Valid Acc: 48.12%\n",
      "ComputerVision Test Loss: 0.659 | Test Acc: 64.93%\n",
      "Epoch: 12 | Epoch Time: 0m 5s\n",
      "ComputerVision Train Loss: 0.679 | Train Acc: 47.08%\n",
      "ComputerVision Valid Loss: 0.681 | Valid Acc: 47.23%\n",
      "ComputerVision Test Loss: 0.669 | Test Acc: 61.27%\n",
      "Epoch: 13 | Epoch Time: 0m 5s\n",
      "ComputerVision Train Loss: 0.679 | Train Acc: 53.44%\n",
      "ComputerVision Valid Loss: 0.684 | Valid Acc: 48.14%\n",
      "ComputerVision Test Loss: 0.658 | Test Acc: 64.91%\n",
      "Epoch: 14 | Epoch Time: 0m 5s\n",
      "ComputerVision Train Loss: 0.679 | Train Acc: 46.04%\n",
      "ComputerVision Valid Loss: 0.685 | Valid Acc: 48.06%\n",
      "ComputerVision Test Loss: 0.657 | Test Acc: 65.36%\n",
      "Epoch: 15 | Epoch Time: 0m 5s\n",
      "ComputerVision Train Loss: 0.676 | Train Acc: 49.69%\n",
      "ComputerVision Valid Loss: 0.686 | Valid Acc: 47.77%\n",
      "ComputerVision Test Loss: 0.659 | Test Acc: 64.78%\n",
      "Epoch: 16 | Epoch Time: 0m 5s\n",
      "ComputerVision Train Loss: 0.675 | Train Acc: 49.38%\n",
      "ComputerVision Valid Loss: 0.688 | Valid Acc: 48.07%\n",
      "ComputerVision Test Loss: 0.657 | Test Acc: 65.14%\n",
      "Epoch: 17 | Epoch Time: 0m 5s\n",
      "ComputerVision Train Loss: 0.679 | Train Acc: 51.98%\n",
      "ComputerVision Valid Loss: 0.685 | Valid Acc: 47.14%\n",
      "ComputerVision Test Loss: 0.662 | Test Acc: 62.61%\n",
      "Epoch: 18 | Epoch Time: 0m 5s\n",
      "ComputerVision Train Loss: 0.678 | Train Acc: 49.38%\n",
      "ComputerVision Valid Loss: 0.684 | Valid Acc: 48.17%\n",
      "ComputerVision Test Loss: 0.661 | Test Acc: 65.07%\n",
      "Epoch: 19 | Epoch Time: 0m 5s\n",
      "ComputerVision Train Loss: 0.679 | Train Acc: 49.69%\n",
      "ComputerVision Valid Loss: 0.681 | Valid Acc: 47.31%\n",
      "ComputerVision Test Loss: 0.667 | Test Acc: 61.82%\n",
      "Epoch: 20 | Epoch Time: 0m 5s\n",
      "ComputerVision Train Loss: 0.677 | Train Acc: 48.23%\n",
      "ComputerVision Valid Loss: 0.681 | Valid Acc: 48.15%\n",
      "ComputerVision Test Loss: 0.667 | Test Acc: 61.87%\n",
      "Early stopping at epoch 20 for ComputerVision model.\n",
      "Best performing epoch for ComputerVision model: 14\n"
     ]
    }
   ],
   "source": [
    "RESULTS_A_P2_1000, best_model_states = train_loop(models, optimizers, iterators, N_EPOCHS, label_names, target_field, model_file_names, best_valid_losses, \"P2\", \"1000\", 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "0a412923",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "InformationTheory:\n",
      "[[ 287 9300]\n",
      " [ 214 8265]]\n",
      "Accuracy: 0.4733754013063213\n",
      "Macro Precision: 0.5216961465625538\n",
      "Macro Recall: 0.5023487734187358\n",
      "Macro F1 score: 0.3457972087984818\n",
      "MCC: 0.014277161109285449\n",
      "\n",
      "\n",
      "ComputationalLinguistics:\n",
      "[[10404  4294]\n",
      " [ 2465   903]]\n",
      "Accuracy: 0.6258718033875789\n",
      "Macro Precision: 0.49110425713035843\n",
      "Macro Recall: 0.4879815236548738\n",
      "Macro F1 score: 0.4828368419638268\n",
      "MCC: -0.020679775168131014\n",
      "\n",
      "\n",
      "ComputerVision:\n",
      "[[11735   112]\n",
      " [ 6156    63]]\n",
      "Accuracy: 0.6530499280416252\n",
      "Macro Precision: 0.5079581912693534\n",
      "Macro Recall: 0.5003381879210782\n",
      "Macro F1 score: 0.4044659402994262\n",
      "MCC: 0.0032810755315444964\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_IT.load_state_dict(best_model_states[0])\n",
    "model_CL.load_state_dict(best_model_states[1])\n",
    "model_CV.load_state_dict(best_model_states[2])\n",
    "\n",
    "# Evaluate models\n",
    "evaluate_model(model_IT, test_iterator_IT, \"InformationTheory\", target_field)\n",
    "evaluate_model(model_CL, test_iterator_CL, \"ComputationalLinguistics\", target_field)\n",
    "evaluate_model(model_CV, test_iterator_CV, \"ComputerVision\", target_field)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d49b18df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "InformationTheory:\n",
      "[[ 287 9300]\n",
      " [ 214 8265]]\n",
      "Accuracy: 0.4733754013063213\n",
      "Macro Precision: 0.5216961465625538\n",
      "Macro Recall: 0.5023487734187358\n",
      "Macro F1 score: 0.3457972087984818\n",
      "MCC: 0.014277161109285449\n",
      "\n",
      "\n",
      "ComputationalLinguistics:\n",
      "[[10404  4294]\n",
      " [ 2465   903]]\n",
      "Accuracy: 0.6258718033875789\n",
      "Macro Precision: 0.49110425713035843\n",
      "Macro Recall: 0.4879815236548738\n",
      "Macro F1 score: 0.4828368419638268\n",
      "MCC: -0.020679775168131014\n",
      "\n",
      "\n",
      "ComputerVision:\n",
      "[[11735   112]\n",
      " [ 6156    63]]\n",
      "Accuracy: 0.6530499280416252\n",
      "Macro Precision: 0.5079581912693534\n",
      "Macro Recall: 0.5003381879210782\n",
      "Macro F1 score: 0.4044659402994262\n",
      "MCC: 0.0032810755315444964\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_IT.load_state_dict(best_model_states[0])\n",
    "model_CL.load_state_dict(best_model_states[1])\n",
    "model_CV.load_state_dict(best_model_states[2])\n",
    "\n",
    "# Evaluate models\n",
    "evaluate_model(model_IT, test_iterator_IT, \"InformationTheory\", target_field)\n",
    "evaluate_model(model_CL, test_iterator_CL, \"ComputationalLinguistics\", target_field)\n",
    "evaluate_model(model_CV, test_iterator_CV, \"ComputerVision\", target_field)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "6482fc43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"Abstract\", using all data\n",
    "# P1\n",
    "target_field = \"abstract\"\n",
    "\n",
    "TEXT = data.Field(sequential=True, tokenize=custom_tokenizer, lower=True)\n",
    "LABEL = data.LabelField(dtype=torch.float, use_vocab = False, preprocessing = int)\n",
    "\n",
    "train_datafield = [(\"title\", None), \n",
    "                   (\"abstract\", TEXT),\n",
    "                   (\"InformationTheory\", LABEL), \n",
    "                   (\"ComputationalLinguistics\", LABEL),\n",
    "                   (\"ComputerVision\", LABEL)\n",
    "                   ]\n",
    "\n",
    "# Dataset - P1\n",
    "train_data_whole, test_data = TabularDataset.splits(\n",
    "    path = \"./\",\n",
    "    train = \"train.csv\", test = \"test.csv\", format = \"csv\",\n",
    "    skip_header = True, fields = train_datafield)\n",
    "\n",
    "\n",
    "# Building vocab\n",
    "MAX_VOCAB_SIZE = 5000\n",
    "train_data, valid_data = train_data_whole.split(split_ratio = 0.9, random_state = random.getstate())\n",
    "train_1000, remaining = train_data_whole.split(split_ratio = 1000 / len(train_data_whole), random_state = random.getstate())\n",
    "train_1000, valid_1000 = train_1000.split(split_ratio = 0.9, random_state = random.getstate())\n",
    "TEXT.build_vocab(train_data, max_size = MAX_VOCAB_SIZE)\n",
    "\n",
    "# Run generate_label_iterator functions\n",
    "\n",
    "\n",
    "train_iterator_IT, validation_IT, test_iterator_IT = generate_label_iterator(train_data, \"InformationTheory\", target_field, validation = True)\n",
    "train_iterator_CL, validation_CL, test_iterator_CL = generate_label_iterator(train_data, \"ComputationalLinguistics\", target_field, validation = True)\n",
    "train_iterator_CV, validation_CV, test_iterator_CV = generate_label_iterator(train_data, \"ComputerVision\", target_field, validation = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "cc6b9049",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53998 58502\n",
      "85503 26997\n",
      "85499 27001\n"
     ]
    }
   ],
   "source": [
    "# Initialize counts\n",
    "negative_IT_count, positive_IT_count = 0, 0\n",
    "negative_CL_count, positive_CL_count = 0, 0\n",
    "negative_CV_count, positive_CV_count = 0, 0\n",
    "\n",
    "# Iterate through the dataset\n",
    "for example in train_data.examples:\n",
    "    if getattr(example, \"InformationTheory\") == 0:\n",
    "        negative_IT_count += 1\n",
    "    else:\n",
    "        positive_IT_count += 1\n",
    "\n",
    "    if getattr(example, \"ComputationalLinguistics\") == 0:\n",
    "        negative_CL_count += 1\n",
    "    else:\n",
    "        positive_CL_count += 1\n",
    "\n",
    "    if getattr(example, \"ComputerVision\") == 0:\n",
    "        negative_CV_count += 1\n",
    "    else:\n",
    "        positive_CV_count += 1\n",
    "        \n",
    "print(negative_CV_count, positive_CV_count)\n",
    "print(negative_IT_count, positive_IT_count)\n",
    "print(negative_CL_count, positive_CL_count)\n",
    "\n",
    "pos_weight_IT = torch.tensor([negative_IT_count / positive_IT_count])\n",
    "pos_weight_CL = torch.tensor([negative_CL_count / positive_CL_count])\n",
    "pos_weight_CV = torch.tensor([negative_CV_count / positive_CV_count])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "0c8aa37b",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.",
     "output_type": "error",
     "traceback": [
      "Traceback \u001b[1;36m(most recent call last)\u001b[0m:\n",
      "\u001b[0m  Cell \u001b[0;32mIn[64], line 1\u001b[0m\n    model_IT, optimizer_IT = generate_model_and_optimizer(pos_weight = pos_weight_IT)\u001b[0m\n",
      "\u001b[0m  Cell \u001b[0;32mIn[16], line 9\u001b[0m in \u001b[0;35mgenerate_model_and_optimizer\u001b[0m\n    model = model.to(device)\u001b[0m\n",
      "\u001b[0m  File \u001b[0;32m~\\anaconda3\\envs\\5212A1\\lib\\site-packages\\torch\\nn\\modules\\module.py:852\u001b[0m in \u001b[0;35mto\u001b[0m\n    return self._apply(convert)\u001b[0m\n",
      "\u001b[0m  File \u001b[0;32m~\\anaconda3\\envs\\5212A1\\lib\\site-packages\\torch\\nn\\modules\\module.py:530\u001b[0m in \u001b[0;35m_apply\u001b[0m\n    module._apply(fn)\u001b[0m\n",
      "\u001b[0m  File \u001b[0;32m~\\anaconda3\\envs\\5212A1\\lib\\site-packages\\torch\\nn\\modules\\module.py:552\u001b[0m in \u001b[0;35m_apply\u001b[0m\n    param_applied = fn(param)\u001b[0m\n",
      "\u001b[1;36m  File \u001b[1;32m~\\anaconda3\\envs\\5212A1\\lib\\site-packages\\torch\\nn\\modules\\module.py:850\u001b[1;36m in \u001b[1;35mconvert\u001b[1;36m\n\u001b[1;33m    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)\u001b[1;36m\n",
      "\u001b[1;31mRuntimeError\u001b[0m\u001b[1;31m:\u001b[0m CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\n"
     ]
    }
   ],
   "source": [
    "model_IT, optimizer_IT = generate_model_and_optimizer(pos_weight = pos_weight_IT)\n",
    "model_CL, optimizer_CL = generate_model_and_optimizer(pos_weight = pos_weight_CL)\n",
    "model_CV, optimizer_CV = generate_model_and_optimizer(pos_weight = pos_weight_CV)\n",
    "\n",
    "N_EPOCHS = 30\n",
    "label_names = [\"InformationTheory\", \"ComputationalLinguistics\", \"ComputerVision\"]\n",
    "models = [model_IT, model_CL, model_CV]\n",
    "optimizers = [optimizer_IT, optimizer_CL, optimizer_CV]\n",
    "iterators = [(train_iterator_IT, validation_IT, test_iterator_IT), (train_iterator_CL, validation_CL, test_iterator_CL), (train_iterator_CV, validation_CV, test_iterator_CV)]\n",
    "model_file_names = [\"RNN_model_IT\", \"RNN_model_CL.pt\", \"RNN_model_CV.pt\"]\n",
    "best_valid_losses = [float(\"inf\"), float(\"inf\"), float(\"inf\")]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45b8d338",
   "metadata": {},
   "outputs": [],
   "source": [
    "RESULTS_A_P1_ALL, best_model_states = train_loop(models, optimizers, iterators, N_EPOCHS, label_names, target_field, model_file_names, best_valid_losses, \"P1\", \"ALL\", 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79554455",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_IT.load_state_dict(best_model_states[0])\n",
    "model_CL.load_state_dict(best_model_states[1])\n",
    "model_CV.load_state_dict(best_model_states[2])\n",
    "\n",
    "# Evaluate models\n",
    "evaluate_model(model_IT, test_iterator_IT, \"InformationTheory\", target_field)\n",
    "evaluate_model(model_CL, test_iterator_CL, \"ComputationalLinguistics\", target_field)\n",
    "evaluate_model(model_CV, test_iterator_CV, \"ComputerVision\", target_field)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b743f019",
   "metadata": {},
   "outputs": [],
   "source": [
    "# P2\n",
    "\n",
    "target_field = \"abstract\"\n",
    "\n",
    "TEXT = data.Field(sequential=True, tokenize=custom_tokenizer_P2, lower=True)\n",
    "LABEL = data.LabelField(dtype=torch.float, use_vocab = False, preprocessing = int)\n",
    "\n",
    "train_datafield = [(\"title\", None), \n",
    "                   (\"abstract\", TEXT),\n",
    "                   (\"InformationTheory\", LABEL), \n",
    "                   (\"ComputationalLinguistics\", LABEL),\n",
    "                   (\"ComputerVision\", LABEL)\n",
    "                   ]\n",
    "\n",
    "# Dataset\n",
    "train_data, test_data = TabularDataset.splits(\n",
    "    path = \"./\",\n",
    "    train = \"train.csv\", test = \"test.csv\", format = \"csv\",\n",
    "    skip_header = True, fields = train_datafield)\n",
    "\n",
    "# Building vocab\n",
    "MAX_VOCAB_SIZE = 5000\n",
    "\n",
    "train_data, valid_data = train_data_whole.split(split_ratio = 0.9, random_state = random.getstate())\n",
    "\n",
    "TEXT.build_vocab(train_data, max_size = MAX_VOCAB_SIZE)\n",
    "# LABEL.build_vocab(train_data)\n",
    "\n",
    "# Run generate_label_iterator functions\n",
    "train_iterator_IT, validation_IT, test_iterator_IT = generate_label_iterator(train_data, \"InformationTheory\", target_field, validation = True)\n",
    "train_iterator_CL, validation_CL, test_iterator_CL = generate_label_iterator(train_data, \"ComputationalLinguistics\", target_field, validation = True)\n",
    "train_iterator_CV, validation_CV, test_iterator_CV = generate_label_iterator(train_data, \"ComputerVision\", target_field, validation = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06219ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_IT, optimizer_IT = generate_model_and_optimizer(pos_weight = pos_weight_IT)\n",
    "model_CL, optimizer_CL = generate_model_and_optimizer(pos_weight = pos_weight_CL)\n",
    "model_CV, optimizer_CV = generate_model_and_optimizer(pos_weight = pos_weight_CV)\n",
    "\n",
    "N_EPOCHS = 30\n",
    "label_names = [\"InformationTheory\", \"ComputationalLinguistics\", \"ComputerVision\"]\n",
    "models = [model_IT, model_CL, model_CV]\n",
    "optimizers = [optimizer_IT, optimizer_CL, optimizer_CV]\n",
    "iterators = [(train_iterator_IT, validation_IT, test_iterator_IT), (train_iterator_CL, validation_CL, test_iterator_CL), (train_iterator_CV, validation_CV, test_iterator_CV)]\n",
    "model_file_names = [\"RNN_model_IT\", \"RNN_model_CL.pt\", \"RNN_model_CV.pt\"]\n",
    "best_valid_losses = [float(\"inf\"), float(\"inf\"), float(\"inf\")]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f70bb28",
   "metadata": {},
   "outputs": [],
   "source": [
    "RESULTS_A_P2_ALL, best_model_states = train_loop(models, optimizers, iterators, N_EPOCHS, label_names, target_field, model_file_names, best_valid_losses, \"P2\", \"ALL\", 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63371be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_IT.load_state_dict(best_model_states[0])\n",
    "model_CL.load_state_dict(best_model_states[1])\n",
    "model_CV.load_state_dict(best_model_states[2])\n",
    "\n",
    "# Evaluate models\n",
    "evaluate_model(model_IT, test_iterator_IT, \"InformationTheory\", target_field)\n",
    "evaluate_model(model_CL, test_iterator_CL, \"ComputationalLinguistics\", target_field)\n",
    "evaluate_model(model_CV, test_iterator_CV, \"ComputerVision\", target_field)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba769e7b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85b73a79",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "328824b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "048c3227",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44e06b3f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f48ae351",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "910c7c57",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d917c0f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "231c4b18",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "786b55a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd217316",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (Spyder)",
   "language": "python3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
